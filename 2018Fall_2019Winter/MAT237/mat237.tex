\documentclass[11pt]{article}
\usepackage{spikey}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{soul}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{chngcntr}
\usepackage{centernot}
\usepackage{datetime}
\usepackage[shortlabels]{enumitem}

\usepackage[margin=1truein]{geometry}

\title{MAT237: Multivariable Calculus}
\date{\today}
\author{Tianyu Du}

\usepackage[
    type={CC},
    modifier={by-nc},
    version={4.0},
]{doclicense}

\counterwithin{equation}{subsection}
\counterwithin{theorem}{subsection}
\counterwithin{lemma}{subsection}
\counterwithin{corollary}{subsection}
\counterwithin{proposition}{subsection}
\counterwithin{remark}{subsection}
\counterwithin{example}{subsection}
\counterwithin{definition}{subsection}

\newcommand{\vef}[0]{\ve{f}}
\newcommand{\veg}[0]{\ve{g}}
\newcommand{\veF}[0]{\ve{F}}
\newcommand{\veG}[0]{\ve{G}}

\begin{document}
	\maketitle
	\doclicenseThis
	\begin{itemize}
		\item GitHub: \url{https://github.com/TianyuDu/Spikey_UofT_Notes}
		\item Website: \url{TianyuDu.com/notes}
	\end{itemize}
	\tableofcontents
	\newpage
	
	\section{Limits, continuity, and related topics}
		\subsection{Open and Closed Sets, Boundary, Interior and Closure}
			\begin{definition}
				Let $\ve{a} \in \R^n$, and $r > 0$. The \textbf{open ball with centre $\ve{a}$ and radius $r$} is defined as
				\begin{gather}
					\mc{B}(r, \ve{a}) := \{ \ve{x} \in \R^n : \norm{\ve{x} - \ve{a}}< r\}.
				\end{gather}
			\end{definition}
			
			\begin{definition}
				The \textbf{sphere with centre $\ve{a}$ and radius $r$} is defined as
				\begin{gather}
					\partial \mc{B}(r, \ve{a}) := \{\ve{x} \in \R^n: \norm{\ve{x} - \ve{a}} = r\}
				\end{gather}
			\end{definition}
			
			\begin{definition}
				Let $S \subset \R^n$, $S$ is \textbf{bounded} if 
				\begin{gather}
					\exists r > 0\ s.t.\ S \subset \mc{B}(r, \ve{0})
				\end{gather}
			\end{definition}
			
			\begin{definition}
				Let $S \subset \R^n$, then the \textbf{complement} of $S$ is defined as 
				\begin{gather}
					S^c := \{\ve{x} \in \R^n: \ve{x} \notin S\}
				\end{gather}
			\end{definition}
			
			\begin{definition}
				Let $S \subset \R^n$, the \textbf{interior} of $S$ is defined as
				\begin{gather}
					S^{int} := \{\ve{x} \in \R^n: \exists \varepsilon > 0\ s.t.\ \mc{B}(\varepsilon, \ve{x}) \subset S\}
				\end{gather}
			\end{definition}
			
			\begin{definition}
				The \textbf{boundary} of $S$ is defined as
				\begin{gather}
					\partial S := \{\ve{x} \in \R^n: \forall \varepsilon > 0\ \mc{B}(\varepsilon, \ve{x}) \cap S \neq \varnothing \land \mc{B}(\varepsilon, \ve{x}) \cap S^c \neq \varnothing \}
				\end{gather}
			\end{definition}
			
			\begin{theorem}
				A point $\ve{x} \in S$ is either a \emph{boundary point} or a \emph{interior point}.
			\end{theorem}
			
			\begin{definition}
				The \textbf{closure} of $S$ is defined as 
				\begin{gather}
					\overline{S} := S^{int} \cup \partial S
				\end{gather}
			\end{definition}
			
			\begin{theorem}
				For any $S \subset \R^n$
				\begin{gather}
					S^{int} \subset S \subset \overline{S}
				\end{gather}
			\end{theorem}
			
			\begin{theorem}
				For any $S \subset \R^n$
				\begin{gather}
					\partial S = \partial (S^c)
				\end{gather}
			\end{theorem}
			
			\begin{definition}
				A set $S \subset \R^n$ is \textbf{open} if $S = S^{int}$. $S$ is \textbf{closed} if $S = \overline{S}$.
			\end{definition}
			
			\begin{theorem}
				\begin{gather}
					S \tx{ is closed} \iff S^c \tx{ is open}
				\end{gather}
				\begin{proof}
					\begin{gather}
						S \tx{ is closed} \iff \partial S \subset S
						\iff \partial (S^c) \subset S \\
						\iff \tx{no point of $S^c$ is a boundary point}
						\iff S^c \tx{ is open}
					\end{gather}
				\end{proof}
			\end{theorem}
			
			\begin{proposition}
				A set $S$ is \emph{closed} if it contains all limit points. That's, every convergent sequence in $S$ converges to a limit point in $S$.
			\end{proposition}
		
		\subsection{Limits and Continuity}
			\subsubsection{Limits of Multivariable Functions}
			\begin{definition}
				Let $S \subset \R^n$, $\ve{f}: S \to \R^k$, and $\ve{a} \in S$, then
				\begin{equation}
					\lim_{\ve{x} \to \ve{a}} \ve{f}(\ve{x}) = \ve{L} \in \R^k
				\end{equation}
				is defined as
				\begin{gather}
					\forall \varepsilon > 0\ \exists \delta > 0\ s.t.\ \forall \ve{x} \in S,\ \red{0 <} \norm{\ve{x} - \ve{a}} < \delta \implies \norm{\ve{f}(\ve{x}) - \ve{L}} < \varepsilon
				\end{gather}
				For this definition to be non-trivial, we need $\ve{a}$ not be an isolated point,
				\begin{equation}
					\forall \delta > 0,\ \exists \ve{x} \in S\ s.t.\ \norm{\ve{x} - \ve{a}} \in (0, \delta)
				\end{equation}
			\end{definition}
			
			\begin{theorem}[Limit Laws]
				Let $S \subset \R^n$ and $\ve{a} \in \R^n$ satisfying (1.3.3)
				And $f, g: S \to \R$, $L, M \in \R$ such that
				\begin{gather}
					\lim_{\ve{x} \to \ve{a}} f(\ve{x}) = L \\
					\lim_{\ve{x} \to \ve{a}} f(\ve{x}) = M
				\end{gather}
				then 
				\begin{gather}
					\lim_{\ve{x} \to \ve{a}} [f(\ve{x})	+ g(\ve{x})] = L + M\\
					\lim_{\ve{x} \to \ve{a}} [f(\ve{x}) \cdot g(\ve{x})] = LM
				\end{gather}
			\end{theorem}
			
			\begin{theorem}[Squeeze Theorem on Real Valued Functions]
				Let $S \subset \R^n$, $\ve{a} \in \R^n$ satisfies (1.3.3). Suppose that $f, g, h: S \to \R$ and there exists $p > 0$ and $L \in \R$ such that
				\begin{equation}
					\forall \ve{x} \in S \cap \mc{B}(p, \ve{a})\ f(\ve{x}) \leq g(\ve{x}) \leq h(\ve{x})
				\end{equation}
				and 
				\begin{equation}
					\lim_{\ve{x} \to \ve{a}} f(\ve{x}) = \lim_{\ve{x} \to \ve{a}} h(\ve{x}) = L
				\end{equation}
				then 
				\begin{equation}
					\lim_{\ve{x} \to \ve{a}} g(\ve{x}) = L
				\end{equation}
			\end{theorem}
			
			\begin{corollary}
				Let $g, h: S \to \R$ and
				\begin{gather}
					|g(\ve{x})| \leq h(\ve{x})\ \forall \ve{x} \in S \\
					\tx{and } \lim_{\vex \to \vea} h(\vex) = 0
				\end{gather}
				then 
				\begin{gather}
					\lim_{\vex \to \ve{a}} g(\vex) = 0
				\end{gather}
			\end{corollary}
			
			\begin{theorem}
				Assume that $S \subset \R^n$ and let $\vea \in \R^n$ satisfying (1.3.3). Let $\vef: S \to \R^k$, then
				\begin{equation}
					\lim_{\vex \to \vea} \vef(\vex) = \ve{L} \iff \lim_{\vex \to \vea} f_j(\vex) = L_j\ \forall j
				\end{equation}
			\end{theorem}
			
			\subsubsection{Continuity}
				\begin{definition}
					Let $S \subset \R^n$ and $\vef: S \to \R^k$. $\vef$ is \textbf{continuous at $\vea \in S$} if 
					\begin{equation}
						\lim_{\vex \to \vea}\vef(\vex) = \vef(\vea)
					\end{equation}
					and $\vef$ is \textbf{continuous} if $\vef$ is continuous at every point in $S$.
				\end{definition}
			
				\begin{theorem}[Basic Properties of Continuity]
					Assume that $S \subset \R^n$ and $\vea \in S$,
					\begin{enumerate}[(i)]
						\item If $\vef: S \to \R^k$ is continuous at $\vea$, then every component of $\vef$, $f_j: S \to \R$, is continuous at $\vea$.
						\item If $\vef, \veg: S \to \R^k$ are continuous at $\vea$, then $\vef + \veg$ is continuous at $\vea$.
						\item If $f, g: S \to \R$ continuous, then $fg$ is continuous and $\frac{f}{g}$ is continuous given $g(\vea) \neq 0$.
						\item A composition of continuous functions is continuous.
						\item The elementary functions of a single variable (trigonometric functions and their inverses, polynomials, exponential and log) are continuous on their domains.
					\end{enumerate}
				\end{theorem}
			\subsubsection{Continuous Functions and Open Sets}
				\begin{theorem}
					Assume that $\vef: \R^n \to \R^k$, then the following are equivalent
					\begin{enumerate}[(i)]
						\item $\vef$ is continuous;
						\item For every open set $\mc{O} \subset \R^k$, $\vef^{-1}(\mc{O})$ is also open;
						\item For every closed set $\mc{C} \subset \R^k$, $\vef^{-1}(\mc{C})$ is also closed.
					\end{enumerate}
				\end{theorem}
		\subsection{Sequences and Completeness}
			\begin{definition}
		    	    A sequence $\{\vea_j\}_j$ in $\R^n$ \textbf{converges to the limit $\ve{L} \in \R^n$} if 
		    	    \begin{equation}
		    	    	\forall \varepsilon > 0\ \exists J \in \N,\ s.t.\ \forall j \geq J \implies \norm{\vea_j - \ve{L}} < \varepsilon
		    	    \end{equation}
		    \end{definition}
		    
		    \begin{theorem}
		    		\begin{equation}
		    			\lim_{j \to \infty} \vea _j = \ve{L} \iff \lim_{j \to \infty} \norm{\vea_j - \ve{L}} = 0
		    		\end{equation}
		    \end{theorem}
		    
		    \begin{theorem}
		    		Let $\{a_{jk}\}_j$ be a sequence in $\R^n$ where $k \in [n]$, and let $\ve{L} = (L_1, \dots, L_n) \in \R^n$, then
		    		\begin{equation}
		    			\lim_{j \to \infty} \vea _j = \ve{L} \iff \lim_{j \to \infty} a_{jk} = L_k\ \forall k \in [n]
		    		\end{equation}
		    		\begin{proof}[Proof Idea.]
		    			\begin{equation}
		    				\forall j \in [n],\ |a_j - L_j| \leq \norm{\vea - \ve{L}} \leq n \max_{k \in [n]} |a_k - L_k|
		    			\end{equation}
		    		\end{proof}
		    \end{theorem}
		    
		    \begin{axiom}[the Completeness Axiom]
		    		Every \emph{bounded} and \emph{nonempty} set of \emph{real numbers} has a \emph{least upper bound} (\textbf{supremum}) and a \emph{greatest lower bound} (\textbf{infimum}).
		    \end{axiom}
		    
		    \begin{theorem}[Monotone Sequence Theorem]
		    		Every bounded nondecreasing sequence of real numbers converges to a limit.
		    		\begin{proof}[Proof Idea.]
		    			Note that such sequence converges to its supremum $S$.\\
		    			Let $\varepsilon > 0$, there exists $j^*$ such that
		    			\begin{equation}
		    				S - \varepsilon < a_{j^*} \leq S
		    			\end{equation}
		    			take such $j^*$ and by the nondecreasing property,
		    			\begin{equation}
		    				\forall j \geq j^*\ a_j > S - \varepsilon
		    			\end{equation}
		    			which implies $|S - a_j| < \varepsilon$.
		    		\end{proof}
		    \end{theorem}
		    
		    \begin{theorem}[Monotone Sequence Theorem]
		    	Every bounded monotone sequence in $\R$ is convergent.
		    \end{theorem}
		    
		    \begin{definition}
		    		A \textbf{subsequence} of a sequence $\{\vea_j\}_{j \geq j_0}$ in $\R^n$ is a sequence constructed as $\{a_{k_j}\}_j$, such that $\{k_j\}_j$ is a \emph{strictly increasing} sequence bounded below by $j_0$.
		    \end{definition}
		    
		    \begin{remark}
		    		Subsequences can be constructed using strictly increasing transformations.
		    \end{remark}
		    
		    \begin{proposition}
			    	If $\{\vea_j\}_j$ is a sequence in $\R^n$ converges to $\ve{L}$, then (i) any subsequence of it converges to the (ii) same limit.
			    	\begin{proof}[Proof Idea]
			    		Suppose not and reach a contradiction.
			    	\end{proof}
		    \end{proposition}
		    
		    \begin{theorem}[Bounded Sequence Theorem in $\R$]
		    		Every bounded sequence in $\R$ has a convergent subsequence.
		    		\begin{proof}
		    			Let $\{a_j\}_j$ be a bounded sequence. \\
		    			For each $j \in \N$, define $b_{k_j} := \inf_{k > k_j} a_k$. \\
		    			Note that $\{b_j\}$ is non-decreasing and bounded, so it converges to some limit $\ell$. \\
		    			Let $\{a_{k_j}\}_j$ denote a subsequence of the original sequence, define $k_0 = j_0$, and indices are constructed in a recurrent way. \\
		    			Suppose every index before $k_j$ has been chosen, we choose $k_{j+1}$  to be the index such that 
		    			\begin{equation}
		    				b_{k_j} \leq a_{k_{j+1}} < b_{k_j} + \frac{1}{j}
		    			\end{equation}
		    			by construction, $\{a_{k_j}\}_j$ is bounded by both $\{b_{k_j}\}_j$ and $\{b_{k_j} + \frac{1}{j}\}_j$, and both bounding sequences converge to $\ell$. So $\{a_{k_j}\}_j$ converges to $\ell$ by \emph{squeeze theorem}.
		    		\end{proof}
		    \end{theorem}
		    
		    \begin{theorem}[Bounded Sequence Theorem]
		        Every bounded sequence in $\R^n$ has a convergent subsequence.
		        \begin{proof}
		        	Let $\{\vea_j\}_j$ be a bounded sequence. \\
		        	Applying the previous theorem iteratively, we can construct a subsequence of $\{\vea_{k_j}\}_j$ such that $\{\vea_{k_j} \cdot \ve{e}_1\}_{j}$ is bounded and convergent. \\
		        	Then we apply the previous theorem iteratively on the constructed convergent subsequences to construct new subsequences with more convergent components.
		        \end{proof}
		    \end{theorem}
		    
		    \begin{theorem}[Nested Interval Theorem]
		    	Given a sequence of \emph{closed intervals} in $\R$,
		    	\begin{equation}
		    		\{I_k\}_{k \in \mc{A}}\ s.t.\ I_k = [a_k, b_k] \subset \R
		    	\end{equation}
		    	and 
		    	\begin{equation}
		    		\cdots I_{k+1} \subseteq I_{k} \subseteq \cdots I_4 \subseteq I_3 \subseteq I_2 \subseteq I_1
		    	\end{equation}
		    	Then
		    	\begin{equation}
		    		\bigcap_{k \in \mc{A}}I_k \neq \varnothing
		    	\end{equation}
		    \end{theorem}
		    
		\subsection{Compactness}
			\subsubsection{Compactness}
				\begin{definition}[Heine-Borel Property]
					A set $S$ is \textbf{compact} if every \emph{open} covering of $S$ has a \emph{finite} sub-covering.
				\end{definition}
				
				\begin{definition}[Sequentially Compact]
					A set $S\ \red{\subset \R^n}$ is \textbf{compact} if every sequence in $S$ has a subsequence that converges to a limit in $S$.
				\end{definition}
				
				\begin{proposition}
					If $\{\vex_j\}_j$ is a \emph{convergent} sequence in a \emph{closed} set $S \subset \R^n$, the then limit of this sequence is in $S$.
					\begin{proof}[Proof Idea]
						Let $\vex := \lim_{j \to \infty} \vex_j$, and we wish to show $\vex \in S$. \\
						Equivalently, we can show $\vex \in \overline{S}$, and that's 
						\begin{equation}
							\forall \varepsilon >0\ \mc{B}(\varepsilon, \ve{x}) \cap S \neq \varnothing
						\end{equation}
						this is immediately true by the definition of sequence convergence. There must be some points in the sequence, thus in $S$, belongs to $\mc{B}(\varepsilon, \ve{x})$.
					\end{proof}
				\end{proposition}
			
				\begin{theorem}[Bolzano-Weierstrass] Let $S\ \red{\subset \R^n}$,
					\begin{equation}
						S \tx{ is compact} \iff S \tx{ is closed and bounded}
					\end{equation}
					\begin{proof}[Proof Idea] \quad \\
						($\impliedby$) Suppose $S$ is closed and bounded, boundedness ensures such sequence converges, and closeness ensures the limit point of sequence is in $S$. \\
						($\implies$) Prove by \emph{modus tollens}. \\
						\textbf{Case (i): }$S$ is not bounded, then
						\begin{equation}
							\forall R > 0\ \exists \vex \in S \backslash \mc{B}(R,\ve{0})
						\end{equation}
						and above $\vex(R)$ depends on $R$, we can construct a sequence using $\vex(j)$ such that the $\norm{\vex}$ is ever increasing and it does not have a limit. \\
						\textbf{Case (ii):} $S$ is not closed, we can construct a sequence with subsequence converges to $\vex \in \partial S \backslash S$, which is nonempty because $S$ is not closed.
					\end{proof}
				\end{theorem}
				
				\begin{theorem}
					Let $\vef: \R^n \to \R^m$ be a continuous function. If $K \subset \R^n$ is compact, then the image $\vef(K)$ is compact.
				\end{theorem}
			
			\subsubsection{the Extreme Value Theorem}
				\begin{theorem}[the Extreme Value Theorem]
					Assume $K$ is a \hl{compact} subset of $\R^n$ and $f: K \to \R$ is \hl{continuous}. \\
					Then (i) 
					\begin{equation}
						f(K) \tx{ is compact}
					\end{equation}
					and (ii) the infimum and supremum of $f(\vex)$ on $K$ are attainable.
					\begin{equation}
						\exists\ \overline{\vex}, \underbar{\vex} \in K\ s.t.\ 
						\begin{cases}
							f(\overline{\vex}) = \sup_{\vex \in K} f(\vex)\\
							f(\underbar{\vex}) = \inf_{\vex \in K} f(\vex)
						\end{cases}
					\end{equation}
					\begin{proof}
						Let $\{y_j\}_j$ be a sequence in $f(K)$, and we can find a sequence $\{\ve{z}_j\}_j$ in $K$ such that $y_j = f(\ve{z}_j)$ (by definition of image). Because $K$ is compact, there exists a subsequence of $\{\ve{z}_j\}_j$ converges to $\ve{z}^* \in K$. Since $f$ is continuous, we can conclude there a subsequence, sharing the same indices, such that $f(\ve{z}_j) \to f(\ve{z}^*)$ (\emph{Proposition 1.5.2}). Obviously $f(\ve{z}^*) \in f(K)$, \emph{so $f(K)$ is compact}. \\
						Since $f(K)$ is compact, by \emph{Proposition 1.5.3}, $\sup_{\vex \in K} f(\vex) \in f(K)$. By definition of image, $\exists \vex \in K$ such that $f(\vex) = \sup_{\vex \in K} f(\vex)$, \emph{supremum attainability shown}.\\
						Proof for infimum attainability is the same.
					\end{proof}
				\end{theorem}
				
				\begin{proposition}
					Assume that $\{\ve{z}_j\}_j$ is a sequence in a set $S \subset \R^k$, and $f$ is a continuous real-valued function defined on $S$, then
					\begin{equation}
						\ve{z}_j \to \ve{z} \implies f(\ve{z}_j) \to f(\ve{z})
					\end{equation}
				\end{proposition}
				
				\begin{proposition}
					If $S$ is a compact set in $\R$, then $\sup S$ and $\inf S$ both in $S$.
					\begin{proof}[Proof Idea]
						Suppose $\sup S \notin S$, by definition of supremum,
						\begin{equation}
							\forall \varepsilon\ \exists x \in S\ s.t\ \sup S - \varepsilon < x \leq \sup S
						\end{equation}
						note that such $x \in \mc{B}(\varepsilon, \sup S)$. Also, similarly,
						\begin{equation}
							\forall \varepsilon > 0\ \exists x \notin S\ s.t.\ \sup S < x < \sup S + \varepsilon
						\end{equation}
						so such $x \in \mc{B}(\varepsilon, \sup S)$. We conclude
						\begin{equation}
							\forall \varepsilon > 0\ \mc{B}(\varepsilon, \sup S) \cap S \neq \varnothing \land \mc{B}(\varepsilon, \sup S) \cap S^c \neq \varnothing
						\end{equation} 
						which means $\sup S \in \partial S$. Thus if $\sup S \notin S$, $S$ cannot be closed and this contradicts our assumption that $S$ is compact. \\
						The proof for $\inf S \in S$ is similar.
					\end{proof}
				\end{proposition}
				
			\subsubsection{Uniform Continuity}
				\begin{definition}
					Let $S \subset \R^n$, a function $\ve{f}: S \to \R^k$ is \textbf{uniformly continuous} if 
					\begin{equation}
						\red{
						\underbrace{\forall \varepsilon > 0\ \exists \delta > 0\ s.t.\ \forall \vex}_{\forall \vex \in S,\ \varepsilon > 0,\ \exists \delta > 0}
						,\ \vey \in S,\ \norm{\vex - \vey} < \delta \implies \norm{\vef(\vex) - \vef(\vey)} < \varepsilon
						}
					\end{equation}
				\end{definition}
				
				\begin{remark}
					In the definition of \emph{continuity}, value of $\delta$ can depend on $\vex$. But in the definition of \emph{uniform continuity}, one $\delta$ has to work for every $\vex$. 
				\end{remark}
				
				\begin{theorem}
					If $K$ is a compact subset of $\R^n$, and $\vef: K \to R^k$ is continuous, then $\vef$ is uniformly continuous.
				\end{theorem}
				
		\subsection{the Intermediate Value Theorem}
			\begin{definition}
				A set $S \subset \R^n$ is \textbf{path-connected} (\textbf{arcwise connected/ pathwise connected}) if for every $\vex, \vey \in S$, there exists a \hl{continuous} function $\gamma: [0, 1] \to \red{S}$ such that
				\begin{equation}
					\gamma(0) = \vex,\ \gamma(1) = \vey
				\end{equation}
			\end{definition}
			
			\begin{example}
				Convex sets are path-connected, a path can be constructed using the convex combination,
				\begin{equation}
					\gamma(t) := (1 - t) \vex + t \vey
				\end{equation}
			\end{example}
			
			\begin{proposition}
				Let $S_1, S_2 \subset \R^n$ be two path-connected sets, and $S_1 \cap S_2 \neq \varnothing$. Then $S_1 \cup S_2$ is path-connected.
				\begin{proof}
					Take $\ve{z} \in S_1 \cap S_2$, and let $\tilde{\gamma}_1$ and $\tilde{\gamma}_2$ be two connecting paths between $\vex, \ve{z}$ and $\ve{z}, \vey$ respectively. Then define $\gamma: [0, 1] \to S_1 \cup S_2$ as 
					\begin{equation}
						\gamma(t) := \mathds{1}\{t \in [0, \frac{1}{2})\} \times \tilde{\gamma}_1(2t) + \mathds{1}\{t \in [\frac{1}{2}, 1]\} \times \tilde{\gamma}_2(2(t-\frac{1}{2}))
					\end{equation}
				\end{proof}
			\end{proposition}
			
			\begin{theorem}
				Let $\trans{\vef}{\R^m}{\R^k}$ be a \hl{continuous} function, and $S \subset \R^m$ be a \hl{path-connected} set. Then, $\vef(S)$ is path-connected.
				\begin{proof}[Proof Idea.]
					Take the composite $\vef \circ \gamma$.
				\end{proof}
			\end{theorem}
			
			\begin{theorem}[the Intermediate Value Theorem]
				Assume that $S$ is a \hl{path-connected} subset of $\R^n$ and that $f: S \to \R$ is \hl{continuous}. Let $\vea, \veb \in S$.
				Then for every $t \in (\min\{f(\vea), f(\veb)\}, \max\{f(\vea), f(\veb)\})$, there exists $\ve{c} \in S$ such that $f(\ve{c}) = t$.
				\begin{proof}
					Let $\vea, \veb \in S$. WLOG, assume $f(\vea) < f(\veb)$. Let $t$ be an arbitrary value in $(f(\vea), f(\veb))$.\\
					Since $S$ is path-connected, let $\vec{\varphi}: [0, 1] \to S$ be a continuous function such that $\vec{\varphi}(0) = \vea$ and $\vec{\varphi}(1) = \veb$. \\
					Then we can construct composite $f \circ \vec{\varphi}: [0, 1] \to \R$, then apply the Intermediate Value Theorem in $\R$. We can conclude that $\exists \eta \in (0,1)\ s.t.\ f \circ \vec{\varphi}(\eta) = t$. And $\vec{\varphi}(\eta) \in S$ is the point desired.
				\end{proof}
			\end{theorem}
			
	\section{Differentiation and related topics}
		\subsection{Differentiation of Real-Valued Functions}
			\subsubsection{Single Variable Case}
				\begin{definition}[Equivalent Definitions of Differentiability]
					Let $S \subset \R$ open, and $f: S \to \R$ is said to be \textbf{differentiable at $x \in S$} if 
					\begin{equation}
						\lim_{h \to 0} \frac{f(x+h) - f(x)}{h} \tx{ exists}
					\end{equation}
					or there exists $m \in \R$ such that
					\begin{equation}
						\lim_{h \to 0} \frac{f(x+h) - f(x) - mh}{h} = 0
					\end{equation}
					or there exists $m \in \R$ and $E(h): \R \to \R$ such that
					\begin{equation}
						f(x+h) = f(x) + mh + E(h),\ \lim_{h \to 0} \frac{E(h)}{h} = 0
					\end{equation}
					If $f$ is differentiable at $x$, we define the \textbf{derivative} $f'(x) := m$.
				\end{definition}
			
			\subsubsection{Differentiability of Real-valued Functions Defined on $\R^n$}
				\begin{definition}
					Let $S$ be an open subset of $\R^n$, and $f: S \to \R$ is \textbf{differentiable at $\vex \in S$} if 
					\begin{equation}
						\lim_{\ve{h} \to \ve{0}} \frac{
							f(\vex + \ve{h}) - f(\vex)
						}{\norm{\ve{h}}} \tx{ exists}
					\end{equation}
					or there exists $\ve{m} \in M_{1\times n}$ such that
					\begin{equation}
						\lim_{\ve{h} \to \ve{0}} \frac{
							f(\vex + \ve{h}) - f(\vex) - \ve{m} \cdot \ve{h}
						}{\norm{\ve{h}}} = 0
					\end{equation}
					or there exists $\ve{m} \in M_{1\times n}$ and $E(\ve{h})$ such that
					\begin{equation}
						f(\vex + \ve{h}) = f(\vex) + \ve{m} \cdot \ve{h} + E(\ve{h}),\ \lim_{\ve{h} \to \ve{0}} \frac{E(\ve{h})}{\norm{\ve{h}}} = 0
					\end{equation}
					If $f$ is differentiable at $\vex$, we define its gradient as $\nabla f(\vea) := \ve{m}$.
				\end{definition}

				\begin{theorem}
					Assume that $f: S \to \R$, where $S$ is an open subset of $\R^n$, and that $\vex \in S$. If $f$ is \emph{differentiable} at $\vex$, then $f$ is continuous at $\vex$.
					\begin{proof}
						\begin{gather}
							f(\vex + \ve{h}) - f(\vex) = \ve{m} \cdot \ve{h} + E(\ve{h})
						\end{gather}
						Note \ul{that when $\norm{\ve{h}} \leq 1$},
						\begin{gather}
							E(\ve{h}) \leq \frac{|E(\ve{h})|}{\norm{\ve{h}}}
						\end{gather}
						By the \emph{Squeeze Theorem}, $\lim_{\ve{h} \to \ve{0}} E(\ve{h}) = 0$. Also, $\lim_{\ve{h} \to \ve{0}} \ve{m} \cdot \ve{h} = 0$. Thus 
						\begin{gather}
							\lim_{\ve{h} \to \ve{0}} f(\vex + \ve{h}) - f(\vex) = 0
						\end{gather}
						so $f$ is continuous at $\vex$.
					\end{proof}
				\end{theorem}
				
			\subsubsection{Partial Differentiability}
				\begin{definition}
					Let $S$ be an open subset of $\R^n$, and $f: S \to \R$. The \textbf{$j$-th partial derivative of $f$ at $\vex$} is defined as 
					\begin{equation}
						\pd{f(\vex)}{x_j} := \lim_{h \to 0} \frac{f(\vex + h \ve{e}_j) - f(\vex)}{h}
					\end{equation}
				\end{definition}
				
				\begin{theorem}
					Let $f$ be a function $S \to \R$, where $S$ is an open subset of $\R^n$. If $f$ is differentiable at a point $\vex \in S$, then (i) $\pd{f}{x_j}$ exists at $\vex$ for every $j \in [n]$ and (ii) 
					\begin{equation}
						\nabla f(\vex) := (\pd{f}{x_1}, \dots, \pd{f}{x_n})(\vex)
					\end{equation}
				\end{theorem}
				
				\begin{theorem}
					Assume $f$ is a function $S \to \R$ for some open $S \subset \R^n$. If all partial derivatives of $f$ \hl{exist and are continuous} at every point of $S$, then $f$ is differentiable in $S$.
				\end{theorem}
				
				\begin{definition}
					A function $f: S \to R$ is said to be \textbf{of class $C^1$} if all partial derivatives of $f$ \ul{exist and continuous} at every point of $S$.
				\end{definition}
								
			\subsubsection{Directional Derivatives}
				\begin{definition}
					A \textbf{direction} in $\R^n$ is represented by a unit vector $\ve{u}$. And given such a unit vector, the \textbf{directional derivative of $f$ at $\vex$ in the direction of $\ve{u}$} is defined as
					\begin{equation}
						\partial_{\ve{u}} f(\vex) := \lim_{h \to 0} \frac{f(\vex + h \ve{u}) - f(\vex)}{h}
					\end{equation}
				\end{definition}
				
				\begin{theorem}
					If $f$ is differentiable at a point $\vex$, then $\partial_{\ve{u}} f(\vex)$ exists for every unit vector $\ve{u}$, and moreover
					\begin{equation}
						\red{\partial_{\ve{u}} f(\vex) = \ve{u} \cdot \nabla f(\vex)}
					\end{equation}
				\end{theorem}
		
		\subsection{Differentiation}
			\begin{definition}
				Assume $S$ is an open subset of $\R^n$. Given function $\vef: S \to \R^m$, we say that $\ve{f}$ is differentiable at a point $\vea \in S$ if there exists $M \in M_{m \times n}$ such that
				\begin{equation}
					\vef(\vea + \ve{h}) - \vef(\vea) = M \ve{h} + \ve{E}(\ve{h}),\ \lim_{\ve{h} \to \ve{0}} \frac{\ve{E}(\ve{h})}{\norm{\ve{h}}} = \ve{0} \in \R^m
				\end{equation}
				If such $M$ exists, we define the \textbf{Jacobian matrix} of $\vef$ at $\vea$ as 
				\begin{equation}
					D\vef(\vea) := M
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Given a differentiable function $f: S \to \R$, where $S$ is an open subset of $\R^n$, at a point $\vea$ we define the \textbf{differential of $f$ at $\vea$} as 
				\begin{equation}
					df|_{\vea}(\ve{h}) := \nabla f(\vea) \cdot \ve{h}
				\end{equation}
			\end{definition}
			
			\begin{remark}
				The notion of differential applies to real-valued functions only (in this textbook).
			\end{remark}
			
			\begin{remark}[First Order Taylor Polynomial]
				The differential can be used for linear approximations for small $\ve{h}$.
				\begin{equation}
					f(\vex + \ve{h}) \approx f(\vex) + df|_{\vea}(\ve{h})
				\end{equation}
			\end{remark}
			
		\subsection{the Chain Rule}
			\begin{theorem}[the Chain Rule]
				Let $S_n \subset \R^n$ and $T_m \subset \R^m$, given functions $\veg: S_n \to \R^m$ and $\vef: T_m \to \R^{\ell}$. Also let $\vea \in S_n$ such that $\veg$ is differentiable at $\vea$ and $\vef$ is differentiable at $\veg(\vea)$\footnote{Also all functions $\vef$ and $\veg$ and $\vef \circ \veg$ are well-defined near $\vea$ and $\veg(\vea)$.}. Then
				\begin{equation}
					\underbrace{D(\vef \circ \veg)(\vea)}_{\ell \times n} 
					= \underbrace{D(\vef)(\veg(\vea))}_{\ell \times m} \underbrace{D\veg(\vea)}_{m \times n}
				\end{equation}
			\end{theorem}
			
			\begin{example}
				\begin{equation}
					\frac{d}{d\vex} \norm{\vex} = \frac{\vex}{\norm{\vex}}
				\end{equation}
			\end{example}
			
			\begin{definition}
				A function $f: \R^n \to \R$ is called \textbf{homogeneous of degree} $\alpha$ if
				\begin{equation}
					f(\lambda \vex) = \lambda^\alpha f(\vex)\ \forall \vex \neq \ve{0},\ \lambda \in \R_{++}
				\end{equation}
			\end{definition}
			
			\begin{theorem}[the Euler's Theorem of Homogeneous Functions]
				If $f: \R^n \to \R$ is a homogeneous equation of degree $\alpha$, then 
				\begin{equation}
					\nabla f(\vex) \cdot \vex = \alpha f(\vex)
				\end{equation}
				\begin{proof}
					\begin{gather}
						\begin{cases}
							\pd{f(\lambda \vex)}{\lambda} = \nabla f(\lambda \vex) \cdot \vex \\
							\pd{f(\lambda \vex)}{\lambda} = \pd{\lambda^\alpha f(\vex)}{\lambda} = \alpha \lambda^{\alpha - 1} f(\vex)
						\end{cases} \\
						\implies \nabla f(\lambda \vex) \cdot \vex = \alpha \lambda^{\alpha - 1} f(\vex) \\
						\implies \nabla f(\vex) \cdot \vex = \alpha f(\vex) \tx{ evaluated at } \lambda = 1
					\end{gather}
				\end{proof}
			\end{theorem}
			
			\begin{definition}
				Let $C$ be the level set of $f: S \to \R$ at $\vea \in S$ defined as 
				\begin{equation}
					C := \{\vex \in S: f(\vex) = f(\vea)\}
				\end{equation}
				and a vector $\ve{v}$ is \textbf{tangent to $C$ at $\vea$} if there exists a function $\gamma: I \to C$ defined on interval $I$ containing $0$, such that
				\begin{equation}
					\gamma(0) = \vea
				\end{equation}
				and 
				\begin{equation}
					\ve{v} = \gamma'(0)
				\end{equation}
			\end{definition}
			
			\begin{theorem}
				Let $S \subset \R^n$ be an open set, and $f: S \to \R$ is differentiable at $\vea$. Then $\nabla f(\vea)$ is orthogonal to the level set of $f$ passes through $\vea$.
				\begin{proof}[Proof Idea]
					Let $\ve{v}$ be an arbitrary tangent vector to $C$ at $\vea$, there must exists a function $\gamma: I \to C$. And define 
					\begin{equation}
						h(t) := f \circ \gamma (t)
					\end{equation}
					by definition of $\gamma$, $h(I) = \{f(\vea)\}$. Thus
					\begin{align}
						\frac{d}{dt}h(t) &= \frac{d}{dt} f \circ \gamma (t) \tx{ evaluated at }t=0\\
						&= \nabla f (\gamma(0)) \cdot \gamma'(0) \\
						&= \nabla f(\vea) \cdot \gamma'(0) \\
						&= \nabla f(\vea) \cdot \ve{v} = 0
					\end{align}
					So $\nabla f(\vea)$ is orthogonal to any tangent vector of $C$ at $\vea$, which means $\nabla f(\vea)$ is orthogonal to $C$.
				\end{proof}
			\end{theorem}
			
			
		\subsection{the Mean Value Theorem}
			\begin{theorem}[the Mean Value Theorem]
				Assume $f: S \to \R$, where $S$ is a \hl{convex} and \hl{open} subset of $\R^n$, of class $C^1$, then
				\begin{gather}
					\forall \vea, \veb \in S,\ \exists \lambda \in [0, 1]\ s.t.\ \ve{c} = \lambda \vea + (1 - \lambda) \veb \\
					\red{\nabla f(\ve{c}) \cdot (\veb - \vea) = f(\veb) - f(\vea)}
				\end{gather}
				\begin{proof}[Proof Idea]
					Define $\gamma(t) := t \vea + (1-t)\veb$.
					Construct $h: [0, 1] \to \R$ defined as $h := f(\gamma(t))$
					then apply one dimensional mean value theorem on $h$.
				\end{proof}
			\end{theorem}
			
			\begin{definition}
				A set $S \subset \R^n$ is \textbf{convex} if
				\begin{equation}
					\forall \vea, \veb \in S, \lambda \in [0, 1],\ \lambda \vea + (1 - \lambda) \veb \in S
				\end{equation}				
			\end{definition}
			
			\begin{theorem}
				Assume that $S$ is an \ul{open and convex} subset of $\R^n$ and that $f: \R^n \to \R$ is differentiable in $S$ such that
				\begin{equation}
					\norm{\nabla f(\vex)} \leq M\ \forall \vex \in S
				\end{equation}
				then for every $\vea, \veb \in S$,
				\begin{equation}
					|f(\veb) - f(\vea)| \leq M \norm{\veb - \vea}
				\end{equation}
				\begin{proof}[Proof Idea]
					Use \emph{Cauchy's Inequality}.
				\end{proof}
			\end{theorem}
			
			\begin{theorem}
				Assume that $S$ is an \ul{open and convex} subset of $\R^n$, and $f: S \to \R$ is a function differentiable on $S$. If $\nabla f(\vex) = \ve{0}\ \forall \vex \in S$, then $f$ is constant on $S$.
				\begin{proof}[Proof Idea]
					Take two arbitrary $\vea, \veb \in S$, then use mean value theorem to show $f(\vea) = f(\veb)$.
				\end{proof}
			\end{theorem}
			
			\begin{theorem}[Generalization of the Previous Theorem]
				Assume that $S$ is an \ul{open and path-connected} subset of $\R^n$, and $f: S \to \R$ is a function differentiable on $S$. If $\nabla f(\vex) = \ve{0}\ \forall \vex \in S$, then $f$ is constant on $S$.
				\begin{proof}
					Any path-connected set can be written as a countable union of convex sets $S = \cup_{i \in \mc{A}} C_i$ such that
					\begin{equation}
						\forall \alpha \subset \mc{A}\ s.t.\ \alpha \neq \varnothing,\ \cup_{i \in \alpha} C_i \cap \cup_{i \in \alpha^c} C_i \neq \varnothing
					\end{equation}
					then apply the previous theorem.
				\end{proof}
			\end{theorem}
			
		\subsection{Higher Order Derivatives}
			\begin{definition}
				A function $f$ defined on $S$ is \textbf{of class} $C^k$ if all of its $k^{th}$ order partial derivatives exists and continuous everywhere in $S$.
			\end{definition}
			
			\begin{theorem}
				Assume that $S$ is an open subset of $\R^n$ and that $f: S \to \R$ is $C^k$. Let $\alpha \in [n]^k$, and let $\beta$ be any permutation of $\alpha$,
				\begin{equation}
					\partial^{\alpha} f = \partial^{\beta} f
				\end{equation}
			\end{theorem}
			
			\begin{definition}
				A \textbf{multi-index} is an $n$-tuple of nonnegative integers. And we define
				\begin{equation}
					\partial^\alpha f := (\frac{\partial}{\partial x_1 })^{\alpha_1}(\frac{\partial}{\partial x_{2} })^{\alpha_{2}}\cdots (\frac{\partial}{\partial x_n })^{\alpha_n}f, \quad\mbox{ for }\alpha = (\alpha_1,\ldots, \alpha_n)
				\end{equation}
				where the \textbf{order} of multi-index is defined as
				\begin{equation}
					|\alpha| := \alpha_1 + \alpha_2 + \dots + \alpha_n
				\end{equation}
			\end{definition}
			
			\begin{theorem}[the Multinomial Theorem]
				\begin{equation}
					(x_1 + x_2 + \cdots + x_n)^k = \sum_{|\alpha| = k} \frac{k!}{\alpha !} \vex^\alpha
				\end{equation}
				\begin{proof}[Proof Idea]
					Prove by induction on $n$, with Binomial Theorem.
				\end{proof}
			\end{theorem}
			
			\begin{definition}
				Let $f: \R^n \to \R$ be a $C^2$ function, then its \textbf{Hessian matrix} is defined as
				\begin{equation}
					H_f := \left(\begin{array}{ccc}
					\partial_1\partial_1 f & \cdots & \partial_n\partial_1 f \\
					\vdots & \ddots & \vdots \\
					\partial_1\partial_n f & \cdots & \partial_n\partial_n f 
					\end{array}\right)
				\end{equation}
			\end{definition}
			
		\subsection{Taylor's Theorem}
			\begin{definition}
				Let $f: I \to \R$, where $I$ is an open subset of $\R$, be $C^k$. Let $a \in I$. then the \textbf{$k^{th}$ order Taylor polynomial of $f$ at $a$} is the \ul{unique} polynomial of order at most $k$, denoted $P_{a, k}(h)$ such that 
				\begin{equation}
					f^{(j)}(a) = P^{(j)}_{a, k}(0)\ \forall j \in \{0, 1, \dots, k\}
				\end{equation}
				Note 
				\begin{equation}
					P^{(j)}_{a, k}(h) = \sum_{j=0}^k \frac{h^j}{j!} f^{(j)} (a)
				\end{equation}
			\end{definition}
			
			\begin{theorem}[Taylor's Theorem in 1 Dimension]
				Assume that $I \subset \R$ is an open interval and that $f: I \to \R$ is a function of class $C^k$ on $I$. For $a \in I$ and $h \in \R$ such that $a + h \in I$. Define the \textbf{reminder} 
				\begin{equation}
					R_{a, k}(h) := f(a+h) - P_{a,k}(h)
				\end{equation} 
				Then
				\begin{equation}
					\lim_{h \to 0} \frac{R_{a, k}(h)}{h^{\red{k}}} = 0
				\end{equation}
			\end{theorem}
			
			\begin{proposition}
				Assume that $I \subset \R$ is an open interval and that $f: I \to \R$ is a function of class $C^k$ on $I$. For $a \in I$ and $h \in \R$ such that $a + h \in I$, there exists some $\theta \in (0, 1)$ such that
					\begin{equation}
						f(a+h) = f(a) + h f'(a) + \frac {h^2}{2}f''(a) + \cdots + \frac {h^{k-1}}{(k-1)!} f^{(k-1)}(a) +
						\frac {h^k}{k!} f^{(k)}(a+\theta h)
					\end{equation}
			\end{proposition}
			
			\begin{definition}
				Assume that $S \subset \R^n$ is an open interval and that $f: S \to \R$ is a function of class $C^k$ on $S$. For a point $\vea \in S$, the \textbf{$k^{th}$ order Taylor polynomial of $f: S \to \R$} is a \hl{polynomial of order at most $k$}, denoted $P_{\vea, k}(\ve{h})$ satisfying
				\begin{gather}
					f(\vea) = P_{\vea, k}(\ve{0}) \\
					\partial^\alpha f(\vea) = \partial^\alpha P_{\vea, k}(\ve{0})\ \forall \alpha\ s.t.\ |\alpha| \leq k
				\end{gather}
			\end{definition}
			
			\begin{theorem}[Taylor's Theorem in $n$ Dimensions]
				Assume that $S \subset \R^n$ is an open set and that $f: S \to \R$ is a function of class $C^k$ on $S$. For $\vea \in S$ and $\ve{h} \in \R^n$ such that $\vea + \ve{h} \in S$. Define the \textbf{reminder}
				\begin{equation}
					R_{\vea, k}(\ve{h}) := f(\vex + \ve{h}) - P_{\vea, k}(\ve{h})
				\end{equation}
				Then 
				\begin{equation}
					\lim_{\ve{h} \to \ve{0}} \frac{R_{\vea, k}(\ve{h})}{\norm{\ve{h}}^{\red{k}}} = 0
				\end{equation}
			\end{theorem}
			
			\begin{theorem}[the Quadratic Case]
				\begin{gather}
					\red{P_{\vea, 2}(\ve{h}) = f(\vea) + \nabla f(\vea) \cdot \ve{h} + \frac{1}{2} \ve{h}^T H_f(\vea) \ve{h}} \\
					\exists \theta \in (0, 1)\ s.t.\ f(\vea+\ve{h}) = f(\vea) + \nabla f(\vea) \cdot \ve{h} + \frac{1}{2} \ve{h}^T H_f(\vea + \red{\theta} \ve{h}) \ve{h} \\
					\lim_{\ve{h} \to \ve{0}} \frac{R_{\vea, 2}(\ve{h})}{\norm{\ve{h}}^2} = 0
				\end{gather}
			\end{theorem}
			
			\begin{definition}[the General Taylor's Polynomial]
				\begin{equation}
					P_{\vea, k}(\ve{h}) = \sum_{\{\alpha : |\alpha| \leq k\}}\frac {\ve{h}^\alpha}{\alpha!}{\partial^\alpha f(\vea)}
				\end{equation}
			\end{definition}
			
		\subsection{Critical Points}
			\begin{definition}
				A \hl{symmetric} $n \times n$ matrix $A$ is said to be
				\begin{itemize}
					\item \textbf{Positive definite} if $\vex^T A \vex > 0$ for all $\vex \in \R^n \backslash \{\ve{0}\}$.
					\item \textbf{Non-negative definite/Positive semi-definite} if $\vex^T A \vex \geq 0$ for all $\vex \in \R^n$.
					\item \textbf{Negative definite} if $\vex^T A \vex < 0$ for all $\vex \in \R^n \backslash \{\ve{0}\}$.
					\item \textbf{Non-positive definite/Negative semi-definite} if $\vex^T A \vex \leq 0$ for all $\vex \in \R^n$.
				\end{itemize}
				and \textbf{indefinite} otherwise.
			\end{definition}
			
			\begin{theorem}
				Assume $A$ is a symmetric matrix. Then
				\begin{align}
					A\mbox{ is positive definite }
					&\iff \mbox{ all its eigenvalues are positive }\nonumber \\
					&\iff \exists\lambda_i>0\mbox{ such that }\vex^T A\vex \geq \lambda_i \norm{\vex}^2 \mbox{ for all }\vex\in \R^n.\nonumber
				\end{align}
				and
				\begin{align}
					A\mbox{ is nonnegative definite } \iff \mbox{ all its eigenvalues are nonnegative.}
				\end{align}
				and 
				\begin{align}
					A\mbox{ is indefinite } \iff \mbox{ $A$ has both positive and negative eigenvalues.}
				\end{align}
			\end{theorem}
			
			\begin{lemma}
				Let $A$ be a symmetric matrix, then
				\begin{equation}
					\mbox{the smallest eigenvalue of }A = \min_{\{\ve{u}\in \R^n : |\ve{u}|=1\} } \ve{u}^T A\ve{u}
				\end{equation}
			\end{lemma}
			
			\begin{definition}
				A point $\vea \in S$ is a \textbf{local minimum point} for $f: S \to \R$ if 
				\begin{equation}
					\exists \varepsilon > 0\ s.t.\ \forall \vex \in \mc{B}(\varepsilon, \vea)\ f(\vea) \leq f(\vex)
				\end{equation}
			\end{definition}
			
			\begin{definition}
				A point $\vea \in S$ is a \textbf{local maximum point} for $f: S \to \R$ if 
				\begin{equation}
					\exists \varepsilon > 0\ s.t.\ \forall \vex \in \mc{B}(\varepsilon, \vea)\ f(\vea) \geq f(\vex)
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Let $f: S \to \R$ is differentiable on the open subset $S \subset \R^n$, then a point $\vea \in S$ is a \textbf{critical point} if 
				\begin{equation}
					\nabla f(\vea) = \ve{0}
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Let $\vea \in S$ be a \ul{critical point} of $f$, then $\vea$ is a \textbf{saddle point} if $H_f(\vea)$ is indefinite.
			\end{definition}
			
			\begin{theorem}[First Derivative Test]
				If $f: S \to R$ is differentiable, then 
				\begin{equation}
					\tx{local extremum} \implies \tx{critical point}
				\end{equation}
			\end{theorem}
			
			\begin{theorem}[\red{Necessary Condition for a Local Minimum}]
				If $f: S \to \R$ is $C^2$ and $\vea$ is a local minimum point for $f$, then
				\begin{enumerate}[(i)]
					\item $\vea$ is critical point of $f$;
					\item $H_f(\vea)$ is positive semi-definite.
				\end{enumerate}
			\end{theorem}
			
			\begin{theorem}[\red{Sufficient Condition for a Local Minimum}]
				If 
				\begin{enumerate}[(i)]
					\item $\vea$ is a critical point of $f$;
					\item $H_f(\vea)$ is positive definite.
				\end{enumerate}
				Then $\vea$ is a local minimum for $f$.
			\end{theorem}
			
			\begin{corollary}
				Assume $f$ is $C^2$ and $\nabla f(\vea) = \ve{0}$, then
				\begin{enumerate}[(i)]
					\item If $H_f(\vea)$ is positive definite, then $\vea$ is a local minimum;
					\item If $H_f(\vea)$ is negative definite, then $\vea$ is a local maximum;
					\item If $H_f(\vea)$ is indefinite, then $\vea$ is a saddle point.
				\end{enumerate}
				\emph{If none of the above hold, then we cannot determine the character of the critical point without further thought.}
			\end{corollary}
			
			\begin{definition}
				A critical point $\vea$ of $f$ is \textbf{degenerate} if $\det H_f(\vea) = 0$, and \textbf{non-degenerate} if $\det H_f(\vea) \neq 0$.
			\end{definition}
		
		\subsection{Optimization}
			\begin{theorem}
				Let $S \subset \R^n$ be an open set and $f, g: S \to \R$ be $C^1$ functions. If $\tbf{x}$ is a \emph{local extremal} satisfying $g(\tbf{x}) = 0$, and \red{$\nabla g(\tbf{x}) \neq 0$}, then
				\begin{equation}
					\exists \lambda \in \R\ s.t.\ \begin{cases}
						\nabla f(\tbf{x}) = \lambda \nabla g(\tbf{x}) \\
						g(\tbf{x}) = 0
					\end{cases}
				\end{equation}
			\end{theorem}
			
%			\begin{lemma}
%				$\nabla g(\tbf{x})$ is \ul{orthogonal} to the constraint set $g^{-1}(0)$.
%			\end{lemma}
			
			\begin{proposition}
				Equations (2.8.1) $\implies$ $\nabla f(\tbf{x}) \perp \{\vex \in S:g(\vex)=0\}$ at \tbf{x}.
			\end{proposition}
			
			\begin{theorem}
				Let $S \subseteq \R^n$ be an open set, and $f, \{g_i\}_{i=1}^k : S \to \R$ be $C^1$ functions. Define $\ve{g}(\ve{x}): \R^n \to \R^k := (g_1(\ve{x}), g_2(\textbf{x}), \dots, g_k(\ve{x}))$. \\
				If $\textbf{x} \in S$ is a \emph{local extremal} of $f$ such that $\textbf{g}(\textbf{x}) = \textbf{0}$, and $\{\nabla g_i(\textbf{x})\}$ are \ul{linearly independent} (i.e. $rank(D\textbf{g}(\textbf{x})) = k$), then
				\begin{equation}
					\exists \boldsymbol{\lambda} \in \R^k\ s.t.\ \begin{cases}
						\nabla f(\textbf{x}) = \boldsymbol{\lambda}^T D\textbf{g}(\textbf{x}) \\
						\textbf{g}(\textbf{x}) =\textbf{0}
					\end{cases}
				\end{equation}
			\end{theorem}
			
			\begin{remark}Procedure of optimization on \emph{open sets}:
				\begin{enumerate}[(i)]
					\item Find all critical points;
					\item Find optimizers (classify them) among critical points.
				\end{enumerate}
			\end{remark}
			
			\begin{remark}Procedure of optimization with \emph{inequality constraints}:
				\begin{enumerate}[(i)]
					\item Find critical points \emph{in} the constraint set;
					\item Find critical points \emph{on} the boundary of constraint set;
					\item Find optimizers among candidates.
				\end{enumerate}
			\end{remark}
	
	\section{The Implicit and Inverse Function Theorems}
		\subsection{The Implicit Function Theorem I}
			\begin{theorem}[Implicit Function Theorem]
				Let $S \subseteq \R^{n+k}$ be an open set, and function $F: S \to \R^k$ be a $C^1$ function. Suppose there exists point $\textbf{a} \in \R^n, \ve{b} \in \R^k$ such that 
				\begin{equation}
					F(\textbf{a}, \textbf{b}) = \textbf{0}
				\end{equation}
				If 
				\begin{equation}
					det(D_{\textbf{y}}(F(\textbf{a}, \textbf{b}))) \neq 0
				\end{equation}
				then there exists $r_0, r_1 > 0$ and a $C^1$ function $\ve{f}: \R^n \to \R^k$ such that
				\begin{gather}
					\forall \ve{x} \in \mc{B}(r_0, \ve{a}),\ \ve{f}(\ve{x}) \in \mc{B}(r_1, \ve{b}) \land F(\ve{x}, \ve{f}(\ve{x})) = \ve{0}
				\end{gather}
				and define $\textbf{y} := \textbf{f}(\textbf{x})$, the derivative of $\textbf{f}$ can be found as
				\begin{equation}
					\red{D\textbf{f}(\textbf{x}) = -[D_{\textbf{y}}F(\textbf{x}, \textbf{y})]^{-1} D_{\textbf{x}}F(\textbf{x}, \textbf{y})}
				\end{equation}
			\end{theorem}
			\begin{remark}
				Procedure to prove solvability of non-linear equations
				\begin{equation}
					\ve{F}(\ve{x}, \ve{y}) = \ve{0}
				\end{equation}
				near $(\ve{a}, \ve{b})$.
				\begin{enumerate}[(i)]
					\item Verify $\ve{F}(\ve{a}, \ve{b}) = \ve{0}$.
					\item Assert
					\begin{equation}
						det(D_\ve{y}\ve{F}(\ve{a}, \ve{b})) \neq 0
					\end{equation}
					\item Approximate solution $\ve{y} = \ve{f}(\ve{x})$ using 
					\begin{gather}
						\ve{f}(\ve{x} + \ve{h}) \approx \ve{a} + D\ve{f}(\ve{a}) \ve{h} \\
						= \ve{a}
						- [D_\ve{y} \ve{F}(\ve{a}, \ve{b})]^{-1}
						D_\ve{x} \ve{F}(\ve{a}, \ve{b}) \ve{h}
					\end{gather}
				\end{enumerate}
			\end{remark}
		\subsection{Geometric Content of the Implicit Function Theorem}
			\begin{definition}
				Let $S \subseteq \R^n$ and $\ve{a} \in S$. $S$ is \textbf{singular} at $\ve{a}$ if 
				\begin{equation}
					\forall r > 0\ S \cap \mc{B}(r, \ve{a}) \tx{ cannot be represented as a $C^1$ graph.}
				\end{equation}
				$S$ is \textbf{regular} at $\ve{a}$ is its not singular there.
			\end{definition}
			
			\begin{theorem}[$k$ dimensional manifold as level set]
				Let $U \subseteq \R^n$ and let $\ve{F}: U \to \R^{n-k}$ be a $C^1$ function.
				\begin{equation}
					S := \{\vex \in U: \ve{F}(\vex) = \ve{0}\}
				\end{equation}
				Let $\ve{a} \in U$, if 
				\begin{equation}
					rank(D\ve{F}(\ve{a})) = n - k
				\end{equation}
				then $\exists r > 0$ such that the \emph{level set of $\ve{F}$ near $\ve{a}$}
				\begin{equation}
					\mc{B}(r, \ve{a}) \cap S
				\end{equation}
				can be represented as a $C^1$ graph.
			\end{theorem}
			
			\begin{remark}[Interpretation]
				In $\R^n$, there are $n$ degree of freedom before imposing any constraint, after add a constraint $\veF(\vex) = \ve{0}$ with $n-k$ effective constraints, there are $k$ degree of freedom left. What's left is a $k$ dimensional manifold.
			\end{remark}
			
			\begin{theorem}[$k$ dimensional manifold as parameterization]
				Let $T \subseteq \R^k$ and let $\ve{f}: U \to \R^n$ be a $C^1$ function.
				\begin{equation}
					S := \ve{f}(T)
				\end{equation}
				Let $\ve{t} \in T$, if
				\begin{equation}
					rank(D\ve{f}(\ve{t})) = k
				\end{equation}
				then $\exists r > 0$ such that the \ul{parameterization of $\ve{f}$ near $\ve{t}$}
				\begin{equation}
					\ve{f}(T \cap \mc{B}(r, \ve{t}))
				\end{equation}
				can be represented as a $C^1$ graph.
			\end{theorem}
		\subsection{Transformations, and the Inverse Function Theorem}
			\begin{example}[Polar coordinate in $\R^2$]
				Let
				\begin{gather}
					U := \{(r, \theta): r > 0 \land \theta \in (-\pi, \pi)\} \\
					V := \R^2 \backslash \{(x,0): x \leq 0\}
				\end{gather}
				Define $\ve{f}: U \to V$ as
				\begin{equation}
					\ve{f}(r, \theta) := \begin{pmatrix}
 						r\cos(\theta) \\
 						r\sin(\theta)
 					\end{pmatrix}
				\end{equation}
			\end{example}
			
			\begin{example}[Spherical coordinate in $\R^3$]
				Define
				\begin{equation}
					\ve{f}(r, \theta, \varphi) = \begin{pmatrix}
						r \cos(\theta) \sin(\varphi) \\
						r \sin(\theta) \sin(\varphi) \\
						r\cos(\varphi)
					\end{pmatrix}
				\end{equation}
			\end{example}
			
			\begin{example}[Cylindrical coordinate in $\R^3$]
				Define
				\begin{equation}
					\ve{f}(r, \theta, z) = \begin{pmatrix}
						r \cos(\theta) \\
						r \sin(\theta) \\
						z
					\end{pmatrix}
				\end{equation}
			\end{example}
			
			\begin{theorem}[Inverse Function Theorem]
				Let $U$ and $V$ be open subsets in $\R^n$, and $\ve{f}: U \to V$. Let $\ve{a} \in U$ and define $\ve{b} := \ve{f}(\ve{a}) \in V$. If
				\begin{equation}
					det(D\ve{f}(\ve{a})) \neq 0
				\end{equation}
				then there exists $M \subseteq U$ and $N \subseteq V$ such that
				\begin{enumerate}[(i)]
					\item $\ve{a} \in M$ and $\ve{b} \in N$,
					\item $\ve{f}$ is bijective between $M$ and $N$,
					\item $\ve{f}^{-1}: N \to M$ is $C^1$,
				\end{enumerate}
					and \red{for all $\ve{x} \in M$} such $\ve{y} := \ve{f}(\ve{x}) \in N$,
					\begin{equation}
						D \ve{f}^{-1} (\ve{y}) = [D \ve{f} (\ve{x})]^{-1}
					\end{equation}
			\end{theorem}
	
	\section{Integration}
		\subsection{Basics}
			\begin{theorem}[\red{Properties of infimum and supremum}]
				Let $A \subseteq \R^n$ and $A \neq \emptyset$, and $f, g: A \to \R$ are bounded functions. Let $m$ and $M$ denote the infimum and supremum respectively, then
				\begin{enumerate}[(i)]
					\item $m_A f + m_A g \leq m_A (f+g) \leq M_A (f+g) \leq M_A f + M_A g$
					\item If $A' \subseteq A$, then $m_A f \leq m_{A'} f \leq M_{A'} f\leq M_A f$
					\item If $f(\ve{x}) \leq g(\ve{x})\ \forall \ve{x} \in A$, then $m_A f \leq m_A g$ and $M_A f \leq M_A g$
					\item $|M_A f| \leq M_A |f|$
					\item $M_A |f| - m_A |f| \leq M_A f - m_A f$
					\item $\forall c \in \R$, $M_A (cf) - m_A (cf) = |c| (M_A f - m_A f)$
					\item $M_A f - m_A f = sup\{f(x) - f(y): x, y \in A\}$
				\end{enumerate}
			\end{theorem}
			
		\subsection{Integration on Higher Dimensions}
			\begin{definition}
				A \textbf{rectangle} $\mc{R} \subseteq \R^n$ (\textbf{$n$-orthotope}) is defined as
				\begin{equation}
					\mc{R} := \prod_{i=1}^n [a_i, b_i]
				\end{equation}
				where $a_i, b_i \in \R$ and $a_i < b_i$.
			\end{definition}
			
			\begin{definition}
				A \textbf{partition} $P$ of rectangle $\mc{R} = \prod_{i=1}^n [a_i, b_i]$ is a list of $n$ \red{finite} and increasing list of real numbers
				\begin{equation}
					P = \{L_1, L_2, \dots, L_n\}
				\end{equation}
				where $L_i = \{e_j\}_{j=0}^{T_i}$ such that
				\begin{equation}
					a_i = e_0 < e_1 < \cdots < e_{T_i} = b_i
				\end{equation}
				and such partition generates a set of rectangles(boxes) $\mc{B}(P) := \{B_j\}_{j=1}^J \subseteq \mc{R}$.
			\end{definition}
			
			\begin{definition}
				Let $P$ and $P'$ be two partitions of $\mc{R}$. Then $P'$ is a \textbf{refinement} of $P$ if 
				\begin{equation}
					\forall B_j \in \mc{B}(P), B_j' \in \mc{B}(P')\quad B_j' \subseteq B_j \lor (B_j^{' int} \cap B_j^{int} = \emptyset)
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Define the \textbf{volume} of rectangle $\mc{R} = \prod_{i=1}^n [a_i, b_i]$ as
				\begin{equation}
					V^n(\mc{R}) := \prod_{i=1}^n (b_i - a_i)
				\end{equation}
			\end{definition}
			
			\begin{definition}
				The \textbf{lower Riemann sum} of $f$ with partition $P$ on $\mc{R}$ is defined as
				\begin{equation}
					L_P f := \sum_{B_j \in \mc{B}(P)} \inf_{\ve{x} \in B_j} f(\ve{x}) V^n(B_j)
				\end{equation}
				and the \textbf{upper Riemann sum} is defined as
				\begin{equation}
					U_P f := \sum_{B_j \in \mc{B}(P)} \sup_{\ve{x} \in B_j} f(\ve{x}) V^n(B_j)
				\end{equation}
			\end{definition}
			
			\begin{definition}
				The \textbf{upper integral} and \textbf{lower integral} of $f$ on $\mc{R}$ are defined as
				\begin{gather}
					\bar{I}_{\mc{R}} f := \inf_{P} U_P f \\
					\underline{I}_{\mc{R}} f := \sup_{P} L_P f
				\end{gather}
			\end{definition}
			
			\begin{definition}
				A bounded real-valued function $f$ defined on $\mc{R}$ is \textbf{integrable} if
				\begin{equation}
					\underline{I}_{\mc{R}} f = \bar{I}_{\mc{R}} f
				\end{equation}
				and the integral is defined as
				\begin{equation}
					\int \cdots \int_\mc{R} f\ dV^n := \underline{I}_{\mc{R}} f = \bar{I}_{\mc{R}} f
				\end{equation}
			\end{definition}
			
			\begin{lemma}
				Let $f$ be a bounded real-valued function defined on $\mc{R}$, $f$ is integrable if and only if $\forall \epsilon > 0$, there exists a partition $P$ of $\mc{R}$ such that
				\begin{equation}
					\red{U_P f - L_P f < \epsilon}
				\end{equation}
			\end{lemma}
			
			\begin{theorem}
				Let $f$ and $g$ be two integrable functions on $\mc{R} \subseteq \R^n$, let $c \in \R$, 
				\begin{enumerate}[(i)]
					\item $f+g:\mc{R} \to \R$ is integrable and $\int_\mc{R} (f+g) = \int_\mc{R} f + \int_\mc{R} g$
					\item $c \cdot f$ is integrable and $\int_\mc{R} c \cdot f = c \int_\mc{R} f$
					\item $f(\ve{x}) \geq g(\ve{x})\ \forall \ve{x} \in \mc{R} \implies \int_\mc{R} f \geq \int_\mc{R} g$
					\item $|f|$ is integrable and $|\int_{R} f| \leq \int_{R} |f|$
				\end{enumerate}
			\end{theorem}
			
			\begin{definition}
				Let $S \subseteq \R^n$ be a bounded set, and there exists rectangle $\mc{R}$ covers $S$, the \textbf{indicator function} of $S$ is $\chi_S: \mc{R} \to \{0, 1\}$, defined as
				\begin{equation}
					\chi_S (\ve{x}) := \id{\ve{x} \in S}
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Let $S \subseteq \R^n$ be a bounded set, and there exists rectangle $\mc{R}$ covers $S$. Let $f: \mc{R} \to \R$ be a bounded function, then $f$ is \textbf{integrable on $S$} if $\chi_S f$ is integrable on $\mc{R}$. And
				\begin{equation}
					\int \cdots \int_S f\ dV^n := \int \cdots \int_\mc{R} \chi_S f\ dV^n
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Let $Z \subseteq \R^n$, $Z$ has \textbf{zero content} if for all $\epsilon > 0$, there exists a \ul{finite} set of rectangles $\{R_\ell\}_{\ell=1}^L$ covers $Z$ and
				\begin{equation}
					\sum_{\ell=1}^L V^n (R_\ell) < \epsilon
				\end{equation}
			\end{definition}
			
			\begin{definition}
				A set $S \subset \R^n$ is \textbf{Jordan measurable} if it is \ul{bounded} and its \ul{boundary has zero content}.
			\end{definition}
			
			\begin{proposition}
				Let $Z \subseteq \R^n$ has zero content, then
				\begin{enumerate}[(i)]
					\item For any $Z' \subseteq Z$, $Z'$ has zero content.
					\item \ul{Finite} union of content zero sets has zero content.
					\item \red{Let $f: [a, b] \to \R$ be an \ul{integrable} function, its graph $\{(x, f(x)): x \in [a, b]\}$ has zero content.}
					\item \red{Let $\ve{f}: [a, b] \to \R^2$ be a $C^1$ function, the parameterization $\ve{f}([a,b])$ has zero content.}
				\end{enumerate}
			\end{proposition}
			
			\begin{theorem}
				Let $\mc{R}$ be a rectangle in $\R^n$ and $f$ is integrable on $\mc{R}$ if the set
				\begin{equation}
					\{\ve{x} \in \mc{R}: f \tx{ is discontinuous at \ve{x}}\}
				\end{equation}
				has zero content.
			\end{theorem}
			
			\begin{proposition}[Folland 4.22]
				Suppose $Z \subseteq \R^n$ has zero content. If $f: \R^n \to \R$ is bounded, then $f$ is integrable on $Z$ and $\int_Z f\ dV^n = 0$.
			\end{proposition}
			
			\begin{remark}[Measures and Contents]
				A measure $\mu$ is required to be \emph{countably} additivity on disjoint sets, but a content only requires \emph{finite} additivity on disjoint sets. Therefore, if a set has content zero based on some content function, such a content function is also a measure function, thus such set has measure zero as well.
				\begin{equation}
					\tx{content zero } \implies \tx{ measure zero}
				\end{equation}
			\end{remark}
			
		\subsection{Iterated Integrals}
			\begin{theorem}[Fubini's Theorem]
				Let $\mc{R} = [a,b] \times [c,d] \subseteq \R^2$ and $f: \mc{R} \to \R$ is bounded. Assuming that
				\begin{enumerate}[(i)]
					\item $f$ is integrable on $\mc{R}$.
					\item for each $y \in [c,d]$, the function $f_y(x) := f(x,y)$ is integrable on $[a,b]$.
					\item Define $g(y) := \int_a^b f(x, y) dy$ is integrable on $[c,d]$.
				\end{enumerate}
				Then 
				\begin{equation}
					\iint_\mc{R} f\ dA = \int_c^d \Big ( \int_a^b f(x,y)\ dx\Big)dy
				\end{equation}
			\end{theorem}
		
		\begin{proposition}
			Let $S \subseteq \R^n$ be an unbounded set, and $f: S \to \R$.
			Then improper integral $\idotsint_{S} f\ d^n \ve{x}$ is absolutely convergent on $\R^n$ \ul{if and only if} $\idotsint_{\R^n} \chi_S f\ d^n \ve{x}$ is absolutely convergent.
		\end{proposition}
	
		\subsection{Change of Variables}
			\begin{theorem}[Change of Variable]
				Let $U$ and $V$ be two open subsets of $\R^n$, and let $\ve{G}: U \to V$ be a $C^1$ bijection. Let $T \subset U$ and $S \subset V$. Suppose $\ve{G}(T) = S$, then
				\begin{equation}
					\underbrace{\int \cdots \int_S f\ d\Omega}_{\tx{Target Intergal}} = \int \cdots \int_{T\equiv \veG^{-1}(S)} f\circ\ve{G}\ |\tx{det}D\ve{G}|\ d\Theta
				\end{equation}
			\end{theorem}
			
			\begin{corollary}
				Let $S$ be a region in $\R^n$, suppose $S$ can be parameterized by $\ve{G}: T \to S$. By the change of variable formula, consider the special case $f(\ve{x})=1$, 
				\begin{equation}
					|S| = \int \cdots \int_S 1\ d\Omega = \int \cdots \int_T 1\ |\tx{det }D\ve{G}(\ve{u})|\ d\Theta
				\end{equation}
			\end{corollary}
			
			\begin{example}[Polar Coordinate]
				Define the coordinate transformation mapping from polar to Cartesian,
				\begin{equation}
					\ve{P}(r, \theta) := (x, y) = 
					\begin{pmatrix}
						r \cos{\theta} \\
						r \sin{\theta}
					\end{pmatrix},\ \theta \in [0, 2\pi]\ r \in \R_{+}
				\end{equation}
				and $|\tx{det }D\ve{P}(r, \theta)| = r$.
			\end{example}
			
			\begin{example}[Cylindrical Coordinate]
				Define the coordinate transformation mapping from cylindrical to Cartesian as
				\begin{equation}
					\ve{C}(r, \theta, z) := (x, y, z) = 
					\begin{pmatrix}
						r \cos{\theta} \\
						r \sin{\theta} \\
						z
					\end{pmatrix},\ \theta \in [0, 2\pi]\ r \in \R_{+}\ z \in \R
				\end{equation}
				and $|\tx{det }D\ve{C}(r, \theta, z)| = r$.
			\end{example}
			
			\begin{example}[Spherical Coordinate]
				Define the coordinate transformation mapping from spherical to Cartesian as
				\begin{equation}
					\ve{S}(r, \theta, \varphi) = 
					\begin{pmatrix}
						r \cos{\theta} \sin{\varphi} \\
						r \sin{\theta} \sin{\varphi} \\
						r \cos{\varphi}
					\end{pmatrix}
				\end{equation}
				and $|\tx{det }D\ve{S}(r, \theta, \varphi)| = \red{r^2 \sin{\varphi}}$
			\end{example}
	
		\subsection{Further Aspects}
			\subsubsection{Exchanging Differentiation and Integration}
			
			\begin{theorem}[\red{Exchanging Differentiation and Integration}]
				Let $f(\ve{x}, \ve{t}): S \times T \to \R$ and define $F(\ve{x}): S \to \R$ as 
				\begin{equation}
					F(\ve{x}) := \int \cdots \int_T f(\ve{x}, \ve{t})\ d\ve{t}
				\end{equation}
				If
				\begin{enumerate}[(i)]
					\item $S$ is open and $T$ is compact;
					\item $f$ and $F$ are continuous;
					\item and $\forall\ x_j \in \ve{x}$, $\pd{f(\ve{x}, \ve{t})}{x_j}$ is continuous,
				\end{enumerate}
				then $F$ is $C^1$ in $S$ and for every $j$,
				\begin{equation}
					\pd{F(\ve{x})}{x_j} = \idotsint_T \pd{f(\ve{x}, \ve{t})}{x_j}\ d\ve{t}
				\end{equation}
			\end{theorem}
	
			\begin{corollary}[\red{Exchanging Limits and Integration}]
				By the definition of partial derivative, above theorem is equivalent to 
				\begin{equation}
					\lim_{h \to 0} \idotsint_T \frac{f(\ve{x} + h \ve{e}_j, \ve{t})}{h}\ d\ve{t} = \idotsint_T \lim_{h \to 0} \frac{f(\ve{x} + h \ve{e}_j, \ve{t})}{h}\ d\ve{t}
				\end{equation}
			\end{corollary}
			
			\subsubsection{Improper Integrals}
				\begin{definition}[Unbounded Domains]
					An \textbf{improper integral} with unbounded domain $\idotsint_{\R^n} f\ d\Omega$ is \textbf{absolutely convergent} if there exists $L \in \R$ such that
					\begin{equation}
						\forall \varepsilon > 0\ \exists R > 0\ s.t.\ \forall S \subseteq \R^n\ \mc{B}(R, \ve{0}) \subset S \implies \Big|\idotsint_S f\ d\Omega - L \Big| < \varepsilon
					\end{equation}
				\end{definition}
				
				\begin{theorem}
					Let $f: \R^n \to \R$ be a continuous function, and that 
					\begin{equation}
						\lim_{R \to \infty} \idotsint_{\mc{B}(R, \ve{0})}\red{|}f\red{|}\ d\Omega \tx{ exists}
					\end{equation}
					then $\idotsint_{\R^n}f\ d\Omega$ is absolutely convergent.
				\end{theorem}
				
				\begin{corollary}[Equivalence]
					Above improper integral $\idotsint_{\R^n}f\ d\Omega$ is absolutely convergent if set
					\begin{equation}
						\{\idotsint_{\mc{B}(R, \ve{0})}\red{|}f\red{|}\ d\Omega: R \in \R_{++}\}
					\end{equation}
					is bounded.
				\end{corollary}
				
				\begin{corollary}
					Let $f: \R^n \to \R$ be an continuous function, if 
					\begin{equation}
						\exists p > n,\ C > 0\ s.t.\ |f(\ve{x})| \leq \frac{1}{\norm{\ve{x}}^p}\ \forall \ve{x} \in \R^n
					\end{equation}
					then $\idotsint_{\R^n}f\ d\Omega$ is absolutely convergent.
				\end{corollary}
	
				\begin{definition}[Unbounded Function]
					Let $S \subset \R^n$, $\ve{a} \in \R^n$. Consider a function $f: S \backslash \{\ve{a}\} \to \R$. Then the improper integral $\idotsint_{\red{S}}f d\Omega$ is absolutely convergent if 
					\begin{equation}
						\exists L \in \R\ s.t\ \forall \varepsilon > 0\ \exists r > 0\ s.t.\ \forall U \subset S\ s.t.\ \ve{a} \in U^{\red{int}} \land U \subset \mc{B}(r, \ve{a}),\ \Big|
							\idotsint_{S \backslash U}f\ d\Omega - L
						\Big| < \varepsilon
					\end{equation}
				\end{definition}
				
				\begin{theorem}
					Let $f: S\backslash \{\ve{a}\} \to \R$, if
					\begin{equation}
						\lim_{r\to 0}\idotsint_{S \backslash \mc{B}(r, \ve{a})}\red{|}f\red{|}\ d\Omega \tx{ exists}
					\end{equation}
					then $\idotsint_S f\ d\Omega$ is absolutely convergent.
				\end{theorem}
				
				\begin{corollary}[Equivalence]
					If the set
					\begin{equation}
						\{\iint_{S \backslash \mc{B}(r, \ve{a})} \red{|}f\red{|}\ d\Omega: r \in \R_{++}\}
					\end{equation}
					is bounded, then $\idotsint_S f\ d\Omega$ is absolutely convergent.
				\end{corollary}
				
				\begin{corollary}
					Let $f: S\backslash \{\ve{a}\} \to \R$, if 
					\begin{equation}
						\exists p < n,\ C > 0\ s.t. |f(\ve{x})| \leq \frac{C}{\norm{\ve{x} - \ve{a}}^p}\ \forall \ve{x} \in S \red{\backslash \{\ve{a}\}}
					\end{equation}
					then the improper integral $\idotsint_S f\ d\Omega$ is absolutely convergent.
				\end{corollary}
				
	\section{Vector Calculus}
		\subsection{Line Integrals}
		\subsubsection{Arc Length}
			\begin{definition}
				Let $C$ be a smooth curve in $\R^n$ parameterized by $C^1$ function $\ve{g}$ such that $\ve{g}'(t) \neq \ve{0}$ for every appropriate $t$.
				\begin{equation}
					C := \{\ve{g}(t): t \in [a, b]\}
				\end{equation}
				and the \textbf{arc length} of $C$ is defined as
				\begin{gather}
					\int_C d^n\ve{x} := \int_C ds := \int_a^b \norm{\ve{g}'(t)}\ dt
				\end{gather}
			\end{definition}
			
			\begin{proposition}
				The arc length of a curve $C$ is an intrinsic property of the geometric object $C$ and should not depend on the particular parameterization we use.
				\begin{proof}
					Let $\varphi:[c,d] \to [a,b]$ be a bijection, so that $\ve{h} := \ve{g} \circ \varphi$ is also a valid parameterization of $C$ such that
					\begin{equation}
						C := \{\ve{h}(u): u \in [c, d]\}
					\end{equation}
					The arc length of $C$ can be computed using
					\begin{align}
						\int_C ds &= \int_c^d \norm{\ve{h}'(u)}\ du \\
						&= \int_c^d \norm{\ve{g}'(\varphi(u))} \cdot \abs{\varphi'(u)}\ du \\
						&= \int_a^b \norm{\ve{g}'(t)}\ dt \tx{ by change of variable formula.}
					\end{align}
				\end{proof}
			\end{proposition}
			
			\begin{remark}[Interpretations]Suppose $\ve{g}$ is a parameterization of $C$.
				\begin{enumerate}[(i)]
					\item $\int_a^b \ve{g}'(t)\ dt = \ve{g}(b) - \ve{g}(a)$ measures the distance between two endpoints of $C$. 
					\item Choosing a parameterization is effectively choosing an \textbf{orientation} for the curve $C$.
				\end{enumerate}
			\end{remark}
			
			\begin{definition}
				A function $\ve{g}: [a, b] \to \R^n$ is called \textbf{piecewise smooth} if 
				\begin{enumerate}[(i)]
					\item it's \emph{continuous}, and 
					\item it's derivate exists and is continuous except at finitely many points $t_j$, at which the \ul{one-sided limits exist}.
				\end{enumerate}
			\end{definition}
		
		\subsubsection{Line Integrals of Scalar Functions}
			\begin{definition} Let smooth curve $C \subseteq \R^n$, $f: C \to \R$ and $\ve{g}$ be a parameterization of $C$, then 
				\begin{equation}
					\int_C f\ ds = \int_a^b f(\ve{g}(t))\ \norm{\ve{g}'(t)}\ dt
				\end{equation}
			\end{definition}
			
			\begin{remark}
				The line integrals of scalar functions are also independent from the choices of parameterizations.
			\end{remark}
			
			\begin{definition}
				\begin{equation}
					\tx{Average of $f$ over $C$} := \frac{\int_C f\ ds}{\int_C\ ds}
				\end{equation}
			\end{definition}
			
		\subsubsection{Line Integrals of Vector Fields}
			\begin{definition} Let smooth $C \in \R^n$ with parameterization $\ve{g}$ and $\ve{F}: C \to \R^n$ defined on it, the \textbf{line integral} of $\ve{F}$ over $C$ is defined as 
				\begin{equation}
					\int_C \ve{F}\cdot d\ve{x} = \int_a^b \ve{F}(\ve{g}(t)) \cdot \ve{g}'(t)\ dt
				\end{equation}
			\end{definition}
			
			\begin{proposition}
				The line integral $\int_C \ve{F}\cdot d\ve{x}$ is independent of the parameterization \emph{as long as the orientation is unchanged}.
			\end{proposition}
			
			\begin{theorem}[The Fundamental Theorem of Line Integral]
				Let $f: C \to \R$ defined on smooth curve $C$ parameterized by $\ve{g}:[a, b] \to \R^n$, then
				\begin{equation}
					\int_C \nabla f(\ve{x}) \cdot d^n\ve{x} = f(\ve{g}(b)) - f(\ve{g}(a))
				\end{equation}
				\begin{proof}
					\begin{gather}
						\int_C \nabla f(\ve{x}) \cdot d^n\ve{x} 
						= \int_a^b \pd{f(\ve{g}(t))}{\ve{g}(t)} \cdot \ve{g}'(t)\ dt \\
						= \int_a^b \pd{f(\ve{g}(t))}{t}\ dt
						= f(\ve{g}(b)) - f(\ve{g}(a))
					\end{gather}
				\end{proof}
			\end{theorem}
			
		\subsubsection{Rectifiable Curves}
			\begin{remark}
				Let $C$ be a curve in $\R^n$ parameterized by injection $\ve{g}: [a, b] \to \R^n$ such that $\ve{g}'(t) \neq \ve{0}$. Let $P$ be a partition of $[a, b]$. Denote
				\begin{equation}
					L_P(C) := \sum_{j} \norm{\ve{g}(t_j) - \ve{g}(t_{j-1})}
				\end{equation}
			\end{remark}
			
			\begin{definition}
				A curve $C$ is \textbf{rectifiable} if the set $\{L_P(C):P\}$ is \ul{bounded}. And the arc length of $C$ s defined as 
				\begin{equation}
					L(C) := \sup \{L_P(C):P\}
				\end{equation}
			\end{definition}
			
			\begin{theorem}
				The supremum found above, $L(C)$ is the precisely the arc length of $C$:
				\begin{equation}
					L(C) = \int_a^b ||\ve{g}'(t)||\ dt
				\end{equation}
			\end{theorem}
		
		\subsection{Green's Theorem}
			\subsubsection{Preliminary Definitions}
				\begin{definition}
					A \textbf{simple closed curve} is a curve with parameterization $\ve{g}: [a, b] \to \R^n$ where
					\begin{enumerate}[(i)]
						\item $\ve{g}$ is continuous;
						\item $\ve{g}(a) = \ve{g}(b)$;
						\item $\ve{g}$ is injective with its domain restricted to $(a, b)$ (so the curve does not cross).
					\end{enumerate}
				\end{definition}
				
				\begin{definition}
					A \emph{simple closed curve} is \textbf{piecewise smooth} if it has a parameterization $\ve{g}$ such that
					\begin{enumerate}[(i)]
						\item $\ve{g}$ is continuously differentiable with $\ve{g}'(t) \neq \ve{0}$ except finitely many breakpoints;
						\item $\ve{g}'(t)$ is \emph{one side continuous} at breakpoints of the curve.
					\end{enumerate}
				\end{definition}
				
				\begin{definition}
					A \textbf{regular region} $S \subseteq \R^n$ is a set satisfying both
					\begin{enumerate}[(i)]
						\item $S$ is compact;
						\item $\overline{S^{int}} = S$.
					\end{enumerate}
				\end{definition}
				
				\begin{definition}
					Let $S \subseteq \R^2$, $S$ has \textbf{piecewise smooth boundary} if $\partial S$ consists of one or more \emph{disjoint, piecewise smooth, simple closed curve}.
				\end{definition}
				
				\begin{definition}
					Let $S \subseteq \R^2$, then \textbf{positive orientation} on $\partial S$ is the orientation on each of the closed curves that make up the boundary such that the region is on the \emph{left} with respect to the positive direction on the curve.
				\end{definition}
				
				\begin{theorem}[Green's Theorem]
					Suppose $S \subseteq \R^2$ is a regular region with piecewise smooth region $\partial S$. Suppose $\ve{F}$ is a $C^1$ vector field defined on $\overline{S}$, then
					\begin{equation}
						\int_{\partial S} \ve{F}\cdot d\ve{x} = \iint_S \Big(\pd{F_2}{x_1} - \pd{F_1}{x_2}\Big)\ dA
					\end{equation}
				\end{theorem}
				
				\begin{corollary}
					Suppose $S$ is a regular region in $\R^2$ with piecewise smooth boundary $\partial S$, and let $\ve{n}(\ve{x})$ be the \emph{unit outward normal} vector to $\partial S$ at $\ve{x} \in \partial S$. Suppose also that $\ve{F}$ is a vector field defined on $\overline{S}$, then
					\begin{equation}
						\int_{\partial S} \ve{F} \cdot \ve{n}\ ds = \iint_S \Big(\pd{F_1}{x_1}  + \pd{F_2}{x_2}\Big)\ dA
					\end{equation}
						\begin{proof}
							Let $\ve{g}(t)$ be a parameterization of boundary $\partial S$. Then the tangent vector would be $\ve{g}'(t)$ and we can conclude the \emph{outer normal vector} $\ve{n}$ is $\frac{(g'_2(t), -g'_1(t))}{||(g'_2(t), - g'_1(t))||}$. Then 
							\begin{gather}
								\int_{\partial S}\ve{F} \cdot \ve{n}\ ds = \int_{T}\ve{F}\circ \ve{g} \cdot \frac{(g'_2(t), -g'_1(t))}{||(g'_2(t), -g'_1(t))||} ||\ve{g}'(t)||\ dt \\
								=  \int_T F_1 g'_2(t) - F_2 g'_1(t)\ dt \\
								= \int_T \begin{pmatrix}-F_2 \\F_1 \end{pmatrix} \cdot \begin{pmatrix} g'_1(t) \\ g'_2(t) \end{pmatrix}\ dt \\
								= \int_{\partial S} \begin{pmatrix}-F_2 \\F_1 \end{pmatrix} \cdot\ d^2\ve{x} \\
								= \iint_{S} \pd{F_1}{x} + \pd{F_2}{y}\ dA \tx{ By Green's Theorem}
							\end{gather}
						\end{proof}
				\end{corollary}
		\subsection{Surface Integrals}
			\subsubsection{Surface Areas and Surface Integrals}
				\begin{definition}
					Suppose $S$ is a surface in $\R^3$ and parameterized by
					\begin{equation}
						\ve{G}(\ve{u}): R \to S
					\end{equation}
					where $rank(D\ve{G}(\ve{u}))=2$ for every $\ve{u} \in R \backslash Z$ where $Z$ is a probably empty set with zero content. If $\norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}$ is integrable, then
					\begin{equation}
						Area(S) := \iint_{\red{R}} \norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}\ d\Theta
					\end{equation}
				\end{definition}
				
				\begin{definition}
					Let $f: S \to \R$ be a real-valued continuous function defined on a super set of $S$, the \textbf{integral of a real-valued function on a surface} is defined as
					\begin{equation}
						\iint_{S}f(\ve{x})\ dA 
						:= \iint_{\red{R}} f(\ve{G}(\ve{u}))\norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}\ d\Theta
					\end{equation}
				\end{definition}
				
				\begin{definition}
					Let $\ve{F}: S \to \R^3$ be a continuous vector field defined on a super set of $S$, the \textbf{integral of vector field on a surface} is defined as
					\begin{equation}
						\iint_{S}\ve{F}(\ve{x}) \cdot \ve{n}\ dA
						:= \iint_{\red{R}} \ve{F}(\ve{G}(\ve{u}))\cdot (\pd{\ve{G}}{u} \times \pd{\ve{G}}{v})\ d\Theta
					\end{equation} 
				\end{definition}
				
				\begin{remark}
					Surface integrals of \hl{real-valued functions} are independent of the choice of parametrization.
				\end{remark}
				
				\begin{remark}
					But the choice of parameterization can change the sign of surface integrals of \hl{vector fields}. We need to \hl{choose the direction of the normal, $\ve{n}$}.
				\end{remark}
				
				\begin{definition}
					Let $S \subseteq \R^3$ be a two dimensional sub-manifold, and $f$ is a real-valued function defined on a super set of $S$. Define the \textbf{average of $f$ over $S$} as
					\begin{equation}
						\tx{aver of $f$ over $S$} := \frac{\iint_S f\ dA}{\iint_S1\ dA}
					\end{equation}
				\end{definition}
				
				\begin{remark}
					A note on the relation between integrals of a vector field and a real-valued function. The surface of vector field $\ve{F}$ on $S$ is defined by \emph{reducing $\ve{F}$ to a real-valued function $\ve{F}\cdot \ve{n}$} and then follow the definition of conventional real-valued function on $S$. Define $h := \ve{F} \cdot \ve{n}$,
					\begin{align}
						\iint_S \ve{F} \cdot \ve{n}\ dA &= \iint_S h\ dA \\
						&:= \iint_R h(\ve{G}(\ve{u})) \norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}\ d\Theta \\
						&= \iint_R \ve{F}(\ve{G}(\ve{u})) \cdot \ve{n}(\ve{G}(\ve{u})) \norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}\ d\Theta \\
						&= \iint_R \ve{F}(\ve{G}(\ve{u})) \cdot \frac{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}{\norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}} \norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}\ d\Theta \\
						&= \iint_R \ve{F}(\ve{G}(\ve{u})) \cdot (\pd{\ve{G}}{u} \times \pd{\ve{G}}{v})\ d\Theta
					\end{align}
					where $\veG: R \to S$ is a parameterization of $S$.
				\end{remark}
			\subsubsection{An invariance property}
				\begin{remark}
					As mentioned above, given $\ve{n}(\ve{x})$ fixed, we can define the surface integral of \ul{vector field} as the surface integral of a \ul{real-valued function} defined as $h(\ve{x}) := \ve{F}(\ve{x}) \cdot \ve{n}(\ve{x})$. And as argued before, one $\ve{n}$ is fixed (i.e. orientation is fixed), the value of integral is deterministic. Therefore we can conclude \hl{the integral of a vector field $\ve{F}$ over a surface $S$ depends on the \textbf{orientation} of $S$ but otherwise independent of the parameterization}.
				\end{remark}
				
				\begin{remark}
					Let $S \subseteq \R^2$ be a two dimensional sub-manifold parameterized by $\ve{G}: R \subseteq \R^2 \to \R^3$ such that $rank(\ve{G}(\ve{u})) = 2$ for all but zero-content sets on its domain. \\
					Let $\varphi: W\subseteq \R^2 \to R$ be a bijection such that $\ve{H} := \ve{G} \circ \varphi: W \to \R^3$ is another parameterization of $S$. \\
					Now consider the integral of vector field $\ve{F}$ under parameterization $\ve{H}$,
					\begin{align}
						\iint_S \ve{F} \cdot \ve{u}\ dA &= \iint_W \ve{F}(\ve{H}) \cdot (\pd{\ve{H}}{s} \times \pd{\ve{H}}{t})\ d\Theta \\
						&= \iint_W \ve{F}\circ\ve{G}\circ\varphi \cdot (\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}) \red{det\ D\varphi}\ d\Theta \\
						&= \pm \iint_R \ve{F}\circ \ve{G} \cdot (\pd{\ve{G}}{u} \times \pd{\ve{G}}{v})\ d\Theta \tx{ (change of variable)}
					\end{align}
				\end{remark}
				
				\begin{theorem}[Invariance]
					Let $\ve{G}: R \to \R^3$ and $\ve{H} := \ve{G}\circ\varphi: W \to \R^3$ be two parameterizations of $S$, then
					\begin{equation}
						\iint_R f\circ \ve{G} \norm{\pd{\ve{G}}{u} \times \pd{\ve{G}}{v}}\ d\Theta = \iint_W f\circ \ve{H} \norm{\pd{\ve{H}}{s} \times \pd{\ve{H}}{t}}\ d\Theta
					\end{equation}
					and 
					\begin{equation}
						\iint_R \ve{F}\circ \ve{G} \cdot (\pd{\ve{G}}{u} \times \pd{\ve{G}}{v})\ d\Theta 
						= \red{\pm}\iint_W \ve{F}\circ \ve{H} \cdot (\pd{\ve{H}}{u} \times \pd{\ve{H}}{v})\ d\Theta
					\end{equation}
				\end{theorem}
				
			\subsubsection{Volume and Area (Optional)}
				\begin{theorem}
					Let $R$ be an arbitrary regular region in $\R^3$, and let $S$ be the boundary surface of $R$, define
					\begin{equation}
						S_h := \{
							\ve{x} + \delta \ve{n}: \ve{x} \in S \land \delta \in [0, h]
						\}
					\end{equation}
					where $S_h$ can be interpreted as \emph{a shell of region $R$ with thickness $h$}. Then the surface area of $S$ is 
					\begin{equation}
						\tx{area}(S) = \lim_{h \to 0} \frac{|S_h|}{h}
					\end{equation}
				\end{theorem}
		\subsection{Divergence, Gradient and Curl}
			\begin{definition}
				Let $U \subseteq \R^n$ be an open set, and define real-valued function $f: U \to \R$ (0-form) and vector field $\ve{F}: U \to \R^n$. Then we define
				\begin{enumerate}
					\item (1-form) The \textbf{gradient} of $f$ as $\nabla f$;
					\item (2-form) The \textbf{curl} of $\ve{F}$ as $\nabla \times \ve{F}$;
					\item (3-form) The \textbf{divergence} of $\ve{F}$ as $\nabla \cdot \ve{F}$.
				\end{enumerate}
			\end{definition}
			
			\begin{definition}
				Let $f: \R^n \to \R$ be a $C^1$ real-valued function, define the \textbf{Laplacian} of $f$ as a mapping from \emph{real-valued functional space} to \emph{real-valued functional space} defined as
				\begin{equation}
					\tx{div(grad)} f := \sum_{j} \partial_j^2 f = \Delta f = \nabla^2 f
				\end{equation}
			\end{definition}
			
			\begin{theorem}
				For every $C^2$ real valued function $f: \R^3 \to \R$,
				\begin{equation}
					\curl(\grad f) = \ve{0}
				\end{equation}
				For every $C^2$ vector field defined in $\R^3$ or a subset of it, 
				\begin{equation}
					\dive (\curl \ve{F}) = 0
				\end{equation}
				Note that \hl{the domain of $f$ and $\ve{F}$ must be $\R^3$ or a subset of it, otherwise the curl operation is not well-defined.}\\
			\end{theorem}
			
			\begin{theorem}[\red{Product rules}]
				\begin{align}
					\grad (fg) &= f\ \grad g + \grad f\ g \\
					\curl (f \ve{G}) &= f\ \curl{\veG} + \grad f \times \ve{G} \\
					\dive (f \ve{G}) &= f\ \dive{\veG} + \grad f \cdot \ve{G}
				\end{align}
			\end{theorem}
			
		\subsection{Divergence Theorem}
			\begin{remark}
				vector field integral on boundary (2-dimensional sub-manifold) of region in $\R^3$ ($\ve{F} \cdot \ve{n}\ dA$ 2-form) and scalar valued function ($\dive (\ve{F})\ dV$3-form) in a region (3-dimensional sub-manifold).
			\end{remark}
			
			\begin{theorem}[Divergence Theorem]
				Let $R \subseteq \R^3$ be a \emph{regular region} with \emph{piece-wise smooth boundary} $\partial S$. And $\ve{n}$ is the \emph{outer normal vector} on $\partial S$, then,
				\begin{equation}
					\iint_{\partial S} \ve{F} \cdot \ve{n}\ dA = \iiint_S \dive (\ve{F})\ dV
				\end{equation}
				\begin{proof}[Proof]
					\begin{definition}
						A region $R \subseteq \R^3$ is said to be \textbf{$xy$-simple} if and only if it can be expressed as the following form
						\begin{equation}
							R = \{(x,y,z)\in \R^3: (x, y) \in W,\varphi_1(x, y) \leq z \leq \varphi_2(x, y)\}
						\end{equation}
					\end{definition}
				Suppose $S$ is simple in terms of all combinations of $x, y, z$. \\
				Then
				\begin{gather}
					\iint_{\partial S} \ve{F} \cdot \ve{n}\ dA 
					= \iint_{\partial S} F_1 n_1 + F_2 n_2 + F_3 n_2\ dA
				\end{gather}
				Consider $\iint_{\partial S} F_3 n_3\ dA$, since $R$ is $xy$-simple, 
				\begin{gather}
					\iint_{\partial S} F_3 n_3\ dA = \iint_{\partial S} F_3 \ve{k} \cdot \ve{n}\ dA
				\end{gather}
				Note that except the bottom and top sides, which are parameterized by $\ve{G}_1(x, y) = (x, y, \varphi_1(x, y))$ and $\ve{G}_2(x, y) = (x, y, \varphi_2(x, y))$,
				 the outer normal vector of those region has form $(\cdot, \cdot, 0)$, and therefore $\ve{n}\cdot \ve{k} = 0$ for every $\ve{x}$ on those regions, and contribute nothing to the integral. \\
				 Therefore, to evaluate $\iint_{\partial S} F_3 \ve{k} \cdot \ve{n}\ dA$, we only need to consider the upper and bottom surfaces. Also note that $\ve{n}$ has opposite $z$ component on those two surfaces. \\
				 Moreover, the undirected $\ve{n}$ on those two surfaces is
				 \begin{align}
				 	\tilde{\ve{n}} &= \begin{pmatrix} 1 \\ 0 \\ \partial_x \varphi_i \end{pmatrix} \times \begin{pmatrix} 0 \\ 1 \\ \partial_y \varphi_i \end{pmatrix} = \begin{pmatrix} - \partial_x \varphi_i \\ \partial_x \varphi_i - \partial_y \varphi_i \\ 1 \end{pmatrix} \\
				 	&\implies \iint_{\partial S} F_3 \ve{k} \cdot \ve{n}\ dA = \iint_{\partial S} F_3\ dA \\
				 	&= \iint_{upper\ \partial S} F_3\ dA - \iint_{lower\ \partial S} F_3\ dA \\
				 	&= \iint_{W} F_3 (x, y, \varphi_2(x, y))\ dx dy -  \iint_{W} F_3 (x, y, \varphi_1(x, y))\ dx dy \\
				 	&= \iint_W \int_{\varphi_1(x, y)}^{\varphi_2(x, y)} \partial_3 F_3\ dz dx dy \\
				 	&= \iiint_S \partial_3 F_3 \ dV
				 \end{align}
				 We can prove the equalities involving the other two components, and the proof is completed by the fact that any open set in $\R^n$ can be written as a countable union of \emph{almost disjoint} cubes, which are simple and the boundary of $S$ has zero content.
				\end{proof}
			\end{theorem}
			
			\begin{proposition}[Geometric Interpretation of Divergence]
				Let $S \subset \R^3$, $\ve{F}: S \to \R^3$, $\ve{a} \in S$, 
				\begin{gather}
					\dive(\ve{F})(\ve{a}) = \lim_{r \to 0} \frac{3}{4 \pi r^2} \iiint_{\mc{B}(\ve{a}, r)} \dive(\ve{F})(\ve{x})\ d\ve{x} \\
					= \lim_{r \to 0} \frac{3}{4 \pi r^2} \underbrace{\iint_{\partial \mc{B}(\ve{a}, r)} \ve{F} \cdot \ve{n}\ d\ve{x}}_{\tx{flux through boundary}}
				\end{gather}
				thus $\dive(\ve{F})(\ve{a}) > 0$ if and only if at point $\ve{a}$, matters are flowing \emph{away} from this point.
			\end{proposition}
			
			\begin{corollary}[Green's Formula]
				Suppose $R \subset \R^3$ and $f, g: R \to \R$ are $C^2$ functions, then 
				\begin{gather}
					\iint_{\partial S} f \nabla g \cdot \ve{n}\ dA = \iiint_S \nabla f \cdot \nabla g + f \nabla^2 g\ dV \\
					\iint_{\partial S} (f \nabla g - g \nabla f)\ dA = \iiint_S (f \nabla^2 g - g \nabla^2)\ dV
				\end{gather}
				\begin{proof}
					\begin{gather}
						\iint_{\partial S} f \nabla g \cdot \ve{n}\ dA = \iiint_S \dive(f \nabla g)\ dA \\
						= \iiint_S f \dive (\nabla g) + \nabla f \cdot \nabla g\ dV 
						= \iiint_S f \nabla f \cdot \nabla g + \nabla^2 g\ dV
					\end{gather}
					The second formula can be proved directly using divergence theorem the first formula.
				\end{proof}
			\end{corollary}
			
		\subsection{Stokes Theorem}
		\subsubsection{The Stoke Boundary}
			\begin{definition}
				Let $S$ be a surface that is a subset of a smooth (or piecewise smooth) surface $S_0$, and the \emph{boundary of $S$} is interpreted as the \emph{boundary of $S$ \ul{within $S_0$}}. Then the $\vex \in S_0$ belongs to the \textbf{Stoke boundary} of $S$ \ul{within $S_0$} if
				\begin{equation}
					\forall r > 0,\ \mc{B}(r, \vex) \cap S \neq \varnothing \land \mc{B}(r, \vex) \cap (S_0 \backslash S) \neq \varnothing
				\end{equation}
			\end{definition}
		
		\subsubsection{The Orientation}
			\begin{definition}
				Given a smooth surface $S \subset S_0$, at a point $\vex$ in the Stoke's boundary of $S$, $\partial S$, if $\ve{n}$ denotes the \textbf{positive orientation normal} to $S_0$ and $\ve{t}$ denotes the tangent to $\partial S$ at $\vex$ with the \textbf{Stokes orientation}, then
				\begin{equation}
					\red{\ve{n} \times \ve{t} \tx{ points into }S}
				\end{equation}
			\end{definition}
		
		\subsubsection{Stokes Theorem in $\R^3$}
			\begin{theorem}[Stokes Theorem, Special Case]
				Let $S$ be a 2 dimensional sub-manifold in $\R^3$, and let $\ve{F}$ be a vector field defined on some neighbour of $S$, then
				\begin{equation}
					\int_{\partial S} \ve{F}\cdot d\ve{x} = \iint_S \curl(\ve{F})\cdot \ve{n}\ dA
				\end{equation}
			\end{theorem}
			
			\begin{remark}
				In above theorem, $\omega := \ve{F} \cdot d \ve{x}$ is a 1-form in $\R^3$ and $d \omega := \curl(\ve{F}) \cdot \ve{n}\ dA$ is a 2-form in $\R^3$.
			\end{remark}
			
			\begin{corollary}
				Let $S$ be a closed surface in $\R^3$, that's, $\partial S = \varnothing$, and let $\ve{n}$ denote the outer normal vector, and $\ve{F}$ is a $C^1$ vector field. Then
				\begin{equation}
					\iint_S \curl(\ve{F}) \cdot \ve{n}\ dA = 0
				\end{equation}
				\begin{proof}
					We can construct a \emph{small} simple closed curve $C$ on $S$ and divide $S$ into two regions sharing the same boundary. And note that given orientation fixed on $S$, the orientation on $\partial S_1$ and $\partial S_2$ are opposite. Then
					\begin{gather}
						\iint_S \curl(\ve{F})\cdot \ve{n}\ dA = \iint_{S_1} \curl(\ve{F})\cdot \ve{n}\ dA + \iint_{S_2} \curl(\ve{F})\cdot \ve{n}\ dA \\
						= \int_{\partial S_1} \ve{F} \cdot d\ve{x} - \int_{\partial S_2} \ve{F} \cdot d\ve{x}
						= \int_{C} \ve{F} \cdot d\ve{x} - \int_{C} \ve{F} \cdot d\ve{x} = 0
					\end{gather}
				\end{proof}
			\end{corollary}
			
			\begin{definition}
				A surface $S \subset \R^3$ is \textbf{closed} if it has no Stokes boundary.
			\end{definition}
			
			\begin{definition}
				A piecewise smooth surface $S \subset \R^3$ is \textbf{closed} if there exists subsets $S_1, S_2$ such that $\partial S_1 = \partial S_2 = S_1 \cap S_2$, and $\partial S_1$ and $\partial S_2$ have \emph{opposite orientations}, where $S_1, S_2$ have the same orientation as $S$.
			\end{definition}
			
			\begin{theorem}
				If $S$ is a piecewise smooth \ul{closed} surface in $\R^3$ and $\veF$ is a vector field that is $C^1$ near $S$, then
				\begin{equation}
					\iint_{S} \operatorname{curl} \mathbf{F} \cdot \mathbf{n} d A=0
				\end{equation}
				\begin{proof}
					\begin{equation}
						\iint_{S} \operatorname{curl} \mathbf{F} \cdot \mathbf{n} d A=\iint_{S_{1}} \operatorname{curl} \mathbf{F} \cdot \mathbf{n} d A+\iint_{S_{2}} \operatorname{curl} \mathbf{F} \cdot \mathbf{n} d A=\int_{\partial S_{1}} \mathbf{F} \cdot d \mathbf{x}+\int_{\partial S_{2}} \mathbf{F} \cdot d \mathbf{x}=0
					\end{equation}
				\end{proof}
			\end{theorem}
			
			\begin{proposition}[Geometric Interpretation of Curl]
				Let $R \subset \R^3$ be a 2 dimensional sub-manifold with $\ve{n}$ as outer normal vector on it, and $\ve{a} \in R$, 
				\begin{gather}
					\curl(F)(\ve{a}) \cdot \ve{n}(\ve{a}) 
					= \lim_{r \to 0} \frac{1}{2\pi r^2} \iint_{\mc{D}(\ve{a}, r)} \curl(F)(\ve{x}) \cdot \ve{n}(\ve{x})\ dA \\
					= \lim_{r \to 0} \frac{1}{2\pi r^2} \int_{\partial \mc{D}(\ve{a}, r)} \ve{F} \cdot d\ve{x} \\
				\end{gather}
				If we think of $\ve{F}$ as a force field, then $\int_{\partial \mc{D}(\ve{a}, r)} \ve{F} \cdot d\ve{x}$ represents the work done by $\ve{F}$ on a particle moves around $\partial \mc{D}(\ve{a}, r)$. Thus $\curl(\ve{F}) \cdot \ve{u}$ represents the \hl{tendency of the force $\ve{F}$ to push the particle around $\partial \mc{D}(\ve{a}, r)$ in a direction compatible with $\ve{n}$}.
			\end{proposition}
			
			\begin{theorem}[Application: Moving the Surface]
				Let $S$ and $S'$ be two oriented surfaces such that $\partial S = \partial S'$ (\emph{share the same orientation}), then 
				\begin{equation}
					\iint_{S} \operatorname{curl} \mathbf{F} \cdot \mathbf{n} d A=\int_{\partial S} \mathbf{F} \cdot d \mathbf{x}=\int_{\partial S^{\prime}} \mathbf{F} \cdot d \mathbf{x}=\iint_{S^{\prime}} \operatorname{curl} \mathbf{F} \cdot \mathbf{n} d A
				\end{equation}
			\end{theorem}
			
		\subsubsection{The Generalization}
			\begin{proposition}[Properties of Exterior Products] Let $\alpha_1, \alpha_2$ and $\beta$ be 1-forms on $\R^n$ and $f_1, f_2$ are continuous functions defined on $\R^n$,
				\begin{enumerate}
					\item \textbf{Distributive}
					\begin{gather}
						(f_1 \alpha_1 + f_2 \alpha_2) \land \beta = f_1(\alpha_1 \land \beta) + f_2 (\alpha_2 \land \beta) \\
						\beta \land (f_1 \alpha_1 + f_2 \alpha_2) = f_1 (\beta \land \alpha_1) + f_2 (\beta \land \alpha_2)
					\end{gather}
					\item \textbf{Anti-commutative}
					\begin{equation}
						\beta \land \alpha = \red{-} \alpha \land \beta
					\end{equation}
				\end{enumerate}
			\end{proposition}
			
			\begin{corollary}
				By the \emph{anti-commutative} property,
				\begin{equation}
					\alpha \land \alpha = 0
				\end{equation}
			\end{corollary}
			
			\begin{theorem}[Divergence Theorem in $\R^n$]
				Let $R$ be a regular region in $\R^n$ bounded by a piecewise smooth hyper-surface $\partial R$. Note here $R$ is a $n$ dimensional sub-manifold and $\partial R$ is a $n-1$ dimension sub-manifold. Then
				\begin{gather}
					\idotsint_{\partial R} \ve{F} \cdot \ve{n} dV^{n-1} = \iint \cdots \int_R \dive(\ve{F})\ dV^n
				\end{gather}
				where if $\partial R$ is parameterized by $\ve{G}(u_1, \dots, u_{n-1})$, then
				\begin{gather}
					\ve{n}dV^{n-1} = \det \begin{pmatrix}
						\ve{e}_1 & \dots & \ve{e}_n \\
						\partial_1 G_1 & \dots & \partial_1 G_n \\
						\vdots & & \vdots \\
						\partial_{n-1} G_1 & \dots & \partial_{n-1} G_n
					\end{pmatrix}
				\end{gather}
			\end{theorem}
			
			\begin{definition}
				A 0-form on $\R^n$ is a real valued function $f$.
			\end{definition}
			
			\begin{remark}
				While writing the basis elements $dx_i \land dx_j$ with the variables in \emph{cyclic order}. That's $dx$ before $dy$ before $dz$ before $dx$ in $\R^3$ case.
			\end{remark}
			
			\begin{definition}
				A $k$-form in $\R^n$ takes the expression of linear combination of $C(n, k)$ basis elements $\{\beta_i\}_i$.
			\end{definition}
			
			\begin{example}
				A 2-form $\omega$ in $\R^3$ can be expressed using a 3-element basis 
				\begin{gather}
					\omega = \sum_{1 \leq i < j \leq 3} C_{ij}(\ve{x}) \beta_{ij} \\
					\beta_{ij} \in \{dx \land dy, dy \land dz, dx \land dz\}
				\end{gather}
			\end{example}
			
			\begin{definition}
				Let $\omega = \sum_{j=1}^{C(n,k)} f_j \beta_j$ be a $k$-form in $\R^n$, then it's \textbf{exterior derivative} is defined to be the $(k+1)$-form in $\R^n$ defined as 
				\begin{gather}
					\red{d\omega := \sum_{j} df_j \land \beta_j}
				\end{gather}
				where $df_j$ can be computed using \emph{total derivative}.
			\end{definition}
			
			\begin{example}
				In $\R^3$, the \emph{exterior derivative} for a 0-form $f$ is its \textbf{gradient}, which is a 1-form. \\
				And the exterior derivate of a 1-form in $\R^3$ is its curl 
				\begin{gather}
					\omega := F_1 dx + F_2 dy + F_3 dz \\
					\implies d\omega = dF_1 \land dx + dF_2 \land dy + dF_3 \land dz \\
					= (\partial_1 F_1 dx + \partial_2 F_1 dy + \partial_3 F_1 dz) \land dx \\
					+ (\partial_1 F_2 dx + \partial_2 F_2 dy + \partial_3 F_2 dz) \land dy \\
					+ (\partial_1 F_3 dx + \partial_2 F_3 dy + \partial_3 F_3 dz) \land dz \\
					= (\partial_1 F_2 - \partial_2 F_1) dx \land dy 
					+ (\partial_2 F_3 - \partial_3 F_2) dy \land dz
					+ (\partial_3 F_1 - \partial_1 F_3) dz \land dx \\
					= \curl(\ve{F})
				\end{gather}
				The exterior derivate of a 2-form in $\R^3$ is its divergence
				\begin{gather}
					\omega := A dy \land dz + B dz \land dx + C dx \land dy\\
					\implies d \omega = (\partial_1 A dx + \partial_2 A dy + \partial_3 A dz) \land dy \land dz \\
					+ (\partial_1 B dx + \partial_2 B dy + \partial_3 B dz) \land dz \land dx \\
					+ (\partial_1 C dx + \partial_2 C dy + \partial_3 C dz) \land dx \land dy \\
					= (\partial_1 A + \partial_2 B + \partial_3 C) dx \land dy \land dz \\
					= \dive(\ve{F})
				\end{gather}
			\end{example}
			
			\begin{theorem}[Stokes Theorem, 5.77]
				Let $M$ be a smooth, oriented $k$ dimensional sub-manifold of $\R^n$ with a piecewise smooth boundary $\partial M$, and let $\partial M$ carry the orientation that is (in a suitable sense) compatible with the one on $M$. If $\omega$ is a $(k-1)$-form of class $C^1$ on an open set containing $M$, then
				\begin{equation}
					\red{\idotsint_{\partial M} \omega = \iint \cdots \int_M d\omega}
				\end{equation}
			\end{theorem}
			
			\begin{theorem}
				The \emph{boundary} of a (smoothly bounded) region $M$ in a $k$ dimensional manifold is a $(k-1)$ dimensional manifold with no boundary. \\
				That's let $M$ be a $k$ dimensional manifold with piecewise smooth boundary $\partial M$, then
				\begin{equation}
					\red{\partial (\partial M) = \varnothing}
				\end{equation}
			\end{theorem}
			
			\begin{theorem}
				For any $k$-form $\omega$ on $\R^n$,
				\begin{equation}
					\red{d(d\omega) = 0}
				\end{equation}
				
				\begin{proof}
					Let $M$ be a $k$ dimensional sub-manifold in $\R^n$ with piecewise smooth boundary, and $\omega$ is a $(k-2)$-form on $\R^n$, so $d(d\omega)$ is a $k$-form on $\R^n$. And
					\begin{gather}
						\iiint \cdots \int_M d(d \omega) 
						= \iint \cdots \int_{\partial M} d\omega \\
						= \idotsint_{\partial(\partial M)} \omega = \idotsint_{\varnothing} \omega = 0
					\end{gather}
				\end{proof}
			\end{theorem}
%	\section{Further Topics}
%		\subsection{Fourier Analysis}
%			\begin{definition}
%				A function $f: \R \to \R$ is \textbf{periodic with period $p$} if\footnote{Here $p$ is not necessarily the least period of $f$.} 
%				\begin{equation}
%					f(x) = f(x+p)\ \forall x \in \R
%				\end{equation}
%			\end{definition}
%			
%			\begin{assumption}
%				WLOG, we can assume $p = 2\pi$ for every periodic function encountered.
%				\begin{proof}
%					If $f$ is periodic with period $p$, we can transform it into a function with period $2 \pi$ by defining $\tilde{f}(x) := f(x \frac{p}{2\pi})$ such that
%					\begin{gather}
%						\tilde{f}(x + 2 \pi) = f(x \frac{p}{2\pi} + p) \\
%						= f(x \frac{p}{2\pi}) = \tilde{f}(x)
%					\end{gather}
%				\end{proof}
%			\end{assumption}
%			
%			\begin{theorem}[Fourier Decomposition]
%				Let $f: \R \to \R$ be a periodic function with period $2\pi$ continuous everywhere but finitely many points on its domain, then it can be expressed as 
%				\begin{equation}
%					f(x) = a_0 + \sum_{n=1}^\infty \{a_n \cos(nx) + b_n \sin(nx)\}
%				\end{equation}
%			\end{theorem}
%			
%			\begin{lemma}
%				\begin{equation}
%					\cos(a)\cos(b) = \frac{1}{2}[\cos(a+b) + \cos(a-b)]
%				\end{equation}
%				\begin{proof}
%					\begin{gather}
%						\cos(a)\cos(b) = \cos(a+b) + \sin(a)\sin(b) \\
%						\cos(a)\cos(b) = \cos(a-b) - \sin(a)\sin(b)
%					\end{gather}
%				\end{proof}
%				\begin{equation}
%					\sin(a)\sin(b) = \frac{1}{2}[\cos(a-b) - \cos(a+b)]
%				\end{equation}
%				\begin{proof}
%					\begin{gather}
%						\sin(a)\sin(b) = \cos(a)\cos(b) - \cos(a+b) \\
%						- \sin(a)\sin(b) = \sin(a)\sin(-b) = \cos(a)\cos(b) - \cos(a-b)
%					\end{gather}
%				\end{proof}
%			\end{lemma}
%			
%			\begin{lemma}
%				\begin{gather}
%					\int_{-\pi}^\pi \cos(nx) \sin(mx)\ dx = 0\ \forall n, m \in \N \\
%					\frac{1}{\pi} \int_{-\pi}^\pi \cos(nx) \cos(mx)\ dx = \mathds{1}\{n = m\} \\
%					\frac{1}{\pi} \int_{-\pi}^\pi \sin(nx) \sin(mx)\ dx = \mathds{1}\{n = m\} \\
%				\end{gather}
%			\end{lemma}
%			
%			\begin{proposition}[Finding the Coefficients]
%				\begin{align}
%					a_m &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos(mx)\ dx \\
%					b_m &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin(mx)\ dx \\
%					a_0 &= \frac{1}{2\pi} \int_{-\pi}^\pi f(x)\ dx
%				\end{align}
%			\end{proposition}
		\subsection{Vector Fields that are Gradients or Curls}
			\subsubsection{Conservative Vector Field}
			\begin{definition}
				A continuous vector field $\veG$ defined on open $U \subset \R^n$ is \textbf{conservative} if there exists a function $f: U \to \R$ of class $C^1$ such that $\veG = \nabla f$.
			\end{definition}
		
			\begin{theorem}
				Let $U \subset \R^n$ open, and let $\veG: U \to \R^n$ be continuous. Then the following are equivalent:
				\begin{enumerate}[(i)]
					\item There exists a function $f: U \to \R$ of class $C^1$ such that $\veG = \nabla f$;
					\item $\int_{C} \mathbf{G} \cdot d \mathbf{x}=0$ for any \ul{closed piecewise} smooth oriented curve $C \subset U$;
					\item $\int_{C_{1}} \mathbf{G} \cdot d \mathbf{x}=\int_{C_{2}} \mathbf{G} \cdot d \mathbf{x}$ for any two piecewise smooth oriented curves $C_1, C_2$ in $U$ that shares starting and ending points.
				\end{enumerate}
				\begin{proof}
					\quad \\
					\textbf{(i) $\implies$ (ii)} by \emph{the Fundamental Theorem of Line Integrals}.\\
					\textbf{(ii) $\implies$ (iii)} Given $C_1$ and $C_2$ both from $\ve{p}$ to $\ve{q}$. Constructing $C_2'$ from $\ve{q}$ to $\ve{p}$ by reversing the orientation of $C_2$. And $C_1 \cup C_2'$ form a closed curve.
					\begin{equation}
						\int_{C} \mathbf{G} \cdot d \mathbf{x}=\int_{C_{1}} \mathbf{G} \cdot d \mathbf{x}-\int_{C_{2}} \mathbf{G} \cdot d \mathbf{x}
					\end{equation}
					\textbf{(iii) $\implies$ (i)}, pick an arbitrary point $\ve{p} \in U$, and for every $\ve{q} \in U$, define $f$ as 
					\begin{equation}
						f(\mathbf{q})=\int_{C_{\mathbf{p}, \mathbf{q}}} \mathbf{G} \cdot d \mathbf{x}
					\end{equation}
					where $C_{\mathbf{p}, \mathbf{q}}$ is an arbitrary curve starting at $\ve{p}$ and ending at $\ve{q}$.
				\end{proof}
			\end{theorem}
			
			\begin{theorem}
				If $\veG$ is a conservative vector field of class $C^1$ on an open set $U \subset \R^3$, then $\curl \veG = \ve{0}$.
			\end{theorem}
			
			\begin{theorem}
				If $U \subset \R^3$ is \ul{convex} and if $\veG$ is a $C^1$ vector field defined on $U$ and $\curl \veG = \ve{0}$ on $U$, then $\veG$ is conservative.
			\end{theorem}
			
			\begin{remark}
				That's possible for a non-conservative vector field $\veG$ defined on some non-convex set to have $\curl \veG = \ve{0}$
			\end{remark}
				
			\begin{proposition}[Finding $f$ for Conservative Vector Fields]
				If the domain of a conservative vector field $\veG$ is \ul{convex}, then we can construct $f$ following
				\begin{enumerate}[(i)]
					\item Choose $\ve{p} = (a, b, c) \in U$;
					\item Define $f(x, y, z)$ as
					\begin{equation}
						f(x, y, z) :=\int_{a}^{x} G_{1}(\blue{t}, b, c) d t+\int_{b}^{y} G_{2}(\red{x}, \blue{t}, c) d t+\int_{c}^{z} G_{3}(\red{x}, \red{y}, \blue{t}) d t
					\end{equation}
				\end{enumerate}
			\end{proposition}
			
			\begin{corollary}
				If the domain of $\veG$ is a convex set containing the \ul{origin}, then we can define $\ve{p} = (a, b, c) = (0, 0, 0)$,
				\begin{equation}
					f(x, y, z)=\int_{0}^{1} \mathbf{G}(t x, t y, t z) \cdot (x, y, z) d t
				\end{equation}
			\end{corollary}
			
		\subsubsection{Vector Fields that are Curls}
			\begin{theorem}
				If $\veG: U \to \R^3$ is a vector field of class $C^1$ and $\veG = \curl \veF$ for some vector field $\veF: U \to \R^3$ of class $C^2$, then $\dive \veG = 0$.
			\end{theorem}
			
			\begin{theorem}
				Suppose $\veG$ is a $C^1$ vector field in an open set $U \subset \R^3$ such that $\dive \veG = 0$. If $U$ is \ul{convex}, then there exists a vector field $\veF$ such that $\curl \veF = \veG$.
			\end{theorem}
			
			\begin{definition}
				Given a closed curve $C \subset \R^3$, the \textbf{minimal surface} is the surface $S$ with the smallest possible area, given that $\partial S = C$.
			\end{definition}
\end{document}























