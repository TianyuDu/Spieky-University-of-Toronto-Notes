\documentclass{article}
\usepackage{spikey}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{soul}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{chngcntr}
\usepackage{centernot}
\usepackage[shortlabels]{enumitem}
\usepackage[margin=1truein]{geometry}
\usepackage{tkz-graph}
\usepackage{dsfont}
%\GraphInit[vstyle = Shade]

\counterwithin{equation}{section}
\counterwithin{figure}{section}

\def\Z{{\mathbb Z}}
\def\Q{{\mathbb Q}}
\def\R{{\mathbb R}}
\def\C{{\mathbb C}}

\newcommand{\bi}[2]{\begin{pmatrix}{#1}\\{#2}\end{pmatrix}}
%\counterwithin{equation}{section}

\usepackage[
    type={CC},
    modifier={by-nc},
    version={4.0},
]{doclicense}

\title{MAT 344 Lecture Notes}
\date{\today}
\author{Tianyu Du}
\begin{document}
	\maketitle
	\doclicenseThis
	\texttt{Github Page} \url{https://github.com/TianyuDu/Spikey_UofT_Notes}\\
	\texttt{Note Page} \url{TianyuDu.com/notes}
	\tableofcontents
	\newpage
	
	\section{Strings, Sets, and Binomial Coefficients}
		\subsection{Strings and Sets}
			\begin{notation}
				Let $n \in \Z_{++}$, and we use $[n]$ to denote the $n$-element set $\{1,2,\dots,n\}$.
			\end{notation}
			
			\begin{definition}
				Let $X$ be a set, then an $X$-\textbf{string of length} (or a \textbf{word}/\textbf{array}) $n$ is a function $s:[n] \to X$, and $X$ is called the \textbf{alphabet} of the string, and each $x \in X$ is called a \textbf{character} or \text{letter}.
			\end{definition}
			
			\begin{remark}
				An $X$-string defined by $s: [n] \to X$ with length $n$ can be equivalently defined as a \textbf{sequence} consisting elements in $X$.
				\begin{equation}
					s(1)s(2)\dots s(n)
				\end{equation}
			\end{remark}
			
			\begin{definition}
				In the case $X = \{0, 1\}$, strings generated from $X$ are called \textbf{binary strings}. When $X = \{0,1,2\}$, strings are called \textbf{ternary strings}.
			\end{definition}
			
			\begin{definition}
				Let $X$ be a \emph{finite} set and let $n \in \Z_{++}$. An $X$-string $s = x_1 x_2 \dots x_n$ is a \textbf{permutation} of size $m$ if $x_i \neq x_j\ \forall x_i, x_j \in s$.
			\end{definition}
			
			\begin{proposition}
				If $X$ is an $m$-element set and $m \geq n \in \Z_{++}$, then the number of $X$-strings of length $n$ that are permutations is 
				\begin{equation}
					P(m, n) \equiv \frac{m!}{(m-n)!}
				\end{equation}
			\end{proposition}
			
			\begin{definition}
				Let $X$ be a \emph{finite} set and let $0 \leq k \leq |X|$. Then $S \subseteq X$ with $|S| = k$ is a \textbf{combination} of size $k$.
			\end{definition}
			
			\begin{proposition}
				Let $n, k \in \Z$ such that $0 \leq k \leq n$, then the number of combinations is
				\begin{equation}
					\bi{n}{k} \equiv \frac{P(n, k)}{n!} = \frac{n!}{k!(n-k)!}
				\end{equation}
			\end{proposition}
			
			\begin{proposition}
				For all integers $n$ and $k$ with $0 \leq k \leq n$
				\begin{equation}
					\bi{n}{k} = \bi{n}{n-k}
				\end{equation}
			\end{proposition}
			
			\begin{example}
				Binomial coefficients can be used to find the number of integer solutions of
				\begin{equation}
					\sum_{i=1}^k x_i \leq N
				\end{equation}
				given appropriate integers $k, N \in \Z$.
				\begin{enumerate}[(i)]
					\item $x_i > 0\ \forall i \in [k]$ and equality holds, then $C(N-1, k-1)$.
					\item $x_i \geq 0\ \forall i \in [k]$ and equality holds, then $C(N+k-1, k-1)$.\footnote{Simulate choosing $x_i + 1$ instead of $x_i$.}
					\item $x_i > 0\ \forall i \neq j, x_j = Z$ and equality holds, then $C(N-Z-2,k-2)$.
					\item $x_i > 0\ \forall i \in [k]$ and strict inequality holds, then $C(N-1, k)$.\footnote{Image there is a placeholder $x_{k+1} > 0$.}
					\item $x_i \geq 0\ \forall i \in [k]$ and strict inequality holds, then $C(N+k-1, k)$.
					\item $x_i \geq 0\ \forall i \in [k]$ and \emph{weak} inequality holds, $C(N+k, k)$ \footnote{This can be calculated by adding case (ii) and case (v) together, and apply Pascal's identity}.
					\begin{gather}
						\bi{N+k-1}{k-1} + \bi{N+k-1}{k} = \bi{N+k}{k}
					\end{gather}
				\end{enumerate}
			\end{example}
			
		\begin{definition}
			Define a \textbf{plane} as $\Z^2$, then a \textbf{lattice path} in the plane is a \emph{sequence} of elements in $\Z^2$
			\begin{equation}
				((x_i, y_i))_{i=1}^t
			\end{equation}
			such that for every $i \in \{1,\dots,t-1\}$, either
			\begin{enumerate}[(i)]
				\item (\emph{Horizontal move}) $x_{i+1} = x_i + 1 \land y_{i+1} = y_i$
				\item Or (\emph{vertical move}) $x_{i+1} = x_i \land y_{i+1} = y_i + 1$
			\end{enumerate}
		\end{definition}
		
		\begin{lemma}
			Let $(p, q), (m, n) \in \Z^2$, then the number of lattice paths from $(p, q)$ to $(m, n)$ is 
			\begin{equation}
				\bi{(p-m) + (q-n)}{p-m}
			\end{equation}
			\begin{proof}
				The lattice is isomorphic to a ${H, V}$-string with length $(p-m)+(q-n)$. There are exactly $p-m$ horizontal moves as well as exactly $q-n$ vertical moves.
			\end{proof}
		\end{lemma}
		
		\begin{theorem}
			Given $n \in \Z_+$, the number of lattice paths from $(0,0)$ to $(n,n)$ which \emph{never go above the diagonal line} is the \textbf{Catalan number}
			\begin{equation}
				C(n) \equiv \frac{1}{n+1} \bi{2n}{n}
			\end{equation}
			\begin{proof}
				Omitted
			\end{proof}
		\end{theorem}
		
		\begin{theorem}[Binomial Theorem]
			Let $x, y \in \R$, then $\forall n \in \Z_+$
			\begin{equation}
				(x + y)^n = \sum_{i=0}^n \bi{n}{i} x^{n-i} y^i
			\end{equation}
		\end{theorem}
		
		\begin{theorem}[Multinomial Theorem]
			Let $r \in \Z_+$, $\{x_i\}_{i=1}^r \in \mc{P}(\R)$. Then for every $n \in \Z_+$,
			\begin{equation}
				(\sum_{i=1}^r x_i)^n = \sum_{|\alpha|\red{=}n} \bi{n}{\alpha} (x_i)^\alpha
			\end{equation}
			where $\alpha \equiv (\alpha_i)_{i=1}^r,\ \alpha_i \in \Z_{++}\ \forall i$ is a \textbf{multi-index}, and 
			\begin{gather}
				(x_i)^\alpha \equiv \sum_{i=1}^r x_i^{\alpha_i} \\
				|\alpha| \equiv \sum_{i=1}^r \alpha_i \\
				\bi{n}{\alpha} \equiv \frac{n!}{\alpha_1!\alpha_2!\dots\alpha_r!}
			\end{gather}
		\end{theorem}
		
	\section{Induction}
		\begin{theorem}[Well-Ordering Principle]
			Every non-empty set of $\Z_{++}$ has a least element.
			\begin{proof}
				Prove using principle of mathematical induction and contradiction.
			\end{proof}
		\end{theorem}
		
		\begin{definition}
			\textbf{Recursive definition}
		\end{definition}
		
		\begin{theorem}[The Principle of Mathematical Induction]
			If $S$ is any set of natural numbers with properties that
			\begin{enumerate}
				\item 1 is in $S$, and
				\item $k+1$ is in $S$ whenever $k$ is any number in $S$.
			\end{enumerate}
			then $S = \Z_+$.
		\end{theorem}
		
		\begin{remark}
			\textbf{Recursive definitions} can also be recast as \textbf{inductive definitions}.
		\end{remark}
		
		\begin{definition}[Summation]
			Summation operator beginning with index 1, $\sum: \mc{F}_1 \times \Z_{++} \to \R$, where $\mc{F}_1$ is the set of unary real-valued functions, is defined inductively as
			\begin{align}
				\sum_{i=1}^1 f(i) &\equiv f(1) \\
				\sum_{i=1}^{k+1} f(i) &\equiv \sum_{i=1}^k f(i) + f(k+1)
			\end{align}
		\end{definition}
		
		
		\begin{theorem}[The Principle of Complete Mathematical Induction]
			If $S$ is any set of natural numbers with the properties that
			\begin{enumerate}
				\item $1 \in S$, and
				\item $\{1, 2, \dots, k\} \subset S \implies k+1 \in S$,
			\end{enumerate}
			then $S = \Z_+$.
		\end{theorem}
	
	\section{Pigeon Hole Principle and Complexity}
		\subsection{Pigeon Hole Principle}
			\begin{theorem}
				Let $f: X \to Y$ be a function, then 
				\begin{equation}
					f \tx{ injective} \implies |X| \leq |Y|
				\end{equation}
			\end{theorem}
			
			\begin{theorem}[Pigeon Hole Principle]
				Let $f: X \to Y$, and suppose $|X| > |Y|$, then $f$ is not injective, that's
				\begin{equation}
					\exists x_1 \neq x_2 \in X\ s.t.\ f(x_1) = f(x_2)
				\end{equation}
				\begin{proof}
					Contrapositive form of the theorem 3.1
				\end{proof}
			\end{theorem}
			
			\begin{theorem}[Erods/Szekeres]
				Let $m, n \in \Z_+$, then any sequence of $mn + 1$ \emph{distinct} real numbers either
				\begin{enumerate}[(i)]
					\item has an increasing subsequence of $m+1$ terms,
					\item or it has a decreasing subsequence of $n+1$ terms.
				\end{enumerate}
				\begin{proof}
					Let $\sigma = (x_1, x_2, \dots, x_{mn+1})$ be a sequence with length $mn+1$ consisting of distinct reals.\\
					For each $i \in [mn+1]$ define $a_i$ as the maximum length of an increasing subsequence of $\sigma$ \emph{beginning with} $x_i$. \\
					Define $b_i$ as the maximum length of a decreasing subsequence of $\sigma$ \emph{ending with} $x_i$. \\
					\textbf{Case (i)}
					\begin{gather}
						\exists i \in [mn+1]\ s.t.\ a_i \geq m+1 \lor b_i \geq n+1
					\end{gather}
					then the theorem is proven. \\
					\textbf{Case (ii)} Suppose otherwise
					\begin{gather}
						\forall i \in [mn+1]\ a_i \leq m \land b_i \leq n
					\end{gather}
					construct function $f: [mn+1] \to [m]\times[n]$ defined as
					\begin{equation}
						f(i) \equiv (a_i, b_i)
					\end{equation}
					Note that $|[mn+1]| > |[m]\times[n]|$ so $f$ cannot be injective, so there exists $j\neq k \in [mn+1]$ such that $(a_j, b_j) = (a_k, b_k)$. \\
					WLOG, assume $j < k$.\\
					Since all elements in $\sigma$ are distinct, $j \neq k \implies x_j \neq x_k$. \\
					\textbf{Sub-case (i)} $x_j < x_k$, then any increasing subsequence beginning with $x_k$ can be extended by prepending $x_j$, so $a_j > a_k$. \\
					\textbf{Sub-case (ii)} $x_j > x_k$, then any decreasing subsequence ending with $x_j$ can be extended by appending $x_k$, so $b_k > b_j$. \\
					Either sub-case leads to a contradiction, so \textbf{case (ii)} is impossible.
				\end{proof}
			\end{theorem}
		\subsection{Complexity}
			\begin{definition}
				Let $f, g: \N \to \R$ be a function, then the \textbf{big oh} $\mc{O}(f)$ is a collection of functions such that, for every $g \in \mc{O}(f)$
				\begin{gather}
					\exists c \in \R, n^* \in \N\ s.t.\ \forall n \in \N, n \geq n^* \implies g(n) \leq c f(n)
				\end{gather}
			\end{definition}
			
			\begin{definition}
				Let $f, g: \N \to \R$ be a function. If $f(n) > 0\ \forall n \in \N$,
				then the \textbf{little oh} $o(f)$ is the collection of functions such that, for every $g \in o(f)$, 
				\begin{equation}
					\lim_{n \to \infty} \frac{g(n)}{f(n)} = 0
				\end{equation}
			\end{definition}
			
			\begin{definition}
				Let $f, g: \N \to \R$, then the \textbf{little oh}, $o(f)$ is defined as the collection of functions such that $g \in o(f)$ if and only if
				\begin{gather}
					\exists c \in \R, n^* \in \N,\ s.t.\ \forall n \in \N, n \geq n^* \implies |g(n)| < c|f(n)|
				\end{gather}
			\end{definition}
			
			\begin{definition}
				Define $\pi: \Z_{++} \to \Z_+$ as $\pi(n) \equiv$ \emph{the number of primes among the first $n$ positive integers}.
			\end{definition}
			
			\begin{theorem}[Prime Number Theorem] $\pi(n)$ grows at a rate the same as $\frac{n}{\ln(n)}$. That's
				\begin{equation}
					\lim_{n \to \infty} \pi(n) \frac{\ln(n)}{n} = 1
				\end{equation}
			\end{theorem}
			
			\begin{definition}
				The class of \textbf{polynomial time} problems, denoted as $\mc{P}$, is the set of decision problems for which there exists one polynomial run time algorithm as the solution.
			\end{definition}
			
			\begin{definition}
				The class of \textbf{nondeterministic polynomial time} problems, denoted as $\mc{NP}$, is the set of decision problems for which there is a certificate for a yes answer whose correctness can be verified in polynomial time.
			\end{definition}
	
	\section{Graph Theory}
		\begin{definition}
			A graph $\mc{G}$ is defined as an order pair of sets $(V, E)$. \textbf{Vertex} set $V$ is a set consisting of \textbf{vertex} objects. \textbf{Edge set} $E$ contains \textbf{edges} as pairs of elements in $E$.
		\end{definition}
		
		\begin{definition}
			A graph $\mc{G}$ is called a \textbf{simple graph} if it is unweighted, undirected and contains no loop or multiple edges. That's, if $\mc{G} \equiv (V, E)$ is a simple graph, then
			\begin{enumerate}
				\item (Undirected) $\forall x, y \in V,\ xy \in E \iff yx \in E$.
				\item (No loop) $\forall xy \in E, x \neq y$.
				\item (No multiple edge) all elements in $E$ are distinct.
				\item Vertices or edges in $\mc{G}$ have no weight.
			\end{enumerate}
			Graphs with multiple edges or loops are called \textbf{multi-graphs}.
		\end{definition}
		
		\begin{remark}
			In this course, unless explicitly mentioned, we consider simple graphs only.
		\end{remark}
		
		\begin{definition}
			Let $x, y \in V$, if $xy \in E$, then $x$ and $y$ are \textbf{adjacent}, and edge $xy$ is \textbf{incident to} vertices $x$ and $y$. If $xy \notin E$, we say $x$ and $y$ are \textbf{non-adjacent}.
		\end{definition}
		
		\begin{definition}
			Let $\mc{G} \equiv (V, E)$ and $x \in V$, then the \textbf{neighbourhood} of $x$ is defined as
			\begin{equation}
				\mc{N}(x) \equiv \{y \in V: xy \in E\}
			\end{equation}
			Then the \textbf{degree} of $x$ in graph $\mc{G}$ is defined as
			\begin{equation}
				\tx{deg}_{\mc{G}}(x) \equiv |\mc{N}(x)|
			\end{equation}
		\end{definition}
		
		\begin{definition}
			Let $\mc{G} \equiv (V, E)$ and $\mc{H} \equiv (W, F)$, we say $\mc{H}$ is a \textbf{subgraph} of $\mc{G}$ when $W \subseteq V$ and $F \subseteq E$. $\mc{H}$ is an \textbf{induced subgraph} if
			\begin{equation}
				F = \{xy \in E: x, y \in W\}	
			\end{equation}
			$\mc{H}$ is a \textbf{spanning subgraph} if $W = V$.
		\end{definition}
		
		\begin{definition}
			$\mc{G} \equiv (V, E)$ is a \textbf{complete graph} ($\ve{K}_n$) if 
			\begin{equation}
				E = \{xy: \tx{ distinct pair } x, y \in V\}
			\end{equation}
		\end{definition}
		
		\begin{definition}
			A graph $\mc{G} \equiv (V, E)$ is a \textbf{independent graph} ($\ve{I}_n$) if for every distinct pair $(x, y) \subset V$, $xy \notin E$.
		\end{definition}
		
		\begin{definition}
			A \textbf{walk} in graph $\mc{G} \equiv (V, E)$ is a \emph{sequence of vertices} $(x_1, x_2, \dots, x_n)$ such that 
			\begin{equation}
				x_ix_{i+1} \in E\  \forall i \in \{1,\dots,n-1\}
			\end{equation}
		\end{definition}
		
		\begin{definition}
			A \textbf{path} is a walk with \emph{distinct} vertices. The length of path is defined as the \hl{number of edges} in it.
		\end{definition}
		
		\begin{definition}
			A \textbf{cycle} is a \emph{path} $(x_1, x_2, \dots, x_n)$ with $n \geq 3$ such that $x_1x_n \in E$.
		\end{definition}
		
		\begin{definition}
			Two graphs $\mc{G} \equiv (V, E)$ and $\mc{H} \equiv (W, F)$ are \textbf{isomorphic}, denoted as $\mc{G} \cong \mc{H}$, if there exists a bijection $f: V \to W$ such that
			\begin{equation}
				\forall x, y \in V,\ xy \in E \iff f(x)f(y) \in F
			\end{equation}
%			And we say $\mc{G}$ \emph{contains} $\mc{H}$ is there is a subgraph of $\mc{G}$ isomorphic to $\mc{H}$.
		\end{definition}
		
		\begin{definition}
			A graph $\mc{G}$ is \textbf{connected} when for every distinct pair $x, y \in V$, there exists a path from $x$ to $y$. Otherwise, $\mc{G}$ is \textbf{disconnected}.
		\end{definition}
		
		\begin{definition}
			Provided $\mc{G}$ is disconnected, then a \textbf{component} of $\mc{G}$ is a \emph{maximal connect subgraph} of $\mc{G}$. That's, if $\mc{H}$ is a component, it is connected and any super-graph of $\mc{H}$ is disconnected.
		\end{definition}
		
		\begin{definition}
			A graph $\mc{G}$ is \textbf{acyclic} when it does not contain any cycle on three or more vertices. An acyclic graph is also called \textbf{forests}. Further, if a acyclic graph is connected, it's called a \textbf{tree}.
		\end{definition}
		
		\begin{definition}
			Given $\mc{G}$ is connected\footnote{If $\mc{G}$ is disconnected, it's impossible for any of its spanning subgraph to be connected.}, a subgraph $\mc{H} \equiv (W, F)$ of $\mc{G}$ is a \textbf{spanning tree} if both $V = W$ and $\mc{H}$ is a tree.
		\end{definition}
		
		\begin{proposition}
			Every connected graph has a spanning tree.
		\end{proposition}
		
		\begin{theorem}
			$\ve{K}_n$ has $n^{n-2}$ \textbf{labelled spanning trees}.
		\end{theorem}
		
		\begin{theorem}
			Let $\mc{G} \equiv (V, E)$ be a graph, then
			\begin{equation}
				\sum_{v \in V}\tx{deg}_\mc{G}(v) = 2 |E|
			\end{equation}
		\end{theorem}
		
		\begin{corollary}
			For any graph, the number of vertices with odd degree is even.
		\end{corollary}
		
		\begin{definition}
			Let $\mc{T}$ be a tree, a vertex $v$ is a \textbf{leaf} if $\tx{deg}_\mc{G}(v)=1$.
		\end{definition}
		
		\begin{proposition}
			Every tree with $|V| \geq 2$ has at least two leaves.
			\begin{proof}
				Let $\mc{T}$ be a tree. The corollary above suggests that it cannot have one leaf. Consider the case it has no leaf, then since every vertex has at least degree of 2 and $\mc{T}$ is connected, there must exist a cycle, which leads to a contradiction.
			\end{proof}
		\end{proposition}
		
		\subsection{Eulerian Graphs}
			\begin{definition}
				Let $\mc{G} \equiv (V, E)$ be a graph, then a sequence of vertices $(v_0,v_1,\dots v_t)$ is an \textbf{Eulerian circuit} if (\hl{\textbf{Unique edge}})
				\begin{enumerate}[(i)]
					\item $v_0 = v_t$;
					\item $v_i v_{i+1} \in E\ \forall i \in \{0, \dots, t-1\}$;
					\item $\forall e \in E, \exists\ ! i \in \Z\ s.t.\ v_i v_{i+1} = e$.
				\end{enumerate}
				That's, it is a graph circuit which uses each graph edge exactly once.
			\end{definition}
			
			\begin{definition}
				A graph is \textbf{Eulerian} if it contains an eulerian circuit.
			\end{definition}
			
			\begin{remark}
				\hl{Some definitions require Eulerian graph to be connected but some don't, check with the lecture notes.}
			\end{remark}
			
			\begin{definition}
				A \textbf{circuit} is a walk with $x_0 = x_n$.
			\end{definition}
			
			\begin{theorem}
				A graph $\mc{G}$ is Eulerian \ul{if and only if} it is connected and every vertex has even degree.
			\end{theorem}
		
		\subsection{Hamiltonian Graphs}
			\begin{definition}
				Let $\mc{G} \equiv (V, E)$ be a graph, then a sequence of vertices $(v_0, v_1, \dots, v_t)$ is a \textbf{Hamiltonian cycle} if (\hl{\textbf{Unique vertex}})
				\begin{enumerate}
					\item $v_0 v_t \in E$;
					\item $v_i v_{i+1} \in E\ \forall i \in \{0, \dots, t-1\}$;
					\item $\forall v \in V, \exists!\ i \in \Z\ s.t.\ v_i = v$.
				\end{enumerate}
			\end{definition}
			
			\begin{definition}
				A graph containing Hamiltonian cycle is \textbf{Hamiltonian}.
			\end{definition}
			
			\begin{theorem}
				If $\mc{G}$ is a graph with $n$ vertices, and $\tx{deg}_\mc{G}(v) \geq \lceil \frac{n}{2} \rceil\ \forall v \in V$, then $\mc{G}$ is Hamiltonian.
			\end{theorem}
			
		\subsection{Graph Colouring}
			\begin{definition}
				Let $\mc{G} \equiv (V, E)$, and $C$ is a set of elements called \textbf{colours}. Then a \textbf{proper colouring} of $\mc{G}$ is a function $\phi:V \to C$ such that 
				\begin{equation}
					\forall x, y \in V,\ xy \in E \implies \phi(x) \neq \phi(y)
				\end{equation}
			\end{definition}
			
			\begin{definition}
				The least size of $C$ such that we can construct a proper colouring with it is defined as the \textbf{chromatic number} of $\mc{G}$, denoted as $\chi(\mc{G})$.
			\end{definition}
			
			\begin{definition}
				A graph $\mc{G} \equiv (V, E)$ with $\chi(\mc{G}) \leq 2$ is called \textbf{2-colourable graph}.
			\end{definition}
			
			\begin{theorem}
				A graph is 2-colourable \ul{if and only if} it does \emph{not} contain an odd cycle.
				\begin{proof}\quad \\
					($\implies$) Let $\mc{G} \equiv (V, E)$ be a 2-clourable graph with proper colouring $\phi: V \to \{\alpha, \beta\}$. \\
					Define $V_1 \equiv \phi^{-1}(\alpha)$ and $V_2 \equiv \phi^{-1}(\beta)$. Clearly those two sets are disjoint and $V = V_1 \cup V_2$. \\
					By definition of proper colouring, for every pair of $x_1, x_2 \in V_1$, $x_1 x_2 \notin E$. The same holds for $V_2$. \\
					Therefore subgraphs of $\mc{G}$ induced from $V_1$ and $V_2$ are themselves independent, and $\mc{G}$ it bipartite. \\
					We've shown the equivalence between bipartite and 2-colourable. \\
					Suppose there's an odd cycle in $\mc{G}$, $C = (x_1, x_2, \dots, x_n)$, where $n$ is odd. \\
					WLOG, assume $x_1 \in V_1$, by nature of bipartite graph, $x_i \in V_2\ \iff i \tx{ even}$. Therefore $x_n \in V_1$, and for $C$ to be a cycle, we require $x_1 x_n \in E$, which contradicts the fact that $\mc{G}$ is bipartite and 2-colourable. \\\emph{Modus Tollens} \\
					($\impliedby$) Suppose there exists an odd cycle $C = (x_1, x_2, \dots, x_n)$ in $\mc{G}$, it's easy to show, by induction,  that for any proper colouring $\phi$ of $\mc{G}$, $|\phi(C)| \geq 3$. This implies $|\phi(V)| \geq 3$, so $\mc{G}$ is not 2-colourable. \\
					\emph{Modus Tollens}
				\end{proof}
			\end{theorem}
			
			\begin{definition}
				A graph $\mc{G} = (V, E)$ is a \textbf{bipartite graph} when $V$ can be partitioned into two sets $V_1, V_2$, such that subgraphs \emph{induced} by $V_1$ and $V_2$ are \emph{independent graphs}.
			\end{definition}
			
			\begin{remark}
				Bipartite graphs are 2-colourable. Simply define $\phi: V \to \{\alpha, \beta\}$ as 
				\begin{equation}
					\phi(v) = \alpha \mathds{1}\{v \in V_1\} + \beta \mathds{1}\{v \in V_2\}
				\end{equation}
			\end{remark}
			
			\begin{definition}
				A \textbf{clique} in a graph $\mc{G} \equiv (V, E)$ is a set $K \subseteq V$ such that the subgraph induced by $K$ is isomorphic to the $|K|$-complete graph $\ve{K}_{|K|}$. (Equivalently, vertices in $K$ are \emph{pair-wise adjacent})
			\end{definition}
			
			\begin{definition}
				The \textbf{maximum clique size} or \textbf{clique number} of graph $\mc{G}$, denoted as $\omega(\mc{G})$ is the largest $t$ such that there exists a clique with $t$ vertices.
			\end{definition}
			
			\begin{proposition}
				For any graph $\mc{G}$, 
				\begin{equation}
					\chi(\mc{G}) \geq \omega(\mc{G})
				\end{equation}
			\end{proposition}
			
			\begin{proposition}[Generalized Pigeon Hole Principle]
				Let $f: X \to Y$ be a mapping such that 
				\begin{equation}
					|X| \red{>} (m-1)|Y|
				\end{equation}
				then there exists $\{x_1, \dots, x_m\} \subseteq X$ such that $f(x_i) = f(x_j)\ \forall i, j$.
				\begin{proof}
					For each $y \in Y$, we can divide $X$ into $|Y|$ partitions, where each partition is defined as the pre-image of one particular $y \in Y$. Let $\{X_i\}$ denote the set of partitions. \\
					We are trying to find the minimum value of $\max_i\{|X_i|\}_{i=1}^{|Y|}$, that's
					\begin{equation}
						\min_{\tx{valid partition}} \max_i\{|X_i|\}_{i=1}^{|Y|}
					\end{equation}
					the minimum is attained when each partition of $X$ has the same cardinality, which is strictly greater than $m-1$. \\
					For each of those partitions, it's a pre-image for some value $y \in Y$ with size at least $m$.
				\end{proof}
			\end{proposition}
			
			\begin{proposition}
				For every $t \geq 3$, there exists a graph $\mc{G}_t$ so that $\chi(\mc{G}_t) = t$ and $\omega(\mc{G}_t) = 2$. \emph{So the difference between $\chi$ and $\omega$ can be arbitrarily large and this inequality in proposition 4.2 cannot always be tight.}
			\end{proposition}
			
			\begin{definition}
				Let $\mc{F} = \{S_\alpha: \alpha \in V\}$ be an indexed family of sets, define a graph $\mc{G}$ in the following such that 
				\begin{equation}
					S_x \cap S_y \neq \emptyset \iff xy \in E
				\end{equation}
				Then we call $\mc{G}$ an \textbf{intersection graph} (representing $\mc{F}$).
			\end{definition}
			
			\begin{remark}
				Every graph is an intersection graph since we can explicitly construct a collection of sets from the adjacency matrix of the given graph.
			\end{remark}
			
			\begin{definition}
				$\mc{G}$ is an \textbf{interval graph} if it is the intersection graph of \emph{a collection of closed intervals in $\R$}.
			\end{definition}
			
			\begin{theorem}
				If $\mc{G}$ is an interval graph, then $\chi(\mc{G}) = \omega(\mc{G})$.
			\end{theorem}
			
			\begin{definition}
				A graph $\mc{G}$ is \textbf{perfect} if $\chi(\mc{H}) = \omega(\mc{H})$ for every \emph{induced subgraph} $\mc{H}$ of $\mc{G}$.
			\end{definition}
			
			\begin{corollary}
				Since every induced subgraph of interval graph is also an interval graph, therefore \emph{every interval graph is perfect}.
			\end{corollary}
		
		\subsection{Planer Graphs}
			\begin{definition}
				A \textbf{drawing} of a graph is a way of associating its vertices with points in $\R^2$ and its edges with simple polygonal arcs whose endpoints are the coordinates associated to the vertices that are the endpoints of the edge.
			\end{definition}
			
			\begin{definition}
				A \textbf{planar drawing} of a graph is on in which arcs corresponding to two edges intersect only at a point corresponding to a vertex to which they are both incident.
			\end{definition}

			\begin{definition}
				A graph $\mc{G}$ is \textbf{planar} if it has a planar drawing.
			\end{definition}
			
			\begin{definition}
				A \textbf{face} of a \emph{planar drawing} of a graph is a region bounded by edges and vertices and not containing any other vertices or edges.
			\end{definition}

			\begin{theorem}[Euler's Formula]
				Let $\mc{G}$ be a \emph{connected planer graph} with $V$ vertices and $E$ edges. Then $\mc{G}$ has $f$ faces where 
				\begin{equation}
					V - E + f = 2
				\end{equation}
			\end{theorem}
			
			\begin{theorem}[Generalization of Euler's Formula]
				If a graph $\mc{G}$ is planar, then
				\begin{equation}
					\red{V - E + F = 1 + \tx{\# of components}}
				\end{equation}
				\begin{proof}
					Induction on $E$.\\
					\textbf{Base Case} $E=0$, there are 1 face and $V$ components, above formula holds. \\
					\textbf{Inductive Step} Adding one edge either
					\begin{enumerate}
						\item Eliminate one component,
						\item Or increase one face.
					\end{enumerate}
					Suppose the new edge $e$ reduces number of component by 1, it must be the case that it connects two components in the original graph, and there is only one edge between those two components, it's impossible for such single edge to form one extra face.
				\end{proof}
			\end{theorem}
			
			\begin{theorem}
				\hl{A planar graph with $n$ vertices has at most $3n - 6$ edges when $n \geq 3$.}
			\end{theorem}
			
			\begin{theorem}[Kuratowski's Theorem]
				A graph is planar \ul{if and only if} it does not \emph{contain} either $\ve{K}_5$ or $\ve{K}_{3,3}$.
			\end{theorem}
			
			\begin{definition}
				Graph $\mc{G}$ \textbf{Contain} $\mc{H}$ means $\mc{G}$ has a subgraph that is homeomorphic to $\mc{H}$.
			\end{definition}
			
			\begin{theorem}[Four Colour Theorem]
				Every planar graph has chromatic number at most four.
			\end{theorem}
		
		\section{Inclusion-Exclusion Principle}
			\begin{theorem}[Generalized Inclusion-Exclusion Principle]
				Let $\{S_i\}_{i=1}^N$ be a collection of $N$ sets, then
				\begin{equation}
				\red{
					\left\vert \bigcup_{i=1}^N S_i \right\vert = \sum_{\varnothing \neq J \subseteq [N]} (-1)^{|J|+1} \left\vert \bigcap_{i \in J} S_i \right\vert
				}
				\end{equation}
				where $\bigcap_{i \in J} \left\vert S_i \right\vert$ represents the number of elements satisfying \hl{at least} $|J|$ conditions (where each one condition is specified by one $S_i$).
			\end{theorem}
		
			\subsection{Counting Surjections}
				\begin{theorem}
					The number of \ul{surjections} $f: [n] \to [m]$ can be computed using principle of inclusion-exclusion. Let $S(n, m)$ denote the number of surjections from $[n]$ to $[m]$. We first count the \emph{number of functions that's not surjections}.
					\begin{gather}
						N(S) = \underbrace{\binom{m}{1} (m-1)^n}_{f \tx{ omit at least 1 element}} 
						- \underbrace{\binom{m}{2} (m-2)^n}_{f \tx{ omit at least 2 elements}}
						+ \underbrace{\binom{m}{3} (m-3)^n}_{f \tx{ omit at least 3 elements}} - \dots \\
						= \sum_{k=1}^m (-1)^{k+1} \underbrace{\binom{m}{k} (m-k)^n}_{f \tx{ omit at least $k$ elements}} \\
					\implies S(n, m) = \underbrace{m^n}_{\tx{all } f} - N(S) = \red{\sum_{k=\blue{0}}^m (-1)^{k} \binom{m}{k} (m-k)^n}
					\end{gather}
				\end{theorem}
				
		\section{Derangements and Euler's $\phi$}
			\subsection{Derangements}
				\begin{definition}
					\textbf{Derangements} are \emph{bijective} functions $f:[n] \to [n]$ (rearrangements of $n$ integers) such that 
					\begin{equation}
						\forall i\ f(i) \neq i
					\end{equation}
					and the number of derangements is denoted as $d_n$.
				\end{definition}
				
				\begin{theorem}
					\begin{gather}
						d_n = 
						\underbrace{n!}_{\tx{all }f}
						- \underbrace{\binom{n}{1} (n-1)!}_{\tx{at least 1 }f(i) = i}
						+ \underbrace{\binom{n}{2} (n-2)!}_{\tx{at least 2 }f(i) = i}
						- \underbrace{\binom{n}{3} (n-3)!}_{\tx{at least 3 }f(i) = i} + \dots \\
						= \red{\sum_{k=0}^n (-1)^k \binom{n}{k}(n-k)!} \\
						= \red{\sum_{k=0}^n (-1)^k \frac{n!}{k!}}
					\end{gather}
				\end{theorem}
				
				\begin{theorem}[Portion of Derangements]
					Find the percentage of functions from $[n]$ to $[n]$ that are derangements.
					\begin{gather}
						\frac{d_n}{n!} = \sum_{k=0}^n (-1)^k \frac{1}{k!} \\
						\implies \lim_{n\to \infty} \frac{d_n}{n!} = \frac{1}{e}
					\end{gather}
					By Taylor's sereis $e^x = \sum_{n=0}^\infty \frac{x^n}{n!}$
				\end{theorem}
				
				\begin{proposition}
					\begin{equation}
						d_n = \begin{cases}
							n \cdot d_{n-1} - 1 \tx{ if $n$ is odd} \\
							n \cdot d_{n-1} + 1 \tx{ if $n$ is even}
						\end{cases}
					\end{equation}
				\end{proposition}
				
				\begin{proposition}
					\begin{equation}
						d_n = (n-1)(d_{n-1} + d_{n-2})
					\end{equation}
				\end{proposition}
			\subsection{Euler's $\phi$}
				\begin{example}[Combinatoric Interpretation for $\phi$]
					Draw $n$ points in a circle, connect every pair $k$ apart, for $1 \leq k  \leq n$. Does it make $C_n$ graph.
				\end{example}
				
				\begin{theorem}
					If $k$ \emph{relatively prime} to $n$, then above rule of connecting nodes creates a $C_n$ graph. Therefore, $\phi(n)$ essentially captures the number of $k$'s that construct a $C_n$ graph.
				\end{theorem}
				
			\begin{theorem}
				Let $n \in \mathbb{N}$, and suppose $n$ can be factorized into primes $p_1^{k_1} p_2^{k_2} \cdots p_m^{k_m}$ then
				\[
					\phi(n) = (p_1^{k_1} - p_1^{k_1 - 1})(p_2^{k_2} - p_2^{k_2 - 1}) \cdots (p_m^{k_m} - p_m^{k_m - 1})
				\]
			\end{theorem}
			
		\section{Generating Function}
			\begin{theorem}
				Let 
				\begin{gather}
					A(n) := \sum_{n=0}^\infty a_n x^n \\
					B(n) := \sum_{n=0}^\infty b_n x^n \\
					C(n) := A(n) B(n)
				\end{gather}
				then
				\begin{gather}
					c_n = \sum_{k=j}^n a_j b_{n-j}
				\end{gather}
			\end{theorem}

		\section{Recurrences}
			\subsection{Solving Recurrence Relations (Mar. 20 2019)}
				\begin{definition}
					A \textbf{linear recurrence relation (LRR) of degree $k$} is a sequence $\{a_n\}$ such that for every $n$, 
					\begin{equation}
						\sum_{i=0}^k c_i a_{n+i} = g(n),\ c_i \in \R,\ c_0, c_k \neq 0
					\end{equation}
				\end{definition}
				
				\begin{definition}
					A linear recurrence relation is said to be \textbf{homogenous} if $g(n) = 0$ for every $n$.
				\end{definition}
				
				\begin{remark}
					A recurrence relation sequence can be extended to both directions, so it can be defined as a function $f: \Z \to \R$ (instead of being only defined on $\N$).
				\end{remark}
				
				\begin{definition}
					The \textbf{advancement operator} $A: \R^{\Z} \to \R^{\Z}$ is defined as
					\begin{equation}
						A f(n) := f(n+1)\ \forall n \in \Z
					\end{equation}
				\end{definition}
				
				\begin{proposition}
					In general, a degree $k$ LRR can be expressed using a degree $k$ polynomial on $A$ as
					\begin{equation}
						P(A) f(n) = g(n)
					\end{equation}
				\end{proposition}
				
				\begin{remark}Procedure to solve for the closed form of a LRR:
					\begin{enumerate}[(i)]
						\item Solve for the \textbf{general solution}, note that there are infinitely many general solutions upon some \emph{free parameters}.
						\item Using the given \emph{initial conditions}, we can find exact values of those free parameters and construct \textbf{particular solutions}.
					\end{enumerate}
				\end{remark}
				
				\subsubsection{Preliminary Case: Distinct Real Roots}
					\begin{remark}
						Given that the roots of $P(A)$ are all distinct and real, for example
						\begin{gather}
							P(A) = (A - \alpha) (A - \beta)
						\end{gather}
						then we can solve them separately
						\begin{gather}
							\begin{cases}
								(A - \alpha) f_1 = 0 \implies f_1(n) = \alpha^n b_1 \\
								(A - \beta) f_2 = 0 \implies f_1(n) = \beta^n b_2
							\end{cases}
						\end{gather}
						Note that any $f_1$ satisfying $(A - \alpha) f_1 = 0$ automatically satisfies $P(A) f_1 = 0$, and the same holds for $f_2$.\\
						So we can combine the solutions to construct the general solution.
					\end{remark}
				
				\subsubsection{Generalized Case: Real Roots with Multiplicity}
					\begin{remark}
						Let $P(A)$ be a degree $k$ polynomial, let $\{r_i\}$ denote the set of roots of $P(A)$. For those roots with multiplicity one, they contribute exactly one basis
						\begin{equation}
							b_i r_i^n	
						\end{equation}
						to the general solution. \\For those roots with multiplicity higher than one, for example, the multiplicity of $r_j$ is $d > 1$. Then $r_j$ contributes $k$ basis elements
						\begin{equation}
							\{b_{\ell} n^{\ell} r_j^n\}_{\ell = 0}^{d-1}
						\end{equation}
						while constructing the general solution
					\end{remark}
				
				\subsubsection{Complex Roots}
					\begin{remark}
						Generally, the \hl{existence of complex roots implies alternating patterns in sequence}. And when aggregating basis of general solution together, $i$ would be cancelled out.
					\end{remark}
	
	\section{Probability}
		\begin{definition}[Probability Space]
			A \textbf{probability space} is a triple $(\Omega, \mc{F}, P)$, where $\Omega$ denotes the \emph{sample space}, $\mc{F}$ is a $\sigma$-algebra representing the \emph{event space}. And $P: \mc{F} \to [0, 1]$ is a \emph{probability measure} such that
			\begin{gather}
				P(\varnothing) = 0,\ 
				P(\Omega) = 1 \\
				P(\cup_{i=1}^\infty E_i) = \sum_{i=1}^\infty P(E_i)\ \forall \tx{ pair-wise disjoint } \{E_i\}_{i=1}^\infty \subset \mc{F}
			\end{gather}
		\end{definition}
		
		\begin{proposition}
			On discrete probability space, the probability measure $P: \mc{F} \to [0, 1]$ can be induced from $p: \Omega \to [0, 1]$.
		\end{proposition}
		
		\begin{assumption}
			In this course, while we are constructing the probability space, we always assume 
			\begin{equation}
				\mc{F} := \mc{P}(\Omega)
			\end{equation}
		\end{assumption}
		
		\begin{definition}
			Given probability space $(\Omega, \mc{F}, P)$, two events $E_1, E_2 \in \mc{F}$ are \textbf{independent} if and only if 
			\begin{gather}
				P(E_1 \cap E_2) = P(E_1) P(E_2)
			\end{gather}
		\end{definition}
		
		\begin{proposition}
			Let $E_1, E_2 \in \mc{F}$ such that $E_1, E_2 \neq \varnothing$ and $E_1 \cap E_2 = \varnothing$, then $E_1 \centernot \perp E_2$.
			\begin{proof}
				Note $0 = P(E_1 \cap E_2) = P(E_1)P(E_2) \neq 0$.
			\end{proof}
			\emph{Mutually exclusive non-empty events cannot be independent}.
		\end{proposition}
		
		\begin{definition}
			A \textbf{Bernoulli Trial} is a sequence of \emph{independent and identical experiments} with two outcomes.
		\end{definition}
		
		\begin{definition}
			\textbf{Conditional probability} of event $F \in \mc{P}(\Omega)$ conditioned on event $E$ is defined as 
			\begin{equation}
				P(F|E) := \frac{P(F \cap E)}{P(E)}
			\end{equation}
		\end{definition}
		
		\begin{theorem}[Bayes' Theorem]
			\begin{equation}
				P(A|B) = \frac{P(B|A)P(A)}{P(B)}
			\end{equation}
		\end{theorem}
		
		\begin{definition}
			A \textbf{random variable} $X$ on probability space is defined as a function $X: \Omega \to \R$.
		\end{definition}
		
		\begin{definition}
			The \textbf{expected value} of a random variable $X$ defined on discrete probability space is defined as 
			\begin{equation}
				\expect{X} := \sum_{\omega \in \Omega} P(\{\omega\})X(\omega)
			\end{equation}
		\end{definition}
		
		\begin{proposition}
			Expectation operator is linear.
		\end{proposition}
		
		\begin{proposition}[Binary/Indicator Random Variable]
			\begin{gather}
				\mathds{1}(\mc{P}(\Omega)) = \{0, 1\} \\
				\expect{\mathds{1}} = P(\mathds{1} = 1)
			\end{gather}
		\end{proposition}
		
		\begin{definition}
			A game is \textbf{fair} if the money wined/lost from this game has expected value zero.
		\end{definition}
		
	\section{Discrete Random Variables and Ramsey Theory}
			
	\newpage
	\section*{References}
		\par Keller, M. T., \& Trotter, W. T. (2017). \emph{Applied combinatorics}: Mitchel T. Keller, William T. Trotter. \texttt{https://www.rellek.net/appcomb}
\end{document}





































