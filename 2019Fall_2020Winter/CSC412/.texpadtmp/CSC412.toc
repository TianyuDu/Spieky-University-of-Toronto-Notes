\babel@toc {english}{}
\contentsline {section}{\numberline {1}Introduction}{2}{section.1}% 
\contentsline {section}{\numberline {2}Probabilistic Models}{2}{section.2}% 
\contentsline {section}{\numberline {3}Directed Graphical Models}{2}{section.3}% 
\contentsline {subsection}{\numberline {3.1}Decision Theory}{2}{subsection.3.1}% 
\contentsline {subsection}{\numberline {3.2}Latent Variables}{2}{subsection.3.2}% 
\contentsline {paragraph}{Complete data case}{2}{section*.2}% 
\contentsline {paragraph}{Partially observed dataset}{2}{section*.3}% 
\contentsline {paragraph}{Inference with Latent Variables}{2}{section*.4}% 
\contentsline {subsection}{\numberline {3.3}Mixture Models}{3}{subsection.3.3}% 
\contentsline {paragraph}{Inference using mixture models}{3}{section*.5}% 
\contentsline {paragraph}{Posterior probabilities / responsibilities}{3}{section*.6}% 
\contentsline {paragraph}{Gaussian mixture models}{3}{section*.7}% 
\contentsline {paragraph}{Mixtures of experts}{3}{section*.8}% 
\contentsline {section}{\numberline {4}Exact Inference}{3}{section.4}% 
\contentsline {subsection}{\numberline {4.1}Variable Elimination}{4}{subsection.4.1}% 
\contentsline {subsection}{\numberline {4.2}Intermediate Factors}{4}{subsection.4.2}% 
\contentsline {subsection}{\numberline {4.3}Sum-Product Inference}{5}{subsection.4.3}% 
\contentsline {subsection}{\numberline {4.4}Complexity of Variable Elimination Ordering}{5}{subsection.4.4}% 
\contentsline {section}{\numberline {5}Message passing, Hidden Markov Models, and Sampling}{5}{section.5}% 
\contentsline {subsection}{\numberline {5.1}Message Passing (Computing All Marginals)}{5}{subsection.5.1}% 
\contentsline {subsection}{\numberline {5.2}Markov Chains}{6}{subsection.5.2}% 
\contentsline {paragraph}{Simplification}{6}{section*.10}% 
\contentsline {paragraph}{Parameterization}{7}{section*.11}% 
\contentsline {subsection}{\numberline {5.3}Hidden Markov Models}{7}{subsection.5.3}% 
\contentsline {paragraph}{Joint distribution}{7}{section*.13}% 
\contentsline {paragraph}{Parameterization}{7}{section*.14}% 
\contentsline {subsection}{\numberline {5.4}Forward-backward Algorithm}{7}{subsection.5.4}% 
\contentsline {paragraph}{Smoothing}{7}{section*.15}% 
\contentsline {paragraph}{Filtering}{7}{section*.16}% 
\contentsline {paragraph}{Prediction}{7}{section*.17}% 
\contentsline {subsection}{\numberline {5.5}Procedure of Smoothing (Forward-backward Algorithm)}{8}{subsection.5.5}% 
\contentsline {paragraph}{Forward filtering (encoding)}{8}{section*.18}% 
\contentsline {paragraph}{Backward filtering (decoding)}{8}{section*.19}% 
\contentsline {subsection}{\numberline {5.6}Sampling}{9}{subsection.5.6}% 
\contentsline {paragraph}{Problem 1}{9}{section*.20}% 
\contentsline {paragraph}{Problem 2}{9}{section*.21}% 
\contentsline {paragraph}{Ancestral sampling}{9}{section*.22}% 
\contentsline {paragraph}{Generating marginal samples}{9}{section*.23}% 
\contentsline {paragraph}{Generating conditional samples}{10}{section*.24}% 
\contentsline {section}{\numberline {6}True Skill}{10}{section.6}% 
\contentsline {paragraph}{Question 1}{11}{section*.25}% 
\contentsline {paragraph}{Approximate Inferences}{11}{section*.27}% 
\contentsline {paragraph}{Intractability}{11}{section*.28}% 
\contentsline {subsection}{\numberline {6.1}Variational Inferences}{11}{subsection.6.1}% 
\contentsline {paragraph}{General Idea of Variational Inferences}{11}{section*.29}% 
\contentsline {paragraph}{Kullback\IeC {\textendash }Leibler Divergence}{12}{section*.30}% 
\contentsline {paragraph}{Properties of KL divergence}{12}{section*.31}% 
\contentsline {paragraph}{Re-parameterization Tricks}{12}{section*.32}% 
\contentsline {paragraph}{Stochastic/Automatic Differentiation Variational Inference}{13}{section*.33}% 
\contentsline {paragraph}{Reinforce / Score Function Estimation}{13}{section*.34}% 
\contentsline {paragraph}{Mean-Field Variational Inference}{13}{section*.35}% 
\contentsline {paragraph}{Jensen's Inequality}{13}{section*.36}% 
\contentsline {section}{\numberline {7}Markov Chain Monte Carlo}{14}{section.7}% 
\contentsline {paragraph}{Problem Statement}{14}{section*.37}% 
\contentsline {subsection}{\numberline {7.1}Monte Carlo}{14}{subsection.7.1}% 
\contentsline {paragraph}{Sample}{14}{section*.38}% 
\contentsline {paragraph}{Simple MC estimator}{14}{section*.39}% 
\contentsline {paragraph}{Aside}{15}{section*.40}% 
\contentsline {paragraph}{Why is sampling $x \sim p$ hard?}{15}{section*.41}% 
\contentsline {paragraph}{Lattice (Bad idea!)}{15}{section*.42}% 
\contentsline {paragraph}{Uniform Sampling}{15}{section*.43}% 
\contentsline {paragraph}{Importance Weight Sampler}{15}{section*.44}% 
\contentsline {paragraph}{Rejection Sampling}{15}{section*.45}% 
\contentsline {paragraph}{Limitations}{15}{section*.46}% 
\contentsline {paragraph}{Typical set}{15}{section*.47}% 
\contentsline {paragraph}{Markov Chain Monte Carlo (MCMC)}{15}{section*.49}% 
\contentsline {paragraph}{Metropolis}{16}{section*.50}% 
\contentsline {paragraph}{Random Walk Metropolis}{16}{section*.51}% 
\contentsline {paragraph}{Hamiltonian Monte Carlo}{16}{section*.52}% 
