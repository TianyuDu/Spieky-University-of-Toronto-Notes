\documentclass{article}
\usepackage{spikey}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{soul}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{chngcntr}
\usepackage{centernot}
\usepackage[shortlabels]{enumitem}
\usepackage[margin=1truein]{geometry}
\usepackage{tkz-graph}
\usepackage{dsfont}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{setspace}
\linespread{1.15}
\usepackage[margin=1truein]{geometry}

\counterwithin{equation}{section}
\counterwithin{figure}{section}

\newcommand{\upn}[0]{^{(n)}}
\newcommand{\upk}[0]{^{(k)}}

\pagestyle{fancy}
\lhead{STA447: Stochastic Processes}

\usepackage[
    type={CC},
    modifier={by-nc},
    version={4.0},
]{doclicense}

\title{STA447: Stochastic Processes}
\date{\today}
\author{Tianyu Du}
\begin{document}
    \maketitle
    \tableofcontents
    \newpage
    \section{Markov Chain Probabilities}
    
    \begin{definition}
    	A \textbf{discrete-time, discrete-space, and time-homogenous Markov chain} is a triple of $\mc{S} = (S, v, P)$ in which
    	\begin{enumerate}[(i)]
    		\item $S$ represents the \emph{state space}, which is nonempty and countable;
    		\item \emph{initial probability} $v$, which is a distribution on $S$;
    		\item and \emph{transition probability} $(p_{ij})$ satisfying
    		\begin{align}
    			\sum_{j \in S} p_{ij} = 1\quad \forall i \in S
    		\end{align}
    	\end{enumerate}
    \end{definition}
    
    \begin{definition}
    	A Markov chain satisfies the \textbf{time-homogenous property} if
    	\begin{align}
    		P(X_{n+1}=j|X_n=i) = P(X_1=j|X_0=i) = p_{ij}\quad \forall n \in \N
    	\end{align}
    \end{definition}
    
    \begin{definition}
    	A Markov chain satisfies the \textbf{Markov property} if
    	\begin{align}
    		P(X_{n+1}=j|X_n=i_n, X_{n-1}=i_{n-1}, \cdots, X_0=i_0) = P(X_{n+1}=j|X_n=i_n)
    	\end{align}
    	That is, the chain is \emph{memoryless}.
    \end{definition}
    
    \begin{proposition}
    	As an immediate result from the Markov property, the joint probability
    	\begin{align}
    		P(X_0=i_0, X_1=i_1, X_2=i_2, \cdots, X_n=i_n)
    		&= P(X_0=i_0) P(X_1=i_1, X_2=i_2, \cdots, X_n=i_n|X_0=i_0) \\
    		&= v_{i_0} P(X_1=i_1|X_0=i_0) P(X_2=i_2, \cdots, X_n=i_n|X_0=i_0, X_1=i_1) \\
    		&= v_{i_0} P(X_1=i_1|X_0=i_0) P(X_2=i_2, \cdots, X_n=i_n|X_1=i_1) \tx{ (Markov property)}\\
    		&= v_{i_0} p_{i_0 i_1} \cdots p_{i_{n-1}i_n}
    	\end{align}
    \end{proposition}
    
    \begin{definition}[$n$-step Arrival Probability]
    	Let $m = |S|$ and $\mu_i^{(n)} := P(X_n=i)$ denote \ul{the probability that the state ends up at $i$ after $n$ step (starting point follows $v$)}.
    \end{definition}	
    
    \begin{proposition}
    	\begin{align}
    		\mu^{(n)} = v P^n
    	\end{align}
    \end{proposition}
	\begin{proof}
    	By the law of total expectation,
    	\begin{align}
    		P(X_n=i) &= \sum_{j \in S} P(X_n=i, X_{n-1}=j) \\
    		&= \sum_{j \in S} P(X_n=i | X_{n-1}=j) P(X_{n-1}=j) \\
    		&= \sum_{j \in S} P(X_{n-1}=j) p_{ij} \\
    		&= \sum_{j \in S} \mu_{j}^{(n-1)} p_{ij}
    	\end{align}
    	Let $\mu^{(n)} := \left[\mu_1^{(n)}, \mu_2^{(n)}, \cdots, \mu_m^{(n)} \right] \in \R^{1 \times m}$ and $P = [p_{ij}] \in \R^{m \times m}$. The recurrence relation can be expressed in matrix notation as:
    	\begin{align}
    		\mu^{(n)} = \mu^{(n-1)} P
    	\end{align}
    	where $\mu^{(0)} = v = [v_1, v_2, \cdots, v_m]$ by construction. Define $P^0$ to be the identity matrix $I_m$, then
    	\begin{align}
    		\mu^{(0)} &= v = v P^0 \\
    		\mu^{(1)} &= \mu^{(0)} P = v P^1 \\
    		&\vdots \\
    		\mu^{(n)} &= v P^n
    	\end{align}
    \end{proof}
    
    \begin{definition}[$n$-step Transition Probability]
    	Define 
    	\begin{align}
    		p_{ij}^{(n)} := P(X_{m+n}=j|X_{m}=i)
    	\end{align}
    	to be the probability of arriving state $j$ after $n$ steps, \ul{starting from state $i$}\footnote{In the definition of $\mu^{(n)}_j$, the starting state is random following distribution $v$. While defining $p^{(n)}_{ij}$ the initial state is fixed to be $i$.}. By the time-homogenous property,
    	\begin{align}
    		p_{ij}^{(n)} = P(X_{m+n}=j|X_{m}=i)\quad \forall m \in \N
    	\end{align}
    \end{definition}
    
    \begin{proposition}
    Let $P^{(n)} := [p_{ij}^{(n)}] \in \R^{m \times m}$, then
    	\begin{align}
    		P^{(n)} = P^n
    	\end{align}
    \end{proposition}
    \begin{proof}
    	\ul{Initial Step}: for $n = 1$, $P^{(1)} = P$ by definition. \\
    	\ul{Inductive Step}: for $n \in \N$,
    	\begin{align}
    		p_{ij}^{(n+1)} &= P(X_{n+1}=j|X_0=i) \\
    		&= \sum_{k \in S} P(X_{n+1}=j|X_n = k, X_0=i) P(X_n=k|X_0=i) \\
    		&= \sum_{k \in S} P(X_{n+1}=j|X_n = k) p_{ik}^{(n)} \\
    		&= \sum_{k \in S} p_{ik}^{(n)} p_{kj} \\
    		&= [P^{(n)} P]_{ij}
    	\end{align}
    	Therefore,
    	\begin{align}
    		P^{(n+1)} = P^{(n)} P
    	\end{align}
    	and 
    	\begin{align}
    		P^{(n)} = P^n
    	\end{align}
    \end{proof}
    
    \begin{theorem}
    	\begin{align}
    		p_{i j}^{(m+n)} &=\sum_{k \in S} p_{i k}^{(m)} p_{k j}^{(n)} \\
    		p_{i j}^{(m+s+n)}&=\sum_{k \in S} \sum_{\ell \in S} p_{i k}^{(m)} p_{k \ell}^{(s)} p_{\ell j}^{(n)}
    	\end{align}
    \end{theorem}
    
    \begin{theorem}[Chapman-Kolmogorov Equations (Generalization)]
    	Let $n = (n_1, n_2, \cdots, n_k)$ be a multi-set of non-negative integers, then
    	\begin{align}
    		P^{(\sum_{i=1}^k n_i)} = \prod_{i=1}^k P^{(n_i)}\quad (\dagger)
    	\end{align}
    \end{theorem}
    
    \begin{proof}
    	Prove by induction on the size of multi-set: \\
    	\ul{Base case} is trivial for $k=1$. \\
    	\ul{Inductive step} for $k > 1$, suppose $(\dagger)$ holds for every set of length $k$, consider another multi-set with length $k+1$: $n' = (n_1, n_2, \cdots, n_k, n_{k+1})$. Let $\delta := \sum_{i=1}^k n_i$.
    	\begin{align}
    		P^{(\delta + n_{k+1})}_{ij}
    		&= P(X_{\delta + n_{k+1}}=j|X_0=i) \\
    		&= \sum_{k \in S} P(X_{\delta + n_{k+1}}=j|X_\delta=k, X_0=i) P(X_\delta | X_0=i) \\
    		&= \sum_{k \in S} P(X_{\delta + n_{k+1}}=j|X_\delta=k) P(X_\delta | X_0=i) \\
    		&= \sum_{k \in S} P(X_{n_{k+1}}=j|X_0=k) P(X_\delta=k | X_0=i) \\
    		&= \sum_{k \in S} p^{n_{k+1}}_{kj} p^{(\delta)}_{ik} \\
    		&= [P^{(\delta)} P^{(n_{k+1})}]_{ij} \\
    		\implies P^{(\delta + n_{k+1})} &= P^{(\delta)} P^{(n_{k+1})}
    	\end{align}
    \end{proof}
    
    \begin{corollary}[Chapman-Kolmogorov Inequality]
    	For every $k \in S$,
    	\begin{align}
    		p_{ij}^{(m+n)} \geq p_{ik}^{(m)} p_{kj}^{(n)}
    	\end{align}
    	For $k,\ell \in S$,
    	\begin{align}
    		p_{ij}^{(m+s+n)} \geq p_{ik}^{(m)} p_{k\ell}^{(s)} p_{\ell j}^{(n)}
    	\end{align}
    \end{corollary}

	\begin{proof}[Informal Proof.]
		Note that $p_{ik}^{(m)} p_{kj}^{(n)}$ is exactly the probability of arriving $j$ from $i$ in $m+n$ steps (say, event $E$), \ul{conditioned on passing state $k$ at $m$ steps}. And $p_{ij}^{(m+n)}$ is the unconditional probability of event $E$, which is no less than the 
	\end{proof}

	\subsection{Recurrent and Transience}
	\begin{notation}
		For an arbitrary event $E$,
		\begin{align}
			P_i(E) &:= P(E|X_0=i) \\
			\expe_i(E) &:= \expect{E|X_0=i}
		\end{align}
	\end{notation}
    
    \begin{notation}
    	Let $N(i) := |\{n \geq 1: X_n = i\}|$ denote the number of times the Markov chain arrives state $i$. Note that $N(i)$ does not count the initial state.
    \end{notation}
    
    \begin{definition}
    	Define the \textbf{return probability} from state $i$ to $j$, $f_{ij}$, as the probability of arriving state $j$ starting from state $i$. That is,
    	\begin{align}
    		f_{ij} &= P(\exists n \geq 1\ s.t.\ X_n = j | X_0 = i) \\
    		&= P(N(j) \geq 1 | X_0 = i) \\
    		&= P_i(N(j) \geq 1)
    	\end{align}
    \end{definition}
    
    \begin{proposition}
    	The probability of \ul{firstly arriving $j$, then arriving $k$} (denoted as event $E$) starting from $i$ equals
    	\begin{align}
    		P_i(E) = f_{ij} f_{jk}
    	\end{align}
    \end{proposition}
    
    \begin{proof}
    	\begin{align}
    		P_i(E) &= P(\exists 1 \leq m \leq n \ s.t.\ X_m=j,\ X_n = k) \\
    		&= P_i(\exists 1 \leq m \leq n \ s.t.\ X_n = k|\exists m \geq 1\ s.t.\ X_m=j) P_i(\exists m \geq 1\ s.t.\ X_m=j) \\
    		&= P_{\red{i}}(\exists 1 \leq m \leq n \ s.t.\ X_n = k|\exists m \geq 1\ s.t.\ X_m=j) f_{ij} \\
    		&= P(\exists 1 \leq m \leq n \ s.t.\ X_n = k|X_m=j) f_{ij} \tx{ (Markov property)} \\
    		&= P(\exists 1 \leq n \ s.t.\ X_n = k|X_0=j) f_{ij} \tx{ (time homogenous property)} \\
    		&= f_{ij}f_{jk}
    	\end{align}
    \end{proof}
    
    \begin{corollary}
    	\begin{align}
    		P_i(N(i) \geq k) &= (f_{ii})^k \\
    		P_i(N(j) \geq k) &= f_{ij}(f_{jj})^{k-1}
    	\end{align}
    \end{corollary}

	\begin{corollary}
		\begin{align}
			f_{ij} \geq f_{ik}f_{kj}
		\end{align}
	\end{corollary}
    
    \begin{proposition}
    	$1-f_{i j}$ captures the probability that the Markov chain does not return to $j$ from $i$.
    	\begin{align}
    		1-f_{i j}=P_{i}\left(X_{n} \neq j \text { for all } n \geq 1\right)
    	\end{align}
    \end{proposition}
    
    \begin{definition}
    	A state $i$ in a Markov chain is \textbf{recurrent} if $f_{ii} = 1$. Otherwise, this state is \textbf{transient}.
    \end{definition}
    
    \begin{theorem}[Recurrent State Theorem]
    	The following statements are equivalent:
    	\begin{enumerate}[(i)]
    		\item State $i$ is recurrent (i.e., $f_{ii}=1$);
    		\item $P_i(N(i) = \infty) = 1$, that is, starting from state $i$, state $i$ will be visited infinitely often;
    		\item $\sum_{n=1}^\infty p_{ii}^{(n)} = \infty$.
    	\end{enumerate}
    \end{theorem}

    \begin{proof}
    	$(i) \iff (ii)$:
    	\begin{align}
    		P(N(i) = \infty|X_0=i) &= P(\lim_{k \to \infty} N(i) \geq k| X_0=i) \\
    		&= \lim_{k \to \infty} P(N(i) \geq k| X_0=i) \\
    		&= \lim_{k \to \infty} (f_{ii})^k = 1 \tx{ if and only if } f_{ii} = 1
    	\end{align}
    	$(i) \iff (iii)$:
    	\begin{align}
    		\sum_{n=1}^\infty p_{ii}^{(n)}
    		&= \sum_{n=1}^\infty P(X_n = i | X_0 = i) \\
    		&= \sum_{n=1}^\infty \expe (1_{X_n=i} | X_0 = i) \\
    		&= \expe \left(
    		\sum_{n=1}^\infty 1_{X_n=i} \Big| X_0 = i
    		\right ) \\
    		&= \expe (N(i) | X_0=i) \\
    		&= \sum_{n=k}^\infty k P(N(i)=k | X_0=i) \\
    		&= \sum_{n=k}^\infty P(N(i) \geq k | X_0=i) \\
    		&= \sum_{n=k}^\infty (f_{ii})^k \\
    		&= \infty \tx{ if and only if } f_{ii} = 1
    	\end{align}
    \end{proof}
 
	\begin{theorem}[Transient State Theorem]
		The following statements are equivalent:
    	\begin{enumerate}[(i)]
    		\item State $i$ is transient;
    		\item $P_i(N(i) = \infty) = 0$, that is, state $i$ will only be visited finitely many times;
    		\item $\sum_{n=1}^\infty p_{ii}^{(n)} < \infty$.
    	\end{enumerate}
	\end{theorem}
 
 	\begin{proof}
 		Take negation of the recurrent state theorem.
 	\end{proof}
 
    \begin{lemma}[Stirling's Approximation]
    	\begin{align}
    		n! \approx (n/e)^n \sqrt{2\pi n}
    	\end{align}
    \end{lemma}

    \begin{proposition}
    	For simple random walk, if $p=1/2$, then $f_{ii} = 1\ \forall i \in S$. Otherwise, all states are transient.
    	\begin{align}
    		\forall i \in S,\ f_{ii} = 1 \iff p = \frac{1}{2}
    	\end{align}
    \end{proposition}
    
    \begin{proof}
    	For simplicity, consider state $0$ and the series $\sum_{n=1}^\infty p_{00}\upn$. \\
    	Note that for odd $n$'s, $p_{00}\upn = 0$. \\
    	For all even $n$'s such that $n = 2k$,
    	\begin{align}
    		\sum_{n=1}^\infty p_{00}\upn &= \sum_{k=1}^\infty p_{00}^{(2k)} \\
    		&= \sum_{k=1}^\infty \binom{2k}{k}p^k (1-p)^k \\
    		&= \sum_{k=1}^\infty \frac{2k!}{(k!)^2} p^k (1-p)^k \\
    		&\approx \sum_{k=1}^\infty
    		\frac{(2k/e)^{2k}\sqrt{4 \pi k}}{(k^k e^{-k} \sqrt{2 \pi k})^2}
    		p^k (1-p)^k \\
    		&= \sum_{k=1}^\infty
    		\frac{2^{2k} k^{2k} e^{-2k} 2 \sqrt{\pi k}}
    		{k^{2k} e^{-2k} 2 \pi k}
    		p^k (1-p)^k \\
    		&= \sum_{k=1}^\infty
    		\frac{2^{2k}}
    		{\sqrt{\pi k}}
    		p^k (1-p)^k \\
    		&= \sum_{k=1}^\infty
    		\frac{4^k}
    		{\sqrt{\pi k}}
    		p^k (1-p)^k \\
    		&= \sum_{k=1}^\infty
    		\frac{1}
    		{\sqrt{\pi k}}
    		[4p(1-p)]^k
    	\end{align}
    	When $p = \frac{1}{2}$, 
    	\begin{align}
    		\sum_{n=1}^\infty p_{00}\upn &= \frac{1}{\sqrt{\pi}} \sum_{k=1}^\infty k^{-1/2} \\
    		&= \infty
    	\end{align}
    	When $p \neq \frac{1}{2}$,
    	\begin{align}
    		\sum_{n=1}^\infty p_{00}\upn &< \frac{1}{\sqrt{\pi}} \sum_{k=1}^\infty [4 \pi (1 - p)]^k \\
    		&< \infty
    	\end{align}
    	By the recurrent state theorem, $f_{ii} = 1 \iff p = 1/2$. \\
    	For other $i \neq 0$, the prove is similar.
    \end{proof}
    
    \begin{theorem}[f-Expansion]
    	\begin{align}
    		f_{ij} = p_{ij} + \sum_{k \in S \backslash \{j\}} p_{ik} f_{kj}
    	\end{align}
    \end{theorem}
    
    \begin{proof}
    	\begin{align}
	    	f_{ij} &= P(\exists n \in \Z_{++} \ s.t.\ X_n = j|X_0 = i) \\
	    	&= \sum_{k \in S} P(\exists n \in \Z_{++} \ s.t.\ X_n = j|X_0 = i, X_1 = k) P(X_1=k|X_0=i) \\
	    	&= \sum_{k \in S} P(\exists n \in \Z_{++} \ s.t.\ X_n = j| X_1 = k) P(X_1=k|X_0=i) \tx{ (Markov Property)} \\
	    	&= \underbrace{P(\exists n \in \Z_{++} \ s.t.\ X_n = j| X_1 = j)}_{=1} P(X_1=j|X_0=i)
	    	+ \sum_{k \neq j} f_{kj} P(X_1=k|X_0=i) \\
	    	&= p_{ij} + \sum_{k \neq j} f_{kj} p_{ik}
    	\end{align}
    \end{proof}

	\subsection{Communicating States}

    \begin{definition}
    	State $i$ is said to \textbf{communicate} with state $j$, denoted as $i \to j$, if $f_{ij} > 0$.
    \end{definition}
    
    \begin{proposition}[Alternative Defintion]
    	The following statements are equivalent:
    	\begin{enumerate}[(i)]
    		\item $i \to j$;
    		\item $\exists m \geq 1,\ s.t.\ p_{ij}^{(m)} > 0$.
    	\end{enumerate}
    \end{proposition}
    
    \begin{proof}
    	If $p^{(m)}_{ij} = 0$ for every $m \geq 1$, then it's impossible to get state $j$ from state $i$, that's, $f_{ij} = 0$.
    \end{proof}
    
    \begin{definition}
    	A Markov chain s \textbf{irreducible} if $i \to j\ \forall i,j \in S$. That is, all states are attainable regardless of the starting point.
    \end{definition}
    
    
    \subsection{Recurrence and Transience Equivalence Theorem}
    \begin{theorem}[Sum Lemma]
    	If
    	\begin{enumerate}[(i)]
    		\item $i \to k$;
    		\item $\ell \to j$;
    		\item $\sum_{n=1}^\infty p_{k \ell}\upn = \infty$.
    	\end{enumerate}
    	Then, $\sum_{n=1}^\infty p_{ij}\upn = \infty$.
    \end{theorem}
    
    \begin{proof}
    	Suppose $i \to k$ and $\ell \to j$, then there exists $m$ and $r$ such that $p_{ik}^{(m)} > 0$ and $p_{\ell j}^{(r)} > 0$. \\
    	By the Chapman-Kolmogorov inequality, $p_{ij}^{(m+n+r)} \geq p_{ik}^{(m)} p_{k \ell}^{(n)} p_{\ell j}^{(r)}$. \\
    	Then,
    	\begin{align}
    		\sum_{n=1}^\infty p_{ij}\upn
    		&\geq \sum_{n=m+r+1}^\infty p_{ij}\upn \\
    		&= \sum_{s=1}^\infty p_{ij}^{(m+s+r)} \\
    		&\geq \sum_{s=1}^\infty p_{ik}^{(m)} p_{k \ell}^{(s)} p_{\ell j}^{(r)} \\
    		&= p_{ik}^{(m)} p_{\ell j}^{(r)} \sum_{s=1}^\infty p_{k \ell}^{(s)} = \infty
    	\end{align}
    \end{proof}
    
    \begin{theorem}
    	If $i \leftrightarrow k$, then
    	\begin{align}
    		f_{ii} = 1 \iff f_{kk} = 1
    	\end{align}
    \end{theorem}
    
    \begin{proof}
    	\todo{Proof.}
    \end{proof}
    
    \begin{theorem}[Case Theorem]
    	For an \emph{irreducible} Markov chain, it is either
    	\begin{enumerate}[(a)]
    		\item a \textbf{recurrent} Markov chain: $\forall i \in S,\ f_{ii} = 1$ and  $\sum_{n=1}^\infty p_{ij}\upn = \infty\ \forall i, j \in S$;
    		\item or a \textbf{transient} Markov chain: $\forall i \in S,\ f_{ii} < 1$ and $\sum_{n=1}^\infty p_{ij}\upn < \infty\ \forall i, j \in S$.
    	\end{enumerate}
    \end{theorem}
    
    \begin{proof}
    	\todo{Proof.}
    \end{proof}
    
    \begin{theorem}[Finite Space Theorem]
    	An \emph{irreducible} Markov chain on a \emph{finite} state space is always recurrent.
    \end{theorem}
    
    \begin{proof}
    	Let $i \in S$ (u.i.),
    	\begin{align}
    		\sum_{j \in S} \sum_{n=1}^\infty p_{ij}\upn
    		&= \sum_{n=1}^\infty \sum_{j \in S} p_{ij}\upn \\
    		&= \sum_{n=1}^\infty 1 = \infty
    	\end{align}
    	Because $S$ is finite, $\exists k \in S$ such that $\sum_{n=1}^\infty p_{ik}\upn = \infty$. Therefore, all states are recurrent.
    \end{proof}
    
    \begin{theorem}[Hit-Lemma]
    	Define $H_{ij}$ as the event in which the chain starts from $j$ and visits $i$ without firstly returning to $j$ (\emph{direct path from $j$ to $i$}) \footnote{Notation abuse: $H_{ij}$ describes the event starting from $j$ and ending at $i$, instead of the other way round.}:
    	\begin{align}
    		H_{\red{ij}} := \{\exists n \in \N\ s.t.\ X_n = i \land X_m \neq j\ \forall m < n\}
    	\end{align}
    	If $j \to i$ with $j \neq i$, then $P(H_{ij}|X_0=j) > 0$.
    \end{theorem}
    
    \begin{theorem}[f-Lemma]
    	For all $i, j \in S$, if $j \to i$ and $f_{jj} = 1$, then $f_{ij} = 1$.
    \end{theorem}
    
    \begin{proof}
    	For $i = j$, trivial. \\
    	Suppose $i \neq j$, since $j \to i$, then $P(H_{ij}|X_0=j)> 0$. \\
    	Further,
    	\begin{align}
    		P(X_n \neq j\ \forall n \in \Z_{++} | X_0=j)
    		&\geq P(H_{ij}|X_0=j) P(X_n \neq j\ \forall n \in \Z_{++} | X_0=i)\\
    		\implies 0 = 1 - f_{jj} &\geq P(H_{ij}|X_0=j) (1 - f_{ij}) \\
    		\implies f_{ij} &= 1
    	\end{align}
    \end{proof}
    
    \begin{theorem}[Infinite Returns Lemma]
    	For an \emph{irreducible} Markov chain,
    	\begin{enumerate}[(i)]
    		\item if this chain is recurrent, then $P(N(j)=\infty|X_0=i)=1\ \forall i, j \in S$;
    		\item if this chain is transient, then $P(N(j)=\infty|X_0=i)=0\ \forall i, j \in S$.
    	\end{enumerate}
    \end{theorem}
    
    \begin{proof}
    	Let $i, j \in S$. \\
    	Suppose the chain is irreducible and recurrent, if $i = j$, then $f_{ii} = f_{jj} = 1$. \\
    	Otherwise, $i \neq j$. Since $j \to i$, by the f-Lemma, $f_{jj} = f_{ii} = f_{ij} = f_{ji} = 1$.
    	\begin{align}
    		P(N(j) = \infty | X_0 = i)
    		&= \lim_{k \to \infty} P(N(j) \geq k | X_0 = i) \\
    		&= \lim_{k \to \infty} f_{ij} f_{jj}^{k-1} \\
    		&= 1
    	\end{align}
    	When the chain is transient, $f_{jj} < 1$, and $\lim_{k \to \infty} f_{ij} f_{jj}^{k-1} = 0$.
    \end{proof}
    
    \begin{theorem}[Recurrent Equivalences Theorem]
    	For a \ul{irreducible} Markov chain (so that $i \to j$ for all $i, j \in S$), the following statements are equivalent:
    	\begin{enumerate}[(1)]
    		\item $\exists k, \ell \in S$ such that $\sum_{n=1}^\infty p_{k \ell}\upn = \infty$;
    		\item $\forall i,j \in S,\ \sum_{n=1}^\infty p_{ij}\upn = \infty$;
    		\item $\exists k \in S\ s.t.\ f_{kk} = 1$;
    		\item $\forall j \in S,\ f_{jj} = 1$;
    		\item $\forall i,j \in S,\ f_{ij} = 1$;
    		\item $\exists k, \ell \in S$ such that $P_k(N(\ell) = \infty) = 1$;
    		\item $\forall i, j \in S,\ P_i(N(j) = \infty)$.
    	\end{enumerate}
    \end{theorem}
    
    \subsection{Closed Subset of a Markov Chain}
    
    \begin{definition}
    	For a Markov chain with state space $S$, then any $C \subseteq S$ satisfies
    	\begin{align}
    		p_{ij} = 0\quad \forall i \in C,\ j \notin C
    	\end{align}
    	is a \textbf{closed subset} of the original Markov chain.
    \end{definition}
    
    \begin{proposition}
    	For a simple random walk, if $p \geq \frac{1}{2}$, then $f_{ij} = 1$ for every $j > i$.
    \end{proposition}
    
    \section{Markov Chain Convergence}
    \subsection{Stationary Distributions}
    \begin{definition}
    	Let $\pi \in \Delta(S)$, $\pi$ is \textbf{stationary} for a Markov chain if
    	\begin{align}
    		\pi_j = \sum_{i \in S} \pi_i p_{ij}\quad \forall j \in S
    	\end{align}
    	In matrix notation
    	\begin{align}
    		\pi = \pi P
    	\end{align}
    \end{definition}
    
    \begin{proposition}
    	Let $\pi$ be a stationary distribution of $\mc{M}$, then 
    	\begin{align}
    		\pi_j = \sum_{i \in S} \pi_i p_{ij}^{\red{(n)}}
    	\end{align}
    \end{proposition}
    
    \begin{proof}
    	Using the matrix notation, it can be shown that $\pi = \pi P^n$ for every $n \in \N$. Therefore,
    	\begin{align}
    		\pi_j &= \sum_{i \in S} \pi_i [P^n]_{ij} \\
    		&= \pi_j = \sum_{i \in S} \pi_i p_{ij}\upn \tx{ since } P\upn = P^n
    	\end{align}
    \end{proof}
    
    \begin{definition}
    	A chain is \textbf{doubly stochastic} if
    	\begin{align}
    		\forall j \in S\ \sum_{i \in S} p_{ij} = 1
    	\end{align}
    	That is, for every state $j$, the arrival probability is one.
    \end{definition}
    
    \subsection{Constructing Stationary Distributions}
    \begin{definition}
    	A Markov chain is \textbf{reversible} with respect to a distribution $\pi$ if 
	    \begin{align}
	    	\pi_i p_{ij} = \pi_j p_{ji}\quad \forall i, j \in S
	    \end{align}
	\end{definition}

	\begin{theorem}
		If a chain is reversible with respect to $\pi$, then $\pi$ is a stationary distribution.
	\end{theorem}
	
	\begin{proof}
		\begin{align}
			\sum_{i \in S} \pi_i p_{ij} &= \sum_{i \in S} \pi_j p_{ji} \\
			&= \pi_j \sum_{i \in S} p_{ji} \tx{ (reverse the chain)}\\
			&= \pi_j
		\end{align}
	\end{proof}
	
	\begin{theorem}[Vanishing Probability]
		Let $\mc{M} := (S, v, P)$, if
		\begin{align}
			\forall i, j \in S,\ \lim_{n\to\infty} p_{ij}\upn = 0
		\end{align}
		Then $\mc{M}$ cannot have a stationary distribution.
	\end{theorem}
	
	\begin{proof}
		Suppose, for contradiction, there is a stationary distribution $\pi$. Then,
		\begin{align}
			\pi_j &= \lim_{n \to \infty} \pi_j \\
			&= \lim_{n \to \infty} \sum_{i \in S} \pi_i p_{ij}\upn \\
			&= \sum_{i \in S} \lim_{n \to \infty} \pi_i p_{ij}\upn \\
			&= \sum_{i \in S} \pi_i \lim_{n \to \infty} p_{ij}\upn \\
			&= 0 \neq 1
		\end{align}
		$\contradiction$
	\end{proof}
	
	\begin{lemma}[Vanishing Lemma]
		If $\mc{M}$ has some $k, \ell$ such that $\lim_{n \to \infty} p_{k\ell}\upn = 0$, then for all $i, j \in S$, $\lim_{n \to \infty} p_{ij}\upn = 0$.
	\end{lemma}
	
	\begin{proof}
		
	\end{proof}
	
	\begin{corollary}
		For an \ul{irreducible} Markov chain, either
		\begin{enumerate}[(i)]
			\item $\lim _{n \rightarrow \infty} p_{i j}^{(n)}=0$ for all $i, j \in S$;
			\item $\lim _{n \rightarrow \infty} p_{i j}^{(n)}\neq 0$ for all $i, j \in S$.
		\end{enumerate}
	\end{corollary}
	
	\begin{corollary}
		If there exists $i, j \in S$, $\lim_{n \to \infty} p_{ij}\upn = 0$, then $\mc{M}$ cannot have a stationary distribution.
	\end{corollary}
	
	\begin{corollary}
		A Markov chain which is \ul{irreducible} and \ul{transient} cannot have a stationary distribution.
	\end{corollary}
	
	\begin{definition}
		The \textbf{period} of a state $i$ is the greatest common divisor of the set
		\begin{align}
			\Phi = \{n \geq 1: p_{ii}\upn > 0\}
		\end{align}
		Note that if $f_{ii} = 0$, then $\Phi = \varnothing$, and period is not well-defined.
	\end{definition}
	
	\begin{definition}
		If all states in $\mc{M}$ has period of 1, then $\mc{M}$ is said to be \textbf{aperiodic}.
	\end{definition}
	
	\begin{lemma}[Equal Period Lemma]
		If $i \leftrightarrow j$, then the periods of $i$ and $j$ are equal.
	\end{lemma}
	
	\begin{corollary}
		If $\mc{M}$ is \ul{irreducible}, then all states have the same period.
	\end{corollary}
	
	\begin{corollary}
		If $\mc{M}$ is \ul{irreducible}, and $p_{ii} > 0$ for some $i \in S$ (so that state $i$ has period 1), then the whole chain $\mc{M}$ is aperiodic.
	\end{corollary}
	
	\subsection{Convergence Theorem}
	
	\begin{theorem}[Markov Chain Convergence Theorem]
		If a Markov chain $\mc{M}$ is 
		\begin{enumerate}[(i)]
			\item irreducible;
			\item and aperiodic;
			\item with a stationary distribution $\pi$
		\end{enumerate}
		Then 
		\begin{align}
			\lim_{n \to \infty} p_{ij}\upn = \pi_j\quad\forall i, j \in S
		\end{align}
		and for any initial probability $v$,
		\begin{align}
			\lim_{n \to \infty} P(X_n = j) = \pi_j
		\end{align}
	\end{theorem}
	
	\begin{theorem}[Stationary Recurrence Theorem]
		For an irreducible chain $\mc{M}$ with a stationary distribution, $\mc{M}$ is always recurrent.
	\end{theorem}
	
	\begin{proposition}
		If a state $i$ has $f_{ii}$ and is aperiodic, then there is $n_0(i) \in \N$ such that
		\begin{align}
			p_{ii}\upn > 0\quad \forall n \geq n_0(i)
		\end{align}
	\end{proposition}

	\begin{corollary}
		If a chain is \ul{irreducible} and \ul{aperiodic}, then for any states $i, j \in S$, there is $n_0(i, j) \in \N$ such that
		\begin{align}
			p_{ii}\upn > 0\quad \forall n \geq n_0(i)
		\end{align}
	\end{corollary}
	
	\begin{lemma}[Markov Forgetting Lemma]
		If a Markov chain $\mc{M}$ is
		\begin{enumerate}[(i)]
			\item irreducible;
			\item and aperiodic;
			\item with a stationary distribution $\pi$
		\end{enumerate}
		then for all $i, j, k \in S$, then
		\begin{align}
			\lim_{n \to \infty} \abs{
				p_{ik}\upn - p_{jk}\upn
			} = 0
		\end{align}
	\end{lemma}
	
	\begin{corollary}
		If $\mc{M}$ is \ul{irreducible} and \ul{aperiodic} then it has at most one stationary distribution.
	\end{corollary}
\end{document}


























