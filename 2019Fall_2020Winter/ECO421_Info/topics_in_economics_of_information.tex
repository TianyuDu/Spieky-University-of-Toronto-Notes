\documentclass{article}
\usepackage{spikey}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{soul}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{chngcntr}
\usepackage{centernot}
\usepackage[shortlabels]{enumitem}
\usepackage[margin=1truein]{geometry}
\usepackage{tkz-graph}
\usepackage{dsfont}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{setspace}
\linespread{1.15}
\usepackage[margin=1truein]{geometry}

\counterwithin{equation}{section}
\counterwithin{figure}{section}

\pagestyle{fancy}
%\lhead{Topics in Economics of Information}

\usepackage[
    type={CC},
    modifier={by-nc},
    version={4.0},
]{doclicense}

\title{ECO421: Topics in Economic of Information \\ \large Games with Incomplete Information}
\date{\today}
\author{Tianyu Du}
\begin{document}
    \maketitle
    \tableofcontents
    \newpage
    
    \section{Knowledge}
    \subsection{Information Structure}
    \begin{notation}
    	Let $\Omega$ denote the all possible states of world, and let $A$ denote the set of all agents. Let $\omega^* \in \Omega$ denote the true state of world.
    \end{notation}
	
	\begin{definition}
		Every $E \subseteq \Omega$ is called an \textbf{event} or a type/piece of \textbf{information}.
	\end{definition}
	
    \begin{definition}
    	Let $E \subseteq \Omega$ be a piece of information and $i \in A$, and we say agent $i$ \textbf{knows} $E$ in state $\omega \in \Omega$ if this agent knows
    	\begin{enumerate}[(i)]
    		\item The true state of world $\omega^* \in E$;
    		\item but, all $\omega \in E$ are considered to be possible.
    	\end{enumerate}
    	Remark: the agent is certain about the true state $\omega^*$ if and only if $E = \{\omega^*\}$.
    \end{definition}
    
    \begin{definition}
    	For an agent $i \in A$, the \textbf{information structure} of this agent, $\mc{T}_i$, is a \ul{partition} of $\Omega$ into types of information.
    \end{definition}
    
    \begin{notation}
    	Each element of the partition corresponds to one piece of information (an event). \\
    	(Information encoding) One may define a mapping $T_i(\cdot): \Omega \to \mc{T}_i$, such that for every $\omega \in \Omega$, let $T_i(\omega) \in \mc{T}_i$ denote the piece of information known by this agent in state $\omega$. \\
    	Equivalently, $T_i(\omega) \subseteq \Omega$ denotes the set of all states that agent $i$ considers possible given her information in state $\omega$.
    \end{notation}
    
    \begin{remark}[Interpretation]
    	At some state of world, $\omega^*$, agent $i$ receives information $T_i(\omega^*)$ but \ul{not} $\omega^*$. This agent only knows $\omega^* \in T_i(\omega^*)$. The information encoding mechanism is a kind of blurring system preventing the agent from identifying the exact $\omega^*$.
    \end{remark}
    
    \subsection{Knowledge Space}
    \begin{definition}
    	A \textbf{knowledge-based type space} is defined to be a tuple
    	\begin{align}
    		(\Omega, (\mc{T}_i)_{i \in A})
    	\end{align}
    	where $\mc{T}_i$ is an information structure of agent $i$.
    \end{definition}
    
    \begin{definition}
    	An event $E \subseteq \Omega$ is \textbf{true} in state $\omega^* \in \Omega$ if $\omega^* \subseteq E$. 
    \end{definition}
   
   	\begin{definition}[Equivalent Definition]
   		An agent $i$ is said to \textbf{know} event $E$ in state $\omega^*$ if and only if
   		\begin{align}
   			T_i(\omega^*) \subseteq E
   		\end{align}
   		That is, the true state $\omega^* \in T_i(\omega) \subseteq E$, so that agent $i$ is certain that $E$ is true.
   	\end{definition}
   	
   	\begin{definition}
   		Define $K_i(E)$ to be the set of states in which agent $i$ knows $E$ to be true, that is,
   		\begin{align}
   			K_i(E) := \{\omega: T_i(\omega) \subseteq E\} \subseteq \Omega
   		\end{align}
   	\end{definition}
   	
   	\begin{theorem}
   		Every agent knows their own information structure, that is,
   		\begin{align}
   			K_i (T_i(\omega)) = T_i(\omega)\quad \forall \omega \in \Omega
   		\end{align}
   	\end{theorem}
   	
   	\begin{theorem}
   		Every agent knows the existence of the world,
   		\begin{align}
   			K_i(\Omega) = \Omega
   		\end{align}
   	\end{theorem}
   	
   	\begin{definition}
   		Agent $i$ has \textbf{better information} than agent $j$ if
   		\begin{align}
   			\forall \omega \in \Omega,\ T_i(\omega) \subseteq T_j(\omega)
   		\end{align}
   		That is, agent $i$'s information structure is a finer partition of $\Omega$.
   	\end{definition}
   	
   	\subsection{Learning}
   	\begin{definition}
   		Given a piece of information $F \subseteq \Omega$ characterizing that $\omega^* \in F$, suppose $F$ is known by all agents,
   		the new \textbf{information structure updated by $F$} is defined to be
   		\begin{align}
   			(\Omega^F, (T^F_i(\cdot)))
   		\end{align}
   		where
   		\begin{align}
   			\Omega^F &= \Omega \cap F \\
   			T_i^F(\omega) &= T_i(\omega) \cap F\quad \forall \omega \in \Omega^F
   		\end{align}
   	\end{definition}
   	\begin{definition}
   		The set of states where $E \subseteq \Omega^F$ is known given $F$ is 
   		\begin{align}
   			K_i(E|F) &:= \left\{
   			\omega \in \Omega^F: T_i^F(\omega) \subseteq E
   			\right\} \\
   			&= \left\{
   			\omega \in \Omega^F: T_i(\omega) \cap F \subseteq E
   			\right\}
   		\end{align}
   	\end{definition}
   	
   	\begin{notation}
   		For $i, j \in A$, the states in which $i$ knows that player $j$ knows $E$ can be denoted as
   		\begin{align}
   			K_i(K_j(E))
   		\end{align}
   	\end{notation}
   	
   	\subsection{Knowledge Hierarchies and Common knowledges}
   	\begin{definition}
   		An event $E \subseteq \Omega$ is a \textbf{common knowledge} in state $\omega$ if everyone knows $E$ and knows everyone else possesses the same information. That is:
   		\begin{align}
   			\omega &\in \bigcap_{i \in A} K_i(E) \\
   			\omega &\in \bigcap_{j \in A} K_j \left(\bigcap_{i \in A} K_i(E) \right) \\
   			\omega &\in \bigcap_{k \in A} K_k \left[
	   			\bigcap_{j \in A} K_j \left(\bigcap_{i \in A} K_i(E) \right)
   			\right] \\
   			&\vdots
   		\end{align}
   	\end{definition}
   	
   	\section{Beliefs}
   	\subsection{Type Space}
   	\begin{definition}
   		A \textbf{type space} is a triple $(\Omega, (T_i), (\mu_i(\omega, t_{-i}|t_i)))$.
   		\begin{enumerate}[(i)]
	   		\item $\Omega$ is the state space. 
	   		\item $T_i$ is the collection of types for player $i$.
	   		\item The \textbf{belief} of type $t_i$ player $i$ is a probability distribution:
	   		\begin{align}
	   			\mu_i(\omega, t_{-i}|t_i) \in \Delta(\Omega \times T_{-i})\tx{ where } T_{-i} = \prod_{j \neq i} T_j
	   		\end{align}
	   	\end{enumerate}
   	\end{definition}
   	
   	\begin{remark}
   		In the definition, we were overloading the notion of $T_i$, here $T_i$ is a fixed set representing the collection of all possible types of player $i$. In the previous section, $T_i(\cdot)$ was a function maps a state $\omega \in \Omega$ to the information possessed by agent $i$ in state $\omega$.
   	\end{remark}
   	
   	\begin{proposition}[Relation between type space and knowledge space]
   		For a type space $(\Omega, (T_i), (\mu_i(\omega, t_{-i}|t_i)))$, define
   		\begin{align}
   			\Omega^{*}:=\Omega \times T_{1} \times \ldots \times T_{n}
   		\end{align}
   		and for every $\omega^* \in \Omega^*$, define
   		\begin{align}
   			T^*_i(\omega^*) \equiv T^*_i(\omega, t_{1:n}) = \{(\omega', t'_{1:n}): t'_i = t_i \} \subseteq \Omega^*
   		\end{align}
   		That is, player $i$ only knows his own type and cannot distinguish types of any other players. And $T^*_i(\cdot)$  defines a partition over $\Omega^*$. Therefore, $(\Omega^*, (T^*_i(\cdot)))$ is a knowledge space induced by the type space.
   	\end{proposition}
   	
   	\subsection{Prior and interim beliefs}
   	
   	\begin{definition}
   		The \textbf{interim belief} of player $i$ is defined to be the distribution $\mu_i(\omega, t_{-i}|t_i)$ in the type space.
   	\end{definition}
   	
   	\begin{definition}
   		The \textbf{posterior belief} of player $i$ is defined as the belief after the player learns the types of all other players:
   		\begin{align}
   			\mu_i(\omega|t_{1:n})
   		\end{align}
   	\end{definition}
   	
   	\begin{definition}
   		The \textbf{prior belief} $\mu$, is a distribution over $(\omega, t_i, t_{-i})$. Then player $i$ can compute the prior belief on $t_i$ by marginalizing
   		\begin{align}
   			\mu\left(t_{i}\right)=\sum_{\omega, t_{-i}} \mu_{i}\left(\omega, t_{-i}, t_{i}\right)
   		\end{align}
   		Note that the prior belief $\mu$ does not have a subscript $i$ because the prior belief is the same for all players.
   	\end{definition}
   	
   	\begin{remark}
	   	Ex-ante approach:
	   	\begin{enumerate}[(i)]
	   		\item Player $i$ learn (overall) prior $\mu\left(\omega, t_{i}, t_{-i}\right)$;
	   		\item Player $i$ deduces his type prior following
	   		\begin{align}
	   			\mu\left(t_{i}\right)=\sum_{\omega, t_{-i}} \mu_{i}\left(\omega, t_{-i}, t_{i}\right)
	   		\end{align}
	   		\item Player $i$ deduces interim belief following
	   		\begin{align}
	   			\mu_{i}\left(\omega, t_{-i} |t_i \right)
	   			=\frac{\mu\left(\omega, t_{i}, t_{-i}\right)}{\mu\left(t_{i}\right)}
	   		\end{align}
	   	\end{enumerate}
   	\end{remark}
   	
   	\subsection{Bayesian Games}
   	\begin{definition}
   		A \textbf{Bayesian game} consists of
   		\begin{enumerate}[(i)]
   			\item A set of players $i \in \{1, \cdots, N\}$;
   			\item Action space $A_i$ for each player $i$;
   			\item Type space $(\Omega, (T_i), \mu_i)$;
   			\item Payoff function for each player $i$:
   			\begin{align}
   				u_{i}\left(a_{i}, a_{-i}, t_{i}, t_{-i}, \omega\right)
   			\end{align}
   			\item Strategies for each player $i$, $\sigma_i: T_i \to \Delta (A_i)$.
   		\end{enumerate}
   	\end{definition}
   	
   	\begin{assumption}
   		Players are assumed to maximize their expected payoffs. Moreover, players calculate their expected payoffs with respect to their interim beliefs.
   	\end{assumption}
   	
   	\begin{definition}
   		The \textbf{expected payoff} of player $i$ with type $t_i$ from a \ul{pure strategy} $a_i \in A_i$ given opponents' strategies $\sigma_{-i}$ is
   		\begin{align}
   			U_{i}\left(a_{i}, \sigma_{-i}, t_{i}\right)=\sum_{t_{-i}, \omega} u_{i}\left(a_{i}, \sigma_{-i}\left(t_{-i}\right), t_{i}, t_{-i}, \omega\right) \underbrace{\mu_{i}\left(t_{-i}, \omega | t_{i}\right)}_{\tx{interim belief}}
   		\end{align}
   	\end{definition}

   	\begin{definition}[Generalization]
   		The \textbf{expected payoff} of player $i$ with type $t_i$ from a \ul{mixed strategy} $\sigma_i \in \Delta(A_i)$ given opponents' strategies $\sigma_{-i}$ is
   		\begin{align}
   			U_{i}\left(\sigma_{i}, \sigma_{-i}, t_{i}\right)
   			=\sum_{a_i \in \sigma_i(t_i)}
   			\sigma_i(t_i)(a_i) \sum_{t_{-i}, \omega} u_{i}\left(a_{i}, \sigma_{-i}\left(t_{-i}\right), t_{i}, t_{-i}, \omega\right) \mu_{i}\left(t_{-i}, \omega | t_{i}\right)
   		\end{align}
   	\end{definition}
   	
   	\begin{definition}
   		An action $a_i$ is a \textbf{best response} \ul{for type $t_i$ against $\sigma_{-i}$} if
   		\begin{align}
   			\forall a_i' \in A_i \backslash \{a_i\},\ U_{i}\left(a_{i}, \sigma_{-i} ; t_{i}\right) \geq U_{i}\left(a_{i}^{\prime}, \sigma_{-i} ; t_{i}\right)
   		\end{align}
   	\end{definition}
   	
   	\begin{definition}
   		An action $a_i$ is \textbf{strictly dominated} \ul{for type $t_i$} if
   		\begin{align}
   			\exists a_i' \in A_i \backslash \{a_i\}\ s.t.\ \forall \sigma_{-i}\ U_{i}\left(a_{i}, \sigma_{-i} ; t_{i}\right)<U_{i}\left(a_{i}^{\prime}, \sigma_{-i} ; t_{i}\right)
   		\end{align}
   	\end{definition}
   	
   	\begin{definition}
   		A \textbf{Bayesian Nash equilibrium} is a profile of strategies $\sigma=\left(\sigma_{1}, \ldots, \sigma_{l}\right)$ such that \ul{for each player $i$ and each type $t_i$ of player $i$}, the action $\sigma_{i}\left(t_{i}\right)$ is a best response for type $t_{i}$ against $\sigma_{-i}$.
   	\end{definition}
   	
   	\section{Adverse Selection}
   	\subsection{Market for Lemons}
   	\par Two types of cars
   	\begin{enumerate}
   		\item high quality $P(h) = \lambda$
   		\item low quality $P(l) = 1 - \lambda$
   	\end{enumerate}
   	Assuming sellers know the quality of car but buyers don't.
   	\begin{enumerate}
   		\item $b_\theta$: value of car with type $\theta \in \{h, l\}$ for the buyer.
   		\item $s_\theta$ value for the seller.
   	\end{enumerate}
   	Assume
   	\begin{enumerate}
   		\item $b_h > b_l$ and $s_h > s_l$ (defining what high quality is);
   		\item $b_h > s_h$ and $b_l > s_l$ (benefit to trade).
   	\end{enumerate}
   	Therefore, if the car quality is observed, then it is beneficial to trade, and two prices exist such that
   	\begin{align}
   		b_\theta > p_\theta > s_\theta\ \forall \theta \in \{l, h\}
   	\end{align}
   	If the quality is not observed, only one price $p$ exists. \\
   	Seller type $h$ sells if and only if $p > s_h$ and type $l$ if and only if $p > s_l$. \\
   	\textbf{Seller behaviours}:
   	\begin{enumerate}[(a)]
   		\item Both types sell: $p > s_h$;
   		\item Only type $h$ sells: $s_h > p > s_l$;
   		\item Nobody wants to sell: $s_l > p$.
   	\end{enumerate}
   	\textbf{Buyer behaviours}:
   	\begin{enumerate}[(a)]
   		\item Both types sell: buyers buy if average quality $\lambda b_ + (1 - \lambda)b_l > p$;
   		\item Only type $l$ sells, buyers buy if
   		\begin{align}
   			\exists\ p\in \R_+\ s.t.\ b_l > p > s_l
   		\end{align}
   	\end{enumerate}
   	
   	\paragraph{Aggregate conditions}
   	\begin{enumerate}[(a)]
   		\item Trade with both types if and only if
   		\begin{align}
   			\exists\ p\in \R_+\ s.t. \lambda b_h + (1 - \lambda) b_l > p > s_h
   		\end{align}
   		That is, 
   		\begin{align}
   			\lambda b_h + (1 - \lambda) b_l > s_h\quad (\dagger)
   		\end{align}
   		\item The second case (low quality trading) is always satisfied given assumption $b_l > s_l$.
   	\end{enumerate}
   	The \textbf{market failure} occurs because high quality cars are withdrawn from the market.
   	\subsection{Market for Insurances}
   	\begin{itemize}
   		\item $p$ denote the price;
   		\item $C$ denote the compensation (paid out if claim);
   		\item $D$ denote the damage;
   		\item $\Delta$ denote value of peace of mind;
   		\item $\pi_h > \pi_l$ probability of damage;
   		\item $\lambda = P(h)$.
   	\end{itemize}
   	
   	\paragraph{Buyer behaviours} for type $\theta \in \{l, h\}$:
   	\begin{enumerate}
   		\item Buy: $\Delta - p + \pi_\theta (C - D)$;
   		\item Don't buy: $\pi_\theta(-D)$.
   	\end{enumerate}
   	Buy if and only if
   	\begin{align}
   		\Delta - p + \pi_\theta (C - D) \geq \pi_\theta(-D) \\
   		\implies p \leq \Delta + \underbrace{\pi_\theta C}_{\tx{expected compensation}}\quad (\dagger\dagger)
   	\end{align}
   	Not that ($\dagger\dagger$) is independent from $D$.
	
   	\paragraph{Seller behaviour}
   	\begin{enumerate}[(a)]
   		\item If both types buy insurance:
   		\begin{align}
   			\pi = \lambda \pi_h + (1 - \lambda) \pi_l
   		\end{align}
   		Sellers sell if 
   		\begin{align}
   			p - \pi C \geq 0
   		\end{align}
   		Aggregated conditions:
   		\begin{align}
   			\exists\ p \in \R_+\ &s.t.\ \Delta + \pi_l C \geq p \geq \pi C \\
   			\iff \Delta + \pi_l C &> \lambda \pi_h + (1 - \lambda) \pi_l C \\
   			\iff \Delta &> \lambda (\pi_h - \pi_l) C \\
   			\iff \pi_h - \pi_l &< \frac{\Delta}{\lambda C}\quad (\dagger)
   		\end{align}
   		($\dagger$) says both types of buyers participate in the market and sellers sell insurances if \ul{the difference between two types is insignificant}. \\
   		If ($\dagger$) is not satisfied, then there is \ul{no trade with both type (only one type trades)}.
   		\item (\ul{Price is high enough so that low type does not want to buy}) Suppose only type $h$ trades, insurer sells if and only if 
   		\begin{align}
   			\pi _h C < p 
   		\end{align}
   		And buyer type $h$ wants
   		\begin{align}
   			\Delta + \pi_h C > p
   		\end{align}
   		Given $\Delta > 0$, there would always be trading between sellers and type $h$ buyers.
   	\end{enumerate}
   	
   	\subsection{Monopoly Under Adverse Selection}
   	\paragraph{Sellers}
   	\begin{enumerate}
   		\item Decision $(p, q)$ where $p$ denotes price and $q$ denotes quality;
   		\item Profit $\pi(p, q) = p - 1/2q^2$.
   	\end{enumerate}
   	\paragraph{Buyers}
   	\begin{enumerate}
   		\item $u_\theta (p, q) = \theta q - p$;
   		\item $\theta$ denotes the taste for quality: $\theta_h > \theta_l$;
   		\item $P(\theta_h) = \lambda$.
   	\end{enumerate}
   	
   	\paragraph{Case 1: 1th degree price discrimination}
   	Monopolist knows type $\theta$ for each consumer, and design good such that
   	\begin{align}
   		&\max_{(p, q)} p - 1/2 q^2 \\
   		s.t.&\ \theta q - p \geq 0 \tx{ (Individual Rationality)}
   	\end{align}
   	Solution:
   	\begin{align}
   		q^* = \theta^*,\ p^* = \theta^{*2}
   	\end{align}
   	
   	\paragraph{Case 2: 2nd degree price discrimination} Monopolist does not the $\theta$. \\
   	Monopolist design a \emph{menu} of products
   	\begin{align}
   		(p_1, q_1), (p_2, q_2), \cdots, (p_j, q_j)
   	\end{align}
   	Provided there are only two types, it is sufficient to construct a menu with two types:
   	\begin{align}
   		 (p_l, q_l), (p_h, q_h)
   	\end{align}
   	Note that it is possible that $(p_l, q_l) = (p_h, q_h)$. Further, it is allowed to exclude certain type of consumers by setting $(p_i, q_i) = (0, 0)$. \\
   	\textbf{Monopolist's problem} designing an optimal menu such that both types are willing to purchase and each type only buy the bundle designed for them.
   	\begin{align}
   		\max_{(p_l, q_l) \in \R^2_+, (p_h, q_h) \in \R^2_+} &\lambda (p_h - 1/2 q_h^2) + (1 - \lambda) (p_l - 1/2 q_l^2) \\
   		\theta_l q_l - p_l &\geq 0 \tx{ (Individual rationality for low type)} \\
   		\theta_h q_h - p_h &\geq 0 \tx{ (Individual rationality for high type)} \\
   		\theta_h q_h - p_h &\geq \theta_h q_l - p_l \tx{ (Incentive compatibility for high type)} \\
   		\theta_l q_l - p_l &\geq \theta_l q_h - p_h \tx{ (Incentive compatibility for low type)}
   	\end{align}
   	\begin{proposition}[Step 0]
   		\begin{align}
   			\tx{IC}_h \land \tx{IC}_l \implies q_h \geq q_l
   		\end{align}
   	\end{proposition}
   	
   	\begin{proof}
   		\begin{align}
   			\tx{IC}_h \iff \theta_h (q_h - q_l) \geq p_h - p_l \\
   			\tx{IC}_l \iff \theta_l (q_l - q_h) \geq p_l - p_h
   		\end{align}
   		Summing two conditions:
   		\begin{align}
   			(q_h - q_l)(\theta_h - \theta_l) \geq 0
   		\end{align}
   		Provided that $\theta_h > \theta_l$,
   		\begin{align}
   			q_h \geq q_l
   		\end{align}
   	\end{proof}
   	
   	\begin{proposition}[Step 1]
   		\begin{align}
   			\tx{IC}_h \land \tx{IR}_l \implies \tx{IR}_h
   		\end{align}
   	\end{proposition}
   	
   	\begin{proof}
   		\begin{align}
   			\tx{IC}_h \iff \theta_h q_h - p_h &\geq \theta_h q_l - p_l \\
   			\implies \theta_h q_h - p_h &\geq \theta_h q_l - p_l \geq \theta_l q_l - p_l \geq 0 \tx{ (By IR for low type)}\\
   			\implies \theta_h q_h - p_h &\geq 0 \iff \tx{IR}_h
   		\end{align}
   	\end{proof}
   	
   	\begin{proposition}[Step 2]
   		Given step 1, IC$_h$ constrain is binding.
   	\end{proposition}
   	
   	\begin{proposition}[Step 3]
   		IC$_h$ is binding and $q_h \geq q_l$ imply IC$_l$.
   	\end{proposition}
   	
   	\begin{proof}
   		\begin{align}
   			\tx{binding IC}_h \iff \theta_h(q_h - q_l) = p_h - p_l \\
   			\implies \theta_l(q_h - q_l) \leq \theta_h(q_h - q_l) = p_h - p_l \\
   			\implies \theta_l(q_h - q_l) \leq p_h - p_l \\
   			\iff \theta_l q_l - p_l \geq \theta_l q_h - p_h \\
   			\iff \tx{IC}_l
   		\end{align}
   	\end{proof}
   	
   	\begin{proposition}[Step 4]
   		IR$_l$ is binding.
   	\end{proposition}
   	
   	\paragraph{Solving the reduced problem}
   	\begin{align}
   		\max_{(p_l, q_l) \in \R^2_+, (p_h, q_h) \in \R^2_+} &\lambda (p_h - 1/2 q_h^2) + (1 - \lambda) (p_l - 1/2 q_l^2) \\
   		\theta_l q_l - p_l &= 0 \tx{ (Individual rationality for low type)} \\
   		\theta_h q_h - p_h &= \theta_h q_l - p_l \tx{ (Incentive compatibility for high type)}
   	\end{align}
   	The problem reduced to
   	\begin{align}
   		\max_{q_l, q_h \in \R_+} ...
   	\end{align}
   	Solving the problem gives
   	\begin{align}
   		q_h &= \theta_h \\
   		q_l &= \theta_l - \frac{\lambda}{1 - \lambda}(\theta_h - \theta_l)
   	\end{align}
   	
   	\section{Communication}
   	\subsection{Cheap Talk}
   	\begin{remark}[Difference between communication and signalling]
   		The message is costless in communication setup, payoffs of sender and receiver depend only on their actions and the state of the world, but independent from the message. In contrast, signalling is costly and the payoff of the sender is in general lower if he chooses to send signal.
   	\end{remark}
   	
   	\begin{definition}
   		A communication is a \textbf{cheap talk} if messages have no cost, no payoff consequences at all.
   	\end{definition}
   	
   	
   	\subsection{Verifiable Talk}
   	\begin{definition}
   		A communication is a \textbf{verifiable talk} if the sender has a full-proof evidence and may choose to show it.
   	\end{definition}
   	
   	\section{Extensive Form Games with Incomplete Information}
   	\begin{definition}
   		A \textbf{terminal history} is a set of action tuples $h=(a_1, \cdots, a_t)$ such that the game ends after the last action is taken.
   	\end{definition}
   	
   	\begin{definition}
   		A \textbf{sub-history} is a proper subset of a terminal history.
   	\end{definition}
   	
   	\begin{definition}
   		An \textbf{extensive-form game} consists of
   		\begin{enumerate}[(i)]
   			\item A set of players $N = \{1, \cdots, I\}$;
   			\item A set of histories $H = T \cup S$ where $T$ denotes terminal histories and $S$ is the set of sub-histories;
   			\item A player correspondence $P: S \rightrightarrows N$;
   			\item Actions $A_i(h)$ for each $i \in P(h)$ for every $h \in S$;
   			\item Payoff functions $u_i:T \to \R$ for defined for every player $i$ on every terminal history $z \in T$;
   		\end{enumerate}
   	\end{definition}
   	
   	\begin{definition}
   		A \textbf{strategy} $\sigma_i$ for player $i$ is a function defined on 
   		\begin{align}
   			\{h\ s.t.\ i \in P(h)\}
   		\end{align}
   		maps from $h$ to $\Delta A_i(h)$.
   	\end{definition}
   	
   	\begin{definition}
   		A \textbf{strategy profile} is a set of strategies $\sigma = (\sigma_i)_{i \in N}$. Each $\sigma$ uniquely determines the terminal history and the outcome.
   	\end{definition}
   	
   	\begin{definition}
   		A \textbf{Nash equilibrium} is a profile of strategies $\left(\sigma_{1}, \ldots, \sigma_{n}\right)$ such that each player's strategy is a best response to the other strategies.
   	\end{definition}
   	
   	\begin{definition}
   		A \textbf{subgame perfect Nash equilibrium} (SPNE) is a profile of strategies $\left(\sigma_{1}, \ldots, \sigma_{n}\right)$ such that each player's strategy is a best response to the other strategies in each subgame.
   	\end{definition}

   	\begin{definition}
   		A \textbf{weak perfect Bayesian equilibrium} (wPBE) is a profile of strategies $\left(\sigma_{1}, \ldots, \sigma_{n}\right)$ and beliefs $\left(P_1, \ldots, P_n\right)$ such that
   		\begin{enumerate}[(i)]
   			\item Each player's strategy is a best response to other strategies given the beliefs;
   			\item Beliefs are updated using Bayes formula, whenever possible.
   		\end{enumerate}
   	\end{definition}
   	
   	\begin{remark}
   		This definition does not put restriction when Bayes formula is not applicable, such as histories not attainable with current strategy profile.
   	\end{remark}
   	
   	\begin{definition}
   		A wPBE is \textbf{separating} (informative) if different types play different strategies. In such equilibria, private information is going to be revealed.
   	\end{definition}
   	
   	   	\begin{definition}
   		A wPBE is \textbf{pooling} if different types play the same strategy. In such equilibria, private information is not going to be revealed.
   	\end{definition}
\end{document}













