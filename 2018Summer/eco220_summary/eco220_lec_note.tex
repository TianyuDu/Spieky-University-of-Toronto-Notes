\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{spikey}
\usepackage{graphicx}
\usepackage{float}
\usepackage{xcolor}
\usepackage{soul}

 
\title{ECO220: Quantitative Methods in Economics \newline Lecture Notes (0201)}
\author{Tianyu Du}
\date{\today}

\begin{document}
	\maketitle
	\tableofcontents
	
	\section{Lecture 1 May. 08 2018}
	\subsection{Notations}
			\begin{center}
			\begin{tabular}{|c|c|c|}
				\hline
				Variable & Population & Sample \\
				\hline
				Size & $N$ & $n$ \\
				\hline
				Mean & $\mu$ & $\overline{x}$ \\
				\hline
				Std & $\sigma$ & $s$ \\
				\hline
			\end{tabular}
		\end{center}
	
	\subsection{From Sample to Population}
	\paragraph{} Let $p$ denote the percentage of qualified people in \underbar{population} and let $\hat{p}$ denote the percentage of qualified people in \underbar{sample}. Then, $p$ has an \underline{unknown} value and the value $\hat{p}$ can be calculated from sample data. We say \emph{$\hat{p}$ is an \textbf{estimator} for $p$}, and the value of $p$ is still unknown and can only be estimated.
	\paragraph{}$p$ is a \textbf{fixed value} (i.e. $p$ is fixed once population is fixed, we can measure the exact and certain value of $p$ if we traverse the whole population). But $\hat{p}$ will change from sample to sample. We call $\hat{p}$ an \textbf{estimator} (or \textbf{sample statistic}). The value of sample statistic will change from sample to sample. And, therefore, we call $\hat{p}$ a \textbf{random value}.
	
	
	\section{Lecture 2 May. 09 2018}
	\subsection{What is Statistics?}
		\[
			\text{Statistics}
				\begin{cases}
					\text{Descriptive Statistics}
						\begin{cases}
							\text{Graphs} \\
							\text{Numerical measures} \\
						\end{cases}
					\\
					\text{Inferential Statistics} \quad \emph{Draw conclusions in a population based on sample data.}
				\end{cases}
		\]
		\emph{Inferential Statistics involves uncertainties. To deal with the uncertainties, we need \textbf{probability}}
		\begin{figure*}[h]
			\centering
			\includegraphics[width=0.6\linewidth]{fig1.png}
		\end{figure*}
		
	\subsection{Data}
		\[
			\text{Data}
			\begin{cases}
				\text{Quantitative data}
					\begin{cases}
						\text{Discrete}\\
						\text{Continuous}
					\end{cases}
					\\
				\text{Qualitative data (Categorical data)}
			\end{cases}
		\]
		
	\subsection{Descriptive Statistics - Graphs}
	
	\subsection{Descriptive Statistics - Numerical measures}
		\subsubsection{Measures of centre}
		\paragraph{Mean} Let $\sset{x}{1}{N}$ be measurements for the population with size $N$. The population mean is denoted by $\mu$ and defined as 
			\[
				\mu = \frac{1}{N}\sum_{i=1}^N{x_i}
			\]
		Let $\sset{x}{1}{n}$ be measurements for the \underbar{sample} of size $n$. The sample mean is denoted by $\overline{x}$ and defined as 
			\[
				\overline{x} = \frac{1}{n}\sum_{i=1}^n{x_i}
			\]
		\textbf{Note} \emph{The mean is sensitive to extreme values.}
		
		\paragraph{Median} is the value in the middle when all data are put in order of magnitude. (For data with even size, median is defined as the average of the two values in the middle.)
		
		\paragraph{Mode} is value(s) with highest frequency.
		
		\paragraph{Percentiles} the $k^{th}$ percentile is a number such that $k \%$ of data fall below this number.
		
		
	\section{Lecture 3 May. 15 2018}
		\subsection{Measures of Variation(Spread)}
		\paragraph{Variance and Standard Derivation} Let $\sset{x}{1}{N}$ denote the population with size $N$ and let $\sset{x}{1}{n}$ denote the sample with size $n$. Then
			\begin{center}
				\begin{tabular}{|c|c|c|}
					\hline
					Measures & Population & Sample \\
					\hline \hline
					Size & $N$ & $n$ \\
					\hline
					Mean & $\mu = \frac{1}{N}\sum_{i=1}^N{x_i}$ & $\overline{x} = \frac{1}{n}\sum_{i=1}^n{x_i}$ \\
					\hline
					Variance & $\sigma^2 = \frac{1}{N}\sum_{i=1}^N{(x_i - \mu)^2}$ & $s^2 = \frac{1}{n-1}\sum_{i=1}^n{(x_i-\overline{x})^2}$ \\
					\hline
					Std & $\sigma = + \sqrt{\sigma^2}$ & $s = +\sqrt{s^2}$ \\
					\hline 
				\end{tabular}
			\end{center}
			\paragraph{Note} When calculate the sample variance, use $n-1$ as denominator.
			\paragraph{Note} mathematically,
			\[
				s^2 = \frac{1}{n-1}\sum_{i=1}^n(x_i - \overline{x})^2 = \frac{1}{n-1}[\sum_{i=1}^n{x_i^2} - \frac{1}{n}(\sum_{i=1}^n{x_i})^2]
			\]
		\paragraph{Range} is defined as the difference between the largest value and the smallest value.
		
		\section{Lecture 4 May. 16 2018}
		\subsection{Covariance and Correlation: on Populations}
		\paragraph{} Consider two sets of data (population) with size $N$, denoted as $\sset{x}{1}{N}$ and $\sset{y}{1}{N}$, where $x$ and $y$ measure the age and income of observation, respectively.
		\paragraph{Denote} $\mu_x:=$ mean of $x$, $\mu_y:=$ mean of $y$\newline $\sigma_x:=$ std dev of $x$ and $\sigma_y:=$ std dev of $y$.
		\emph{When $x$ changes, does $y$ change?}
		\paragraph{Covariance} defined covariance between two datasets, $x$ and $y$ as,
			\[
				Cov(x,y) = \frac{1}{N}\sum_{i=1}^N{(x_i - \mu_x)(y_i - \mu_y)}
			\]
		\paragraph{Correlation coefficient} the correlation coefficient $\rho$ between datasets $x$ and $y$ is defined as
			\[
				\rho = \frac{Cov(x,y)}{\sigma_x \sigma_y}
			\]
			
		\subsection{Covariance and Correlation: on Samples}
		\paragraph{} When $N$ is too large, we select a sample of size $n$.
		\paragraph{} Let $\sset{x}{1}{n}$ and $\sset{y}{1}{n}$ denote the selected samples with size $n$, $\overline{x}, \overline{y}$ denote the sample means, and $s_x, s_y$ denote the sample std dev.
		\paragraph{Covariance} between two sample is defined as
			\[
				Cov(x,y) = \frac{1}{n-1}\sum_{i=1}^n{(x_i - \overline{x})(y_i - \overline{y})}
			\]
		\paragraph{Correlation coefficient} the sample correlation $r$ is defined as
			\[
				r = \frac{Cov(x,y)}{s_x s_y}
			\]
		\subsection{Interpretations}
		\subsubsection{Interpreting covariance}
			\paragraph{Example} Consider samples $x$ and $y$ with
				\[
					Cov(x,y) = -25.31
				\]
			The \underbar{negative sign} means $x$ and $y$ have a \underbar{negative linear relationship}. As $x$ increases, $y$ tends to decrease. The \underbar{magnitude} 25.31 has \textbf{no} meaning.
			
		\subsubsection{Interpreting correlation coefficient}
			\paragraph{Example} Consider samples $x$ and $y$ with
				\[
					r = -0.94
				\]
			The \underbar{negative sign} means $x$ and $y$ have \underbar{negative linear relationship}. As $x$ increases, $y$ decreases. The \underbar{magnitude} 0.94 means the \underbar{linear relationship is strong}. When $r$ is close to 1 or -1, the string line relation is strong, when $r$ is close to 0, the relation is weak.
			\paragraph{Note} $\rho \in [-1, 1]$ and $r \in [-1, 1]$
			
		\section{Lecture 5 May. 22 2018}
		\subsection{Introduction to Simple Regression}
		\paragraph{} Let the linear estimator to be $\hat{y} = b_0 + b_1 x$ and let $y_i$ denote the actual value at $x_i$, $\hat{y}$ is the estimated $y$ value at $x_i$. Then, $e_i := y_i - \hat{y_i}$ is the error of y value at $x_i$ (a.k.a. \textbf{residual}).
		\paragraph{Note} notice that $\sum_{i=1}^n{e_i} \equiv 0$.
		\paragraph{SSE} \textbf{Sum of Squared Error}(SSE) as
			\[
				SSE = \sum_{i=1}^n{e_i^2} = \sum_{i=1}^n(y_i - b_0 - b_1x_i)^2
			\]
		\paragraph{OLS} Minimize $SSE$ with respect to $b_0$ and $b_1$, we have the FOC as
			\[
				\begin{cases}
					\pd{SSE}{b_0} = 0 \\
					\pd{SSE}{b_1} = 0
				\end{cases}
			\]
			By solving the first order conditions, we have
			\[
				\begin{cases}
					b_1 = \frac{\sum(x_i - \overline{x})(y_i - \overline{y})}{\sum{(x_i - \overline{x})^2}} \\
					b_0 = \overline{y} - b_1 \overline{x}
				\end{cases}
			\]
			The above method to find $b_0$ and $b_1$ is called the \underbar{method of least square}, or \underbar{method of Ordinary Least Square (OLS)}.
			
		\subsection{Relationship between $b_1$ and $r$}
		\paragraph{}
			\[
				b_1 = \frac{Cov(x,y)}{Var(x)} = \frac{Cov(x,y)}{std(x)std(y)} \frac{std(y)}{std(x)} = r \frac{s_y}{s_x}
			\]
		
		\subsection{Analysis of Variance (ANOVA)}
		\paragraph{} Let $y_i$ denote the actual $y$ value at $x_i$ and $\hat{y_i}$ denote the estimated $y$ value at $x_i$.
		\paragraph{Definition}
			\[
				SST = \sum_{i=1}^n(y_i - \overline{y})^2
			\]
			\[
				SSR = \sum_{i=1}^n(\hat{y_i} - \overline{y})^2
			\]
			\[
				SSE = \sum_{i=1}^n(y_i - \hat{y_1})^2
			\]
		\paragraph{Notice} $SST = SSR + SSE$
		\paragraph{Anova Table}
		\begin{center}
			\begin{tabular} {|c|c|c|c|c|}
				\hline
				 & SS & df & MS & F \\
				 \hline
				 Regression & SSR & 1 & MSR & MSR/MSE \\
				 \hline
				 Error(Residual) & SSE & MSE & $n-2$ & \\
				 \hline
				 Total & SST & $n-1$ & & \\
				 \hline
			\end{tabular}
		\end{center}
		where MS stands for \textbf{mean square} and is defined as
			\[
				MS = \frac{SS}{df}
			\]
			\[
				MSR = \frac{SSR}{1}
			\]
			\[
				MSE = \frac{SSE}{n-2}
			\]
			
		\section{Lecture 6 May. 23 2018}
		\subsection{OLS, continued.}
		\paragraph{R-square} \textbf{coefficient of determination} is defined as 
			\[
				R^2 = \frac{SSR}{SST}
			\]
			and notice that $R^2 \in [0, 1]$ and can be interpreted as \textbf{\% of variation in $y$ explained by $x$ (via the linear model)}
		\paragraph{Note} in ECO220, we use $R^2$ or $r^2$ to represent the same thing.
		
		\subsection{Sample space, Event and Probability}
		\paragraph{Experiment} an experiment is a process that creates \underbar{two or more} outcomes.
		\paragraph{Random Experiment} a random experiment is an experiment such that the outputs \emph{cannot} be determined \underbar{with certainty} before the end of the experiment.
		\paragraph{Sample Space} a sample space is the \underbar{set} of all possible outcomes in a random experiment.
		\paragraph{Event} an event is a \underbar{subset} of a sample space.
		\paragraph{Prob} Let $S$ be the sample space, let $E$ be an event, then the \textbf{probability of $E$}, $P(E)$ is defined as
			\[
				P(E) = \tx{probability of $E$} = \frac{\tx{Number of outcomes in $E$}}{\tx{Number of outcomes in $S$}}
			\]
			\emph{assuming that each outcome in $S$ has \underbar{equal likelihood} to be chosen into $E$.}
			
		\subsection{Some Rules of Probability}
		\paragraph{} Let $E$ be an event in sample space $S$, then
		\begin{itemize}
			\item $P(E) \in [0, 1]$.
			\item $P(S) = 1$.
			\item Let $E^c$ denote the \textbf{complementary} of $E$, then $P(E^c) = 1 - P(E)$.
			\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ (Addition Rule)
		\end{itemize}
		
	\section{Lecture 7 May. 29 2018}
		\paragraph{Mutually Exclusive Event} If $A\cap B = \emptyset$, we say events $A$ and $B$ are \textbf{mutually exclusive/disjoint}. Then, if $A,B$ are disjoint, we have 
			\[
				P(A\cup B) = P(A) + P(B)
			\]
			
		\subsection{Conditional Probability}
		\paragraph{Conditional Prob} In general, if $A$ and $B$ are events in sample space $S$, the \underbar{conditional probability of $A$ given $B$} is defined as 
			\[
				P(A \vert B) = \frac{P(A \cap B)}{P(B)}
			\]
		\paragraph{Multiplication rule}
			\[
				P(A \cap B) = P(A \vert B) P(B) = P(B \vert A) P(A)
			\]
		
		\subsection{Independent Event}
		\paragraph{Independent Event} We say two events, $A$ and $B$ are \textbf{independent} if any of the following is true. (those definitions below are equivalent.)
			\begin{itemize}
				\item $P(A \vert B) = P(A)$ or
				\item $P(B \vert A) = P(B)$ or
				\item $P(A \cap B) = P(A) P(B)$
			\end{itemize}
			
	\section{Lecture 8 May. 30 2018}
		\subsection{Bayes Theorem}
		\paragraph{} Let $A$ and $B$ be two events. Then,
		\[
			P(B\vert A) = \frac{P(A \vert B)P(B)}{P(A)}
		\]
		\emph{Proven by definition of conditional probability.}
		
		\subsection{Random Variable and Prob. Distributions}
		\paragraph{Prob. distribution}
		\paragraph{Cumulative Prob. distribution}
		
		\subsection{Expected Values}
		\paragraph{Expected Value} Let $X$ be a random variable with probability distribution $P(X)$. Then defined the expected value of $X$, $\mathbb{E}(X)$ as 
			\[
				\mu = \mathbb{E}(X) = \sum_{x}{x P(X=x)}
			\]
		\paragraph{Variance of Random Variable} For random variable $X$, we have
			\[
				\sigma^2 = Var(X) = \sum_{x}{(x - \mu)^2P(X=x)} = \mathbb{E}(X-\mu)^2
			\]
			
	\section{Lecture 9 June. 5 2018}
		\subsection{Expected Value of a Random Variable}
			\paragraph{Mean} $\mu = \mathbb{E}(X) = \sum_{x}{xP(X=x)}$.
			\paragraph{Variance} $\sigma^2 = \mathbb{E}(x - \mu)^2 = \mathbb{E}(X^2) - \mu^2$.
		\subsection{Laws of Expectation}
			\paragraph{} In general, let $X$ be a random variable, and let $a, c \in \R$, then
				\[
					\expect{aX+c} = a \expect{X} + c
				\]
				\[
					Var(aX+c) = Var(aX) = a^2 Var(X)
				\]
			\paragraph{} Let $X$ and $Y$ be random variables, and let $a,b,c \in \R$, then
				\[
					\expect{aX+bY+c} = a\expect{X} + b\expect{Y} + c
				\]
				\[
					Var(aX+bY+c) = Var(aX + bY) = a^2 Var(X) + b^2 Var(Y) + 2ab\ Cov(X,Y)
				\]
			\paragraph{Note} if $X$ and $Y$ are independent, then $\rho = Cov(X,Y) = 0$ and 
				\[
					Var(aX+bY+c) = a^2 Var(X) + b^2 Var(Y)
				\]
				
		\subsection{Binomial Distribution}
			\paragraph{} In general, let $n$ be the number of independent trails and $p = P(\#success)$. Let $X$ be a random variable which is the number of successes in $n$ trails, we have
			\[
				P(X=x) = \begin{pmatrix}
					n \\
					x
				\end{pmatrix} p^x (1-p)^{n-x},\tx{ for } x = \{0,1,2,\dots,n\}
			\]
			\[
				\mu = \expect{X} = np
			\]
			\[
				\sigma^2 = Var(X) = npq,\ q = 1-p
			\]
		
	\section{Lecture 10 June. 6 2018}
		\subsection{Uniform Distribution}
			\paragraph{} Let $X$ be uniform from $a$ to $b$. $f(x) = \frac{1}{b-a}, a \leq x \leq b$
			\[
				\mu = \expect{X} = \int_a^b{xf(x)dx} = \frac{a+b}{2}
			\]
			\[
				\sigma^2 = Var(X) = \expect{X^2} - \mu^2
			\]
		\subsection{Normal Distribution}
			\paragraph{} Let $X$ be a continuous random variable, satisfying $-\infty < x < \infty$. The mean of $X$ is $\mu$ and the variance of $X$ is $\sigma^2$. The graph of $X$ is
			\begin{figure*}[h]
				\centering
				\includegraphics[width=0.6\linewidth]{fig2.png}
			\end{figure*}
			The graph is symmetric at $\mu$ and the variance $\sigma^2$ determines the shape(spread) of $X$. We say $X$ \underbar{follows a normal distribution with mean $\mu$ and variance $\sigma^2$.} And denote as 
				\[
					X \sim N(\mu, \sigma^2)
				\]
			\paragraph{Standard Normal Distribution} A standard normal distribution is a normal distribution with mean $\mu=0$ and standard deviation $\sigma=1$. Denote the standard normal distribution as
				\[
					Z \sim N(0,1)
				\]
	\section{Lecture 11 June. 12 2018}
		\subsection{Applying normal distribution}
			\paragraph{Theorem} Let $X \sim N(\mu, \sigma^2)$, then
				\[
					z = \frac{x - \mu}{\sigma} \sim N(0, 1)
				\]
		\subsection{Normal Approximation to Binomial}
			\paragraph{} Consider a random variable $X \sim B(n,p)$, then we can approximate the binomial with a normal distribution $X \approx N(np, npq)$.
	
	\section{Lecture 12 June. 13 2018}
		\subsection{Sampling Distributions}
			\paragraph{} Consider population with size $N$ has $p$ as percentage of \emph{success} (qualified) and sample with size $n$ with $\hat{p}=\frac{x}{n}$ as percentage of \emph{success}.
			\paragraph{} $p$ is a parameter which has a fixed value. In real life, the value of $p$ is usually unknown. $\hat{p}$ is a sample statistic, which does not have fixed value (random variable, value of $\hat{p}$ vary from sample to sample). Also, $\mu$ and $\sigma$ are parameters, which are fixed but usually unknown. $\overline{x}$ is a sample statistic, and is random.
			\paragraph{} Suppose we know $p$ for population, then we can conclude about random variables from a random sample,
				\begin{enumerate}
					\item $\expect{\hat{p}} = p$.
					\item $Var(\hat{p}) = \frac{pq}{n},\ q = 1-p$
					\item When sample size $n$ is large, the distribution of $\hat{p}$ is \underbar{approximately normal} (\textbf{Central Limit Theorem in proportion}) \footnote{As a rule of thumb, $n$ is considered to be large when $np\geq 10 \land nq \geq 10$.}
				\end{enumerate}
				That's
					\[
						\hat{p} \approx \sim N(p, \frac{pq}{n}),\ \tx{when $n$ is large.}
					\]
			\paragraph{Example} Given $p_{success} = 0.3$ for the whole population and find the probability that at least 320 \emph{success}  found in a sample of size $n=1000$. i.e. Let $X$ denote the number of success in sample with $n=1000$, find $P(X \geq 320)$.
			\paragraph{Method 1} Use Central Limit Theorem, check $np=300\geq10 \land nq = 700 \geq 10$, thus $n$ is \emph{large}. And approximate $\hat{p}$ of sample as
				\[
					\hat{p} \sim N(p, \frac{pq}{n})
				\]
				\begin{multline*}
					\emph{Soln.} \\
					P(X \geq 320) = P(\hat{p} \geq 0.32) \\
					= P(\frac{\hat{p} - p}{\sqrt{\frac{pq}{n}}} \geq \frac{0.32 - 0.3}{\sqrt{\frac{0.3*0.7}{1000}}}) = P(z \geq \frac{0.02}{\sqrt{\frac{0.21}{1000}}}) \\
					\tx{Find $z$ in z-table} \\
					\blacksquare
				\end{multline*}
			
			\paragraph{Method 2} Use Normal Approximation to Binomial. $p=0.3$ and $n=1000$.
			\[
				X \approx Y \sim N(300, 210)
			\]
			\begin{multline*}
				\emph{Soln.} \\
				P(X \geq 320) = P(Y > 319.5) \\
				= P(\frac{Y - \mu}{\sigma} > \frac{319.5 - 300}{\sqrt{210}}) \\
				= P(z > 1.35) \tx{ find in z table} \\
				\blacksquare
			\end{multline*}
			\paragraph{Note} \emph{methods 1 and 2 do \textbf{not} give exactly same answer, but the answers should be close.}
			
		\subsection{Sampling distribution of $\overline{X}$, the sample mean}
			\begin{enumerate}
				\item $\expect{\overline{X}} = \mu$.
				\item $Var(\overline{X}) = \frac{\sigma^2}{n}$.
				\item When $n$ is large, the distribution of $\overline{X}$ is approximately normal. (\textbf{Central Limit Theorem in Mean}).
				\item When population is normal, the distribution of $\overline{X}$ is exactly normal, regardless of the sample size $n$.
			\end{enumerate}
			Putting together,
				\[
					\overline{X} \sim N(\mu, \frac{\sigma^2}{n}), \tx{ when $n$ is large.}
				\]
				
	\section{Lecture 13 Jun. 19 2018}
		\subsection{Confidence Interval}
			\paragraph{} To find $100(1-\alpha)\%$ confidence interval for $p$ estimated from $\hat{p}$ is
			\[
				\hat{p} \pm z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p}\hat{q}}{n}}
			\]
		
		\subsection{Sample Size Required}
			\paragraph{} When we specify the confidence level $1-\alpha$, and the margin of error, the required sample size is
			\[
				n = \frac{z_{\frac{\alpha}{2}}^2}{(ME)^2}pq
			\]
			If $p$ can be estimated from previous surveys, use it to find $n$. Else, use $p=0.5$ to find $n$.
			
	\section{Lecture 14 Jul. 3 2018}
		\subsection{Confidence Interval for Population Proportion}
			\paragraph{} \textbf{Point estimator} for $p$ is $\hat{p}$, confidence interval for $p$ is 
				\[
					\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}\hat{q}}{n}},\ with\ large\ n
				\]
				$n$ is considered as \emph{large} iff $np \geq 10 \land nq \geq 10$.
				$\sqrt{\frac{\hat{p}\hat{q}}{n}}$ is the \textbf{standard error/deviation} of estimation. 
				And $z_{\alpha/2} \sqrt{\frac{\hat{p}\hat{q}}{n}}$ is the \textbf{margin of error}. 
		\subsection{Two populations}
			\paragraph{}$p_1, p_2$ denote the qualification percentages for population 1 and 2. And $\hat{p_1}, \hat{p_2}$ denote the qualification percentages in samples with sample sizes
				$n_1, n_2$ from population 1 and 2.
			\paragraph{Point estimator}To estimate $p_1$ to $p_2$, we estimate $p_1 - p_2$.
			The point estimator for $p_1 - p_2$ is $\hat{p_1} - \hat{p_2}$.
			\paragraph{Interval estimator}The interval estimation for $p_1 - p_2$ is 
				\[
					PointEstimator \pm z_{\alpha /2} \times Std(PointEstimator)
				\]
				\[
					\hat{p_1} - \hat{p_2} \pm z_{\alpha /2} \times Std(\hat{p_1} - \hat{p_2})
				\]
				To find $Std(\hat{p_1} - \hat{p_2})$, by \emph{law of expectation}
				\[
					Var(aX+bY) = Var(aX) + Var(bY) + 2abCov(X,Y)
				\]
				We select two independent samples of size $n_1$ and $n_2$ from populations, therefore
				\[
					V(\hat{p_1} - \hat{p_2}) = V(\hat{p_1}) + V(\hat{p_2})
				\]
				When $n_1$ and $n_2$ are \underline{large}, by \emph{central limit theorem}, 
				\begin{displaymath}
					\hat{p_1} \sim N(p_1, \frac{p_1 q_1}{n_1}), \quad
					\hat{p_2} \sim N(p_2, \frac{p_2 q_2}{n_2})
				\end{displaymath}
				Then, for two \emph{independent} samples, $\hat{p_1}$ and $\hat{p_2}$ are independent, 
				\[
					V(\hat{p_1} - \hat{p_2}) = \frac{p_1 q_1}{n_1} + \frac{p_2 q_2}{n_2}
				\]
				But we do not know $p_1$ and $p_2$, we cannot calculate $V(\hat{p_1} - \hat{p_2})$ directly from above equation. We estimate $p_1$ and $p_2$ by $\hat{p_1}$ and $\hat{p_2}$
				\newline Therefore the \textbf{estimated variance} is 
				\[
					(Estimated)V(\hat{p_1} - \hat{p_2}) = \frac{\hat{p_1} \hat{q_1}}{n_1} + \frac{\hat{p_2} \hat{q_2}}{n_2}
				\]
				\[
					(Estimated)Std(\hat{p_1} - \hat{p_2}) = \sqrt{\frac{\hat{p_1} \hat{q_1}}{n_1} + \frac{\hat{p_2} \hat{q_2}}{n_2}}
				\]
		\paragraph{Result} confidence interval for $\hat{p_1} - \hat{p_2}$
			\[
				C.I._{\alpha} = \hat{p_1} - \hat{p_2} \pm z_{\alpha/2} \sqrt{\frac{\hat{p_1} \hat{q_1}}{n_1} + \frac{\hat{p_2} \hat{q_2}}{n_2}}
			\]
		\paragraph{Example} Compare the percentage of people going to casino in Ontario and Manitoba.
			\begin{center}
				\begin{tabular}{l|cc}
				  Var & Ontario & Manitoba \\
				  \hline
				  Actual & $p_1$ & $p_2$ \\
				  Sample size & $n_1=4151$ & $n_2=389$ \\
				  Point estimator & $\hat{p_1}=66.5\%$ & $\hat{p_2}=75.2\%$
				\end{tabular}
			\end{center}
			\quad \textbf{Point estimator} for $p_1 - p_2$ is $\hat{p_1} - \hat{p_2} = -0.087$
			\newline the 95\% C.I. for $p_1 - p_2$ is
				\[
					-.0087 \pm (z_{.025}=1.96) * \sqrt{\frac{.665 * .335}{4151} + \frac{.752 * .248}{389}} = (-.132, -.042)
				\]
			\newline \textbf{Interpretation} 95\% of the times, $p_1 - p_2$ falls between -.132 and -.042. We are 95\% confident that $p_1 - p_2$ is between -.132 and -.042.
			\newline \textbf{Remark} Is there a \underbar{significant difference} between the \% going to casinos between Ontario and Manitoba? Since the 95\% C.I. for $p_1 - p_2$ does not contain 0, we conclude that there \textbf{is} a significant difference between \% in two population.
			\newline \textbf{Remark} You can also use estimate the $p_2 - p_1$ and the 95\% C.I. would be $(.042, .132)$.
			
		\textcolor{red}{
			\paragraph{Interpretation (midterm 2)}
			A 95\% confidence interval for the proportion of Toronto residents who are in favour of building a new subway was found to be (0.26, 0.34). Which of the following is the best interpretation of this confidence interval?
			\\
			\textbf{Solution} We are 95\% confident that the \underbar{true proportion} of Toronto residents who are in favour of building a new subway is between 26\% and 34\%.
		}
		
		\subsection{Chapter 12. Hypothesis Testing in Population Proportion}
		\[
			\tx{Statistical Inference}
			\begin{cases}
				\tx{Estimation}
					\begin{cases}	
						\tx{Point Estimation} \\
						\tx{Interval Estimation}
					\end{cases}\\
				\tx{Hypothesis Testing}
			\end{cases}
		\]
		\paragraph{} $H_0$: the \textbf{null hypothesis}. $H_1$: the \textbf{alternative hypothesis}.
		\paragraph{Reality}
			\[
				\begin{cases}
					H_0 \tx{ Person not murder}
						\begin{cases}
							Guilty\ \vert \ H_0\textbf{ Type I Error}\\
							NotGuilty\ \vert \ H_0 \textbf{ No error}
						\end{cases} \\
					H_1 \tx{ Person is murderer}
						\begin{cases}
							Guilty\ \vert \ H_1 \textbf{ No error}\\
							NotGuilty\ \vert \ H_1 \textbf{ Type II Error}\\
						\end{cases}
				\end{cases}
			\]
		\paragraph{}When the court concludes "Guilty" and $H_0$ is true, type I error occurs and denote the probability of type I error as $\alpha$
			\[
				\alpha = P(\tx{Reject $H_0$} \vert H_0) P(\tx{Type I Error})
			\]
			And in this case, Type II Error will not occur.
		\paragraph{}Let $\beta$ denote the probability for type II error to occur.
			\[
				\beta = P(\tx{Reject $H_1$/Fail to reject $H_0$} \vert H_1) = P(\tx{Type II Error})
			\]
		\paragraph{Remark} $\beta$ becomes large as $\alpha$ becomes small. 
		\paragraph{Conclusion} Therefore, in \emph{hypothesis testing}, we have two hypotheses, $H_0$ and $H_1$. Based on sample results (evidence), we either \emph{reject $H_0$} or \emph{do not reject $H_0$}
	
	\textcolor{blue}{
		\section*{Midterm 2}
		\paragraph{Question 19} Let $X \sim N(\mu=7, \sigma^2=27)$ and $Y \sim U(-2, 16)$
		}
		\paragraph{Question (c)} Probability of obtaining a negative value of $Y$,
			\[
				P(Y < 0) = \frac{1}{16-(-2)} (0 - (-2)) = \frac{1}{9} = 0.1111
			\]
		\paragraph{Question (d)} A random same of size $n=30$ from the uniform population $Y$, what is the probability of getting a negative sample mean?
		\\
		\textbf{solution:} $\mu_Y = \frac{1}{2}(-2+16) = 7$ and $\sigma_Y^2 = \frac{1}{12}(16-(-2))^2 = 27$. Notice \textcolor{red}{ 
			\[\overline{Y} \sim N(\mu_Y, \sigma_Y^2)\]
			}
		Therefore
		\[
			P(\overline{Y} < 0) = P(\frac{\overline{Y} - \mu_Y}{\sigma_Y/\sqrt{n}} < \frac{0 - 7}{\sqrt{27}/\sqrt{30}}) \approx 0
		\]
	
	\section{Lecture 15 Jul. 4 2018}
		\subsection{Recall: Concepts of Hypothesis Testing}
			\paragraph{Concepts} $H_0$ \textbf{null hypothesis} and $H_1$ \textbf{alternative hypothesis}
			
			\paragraph{Case I} Rejecting $H_0$ while $H_0$ is true. \underbar{Failed to accept null hypothesis $H_0$}.
				\[
					\alpha = P(\tx{Reject }H_0\ \vert \ H_0 \tx{ True})= \textbf{Significance Level}
				\]
				\emph{In real life, we want the \textbf{significance level} to be as low as possible.} And note that significance level is probability for \underbar{type I error} to occur when $H_0$ is true.
				
			\paragraph{Case II} Accepting $H_0$ with $H_1$ is true. \underbar{Fail to accept alternative hypothesis}. $\beta$ is the probability of \underbar{type II error} while $H_1$ is true.
				\[
					\beta = P(\tx{Accept }H_0\ \vert \ H_1 \tx{ True})
				\]
			\paragraph{Remark} In hypothesis testing, we wish both $\alpha$ and $\beta$ to be small. However, by setting the rule of decision making and lowering $\alpha$, $\beta$ goes higher.
		\subsection{Hypothesis Testing}
			\textbf{Steps}
			\begin{enumerate}
				\item Set up null and alternative hypotheses $H_0$ and $H_1$.
				\item Setup a decision rule.
				\item Test statistic.
				\item Conclusion.
			\end{enumerate}
			
		\subsection{Hypothesis Testing in Population Proportion}
			\paragraph{Data} Population proportion $p$. Select sample with sample size $n$ and sample proportion $\hat{p}$.
			\paragraph{} $H_0$ null hypothesis on $p$ and $H_1$ as the alternative hypothesis.
			
			\paragraph{Example} Government claims that more than $50\%$ of Canadian are in favour of a policy.
			\newline
			\textbf{Step 1} setup hypotheses \underbar{$H_0:= p \leq 0.5$ and $H_1 := p > 0.5$}
			\newline
			\textbf{Step 2} setup a decision rule \underbar{If $\hat{p} < c$ we accept $H_0$. If $\hat{p} \geq c$ we reject $H_0$.}
			\newline Consider $c=0.55$. Then in a random sample of $n=200, \hat{p} = \%$ in favour from sample. Decision rule is
			\[
				\begin{cases}
					\tx{Accept $H_0: p \leq 0.5$ if $\hat{p} < 0.55$} \\
					\tx{Accept $H_1: p > 0.5$ if $\hat{p} \geq 0.55$}
				\end{cases}
			\]
			\newline \textbf{Step 3} test statistic. In a sample of $n=200, \hat{p}=0.58$.
			\newline \textbf{Step 4} Conclusion: Reject $H_0$.
			
			\subsubsection{Finding Critical Value c}
				\paragraph{} Finding $\alpha$
					\[
						\alpha = P(\tx{Type I Error}) = P(\hat{p}\geq 0.55 \vert p \leq 0.5)
					\]
					By \underbar{central limit theorem}, when $n$ is large,
					\[
						\hat{p} \sim N(np, \frac{pq}{n})
					\]
					Then normalized data, 
					\[
						\alpha = p(z \geq \frac{0.05 \sqrt{200}}{0.5}) = 0.0793 \approx 8\%
					\]
					Therefore, by setting the critical value $c=0.55$, the probability of type I error, $\alpha = 0.08$.
					\newline
					Finding $\beta$
					\[
						\beta = P(\hat{p} < 0.55 \vert p > 0.5)
					\]
				\begin{figure*}[h]
					\begin{center}
						\includegraphics[width=0.4\linewidth]{fig3}
					\end{center}
				\end{figure*}
				
				
	\section{Lecture 16 Jul. 10 2018}
		\subsection{Concepts in Hypothesis Testing}
			\begin{enumerate}
				\item Set up $H_0$ and $H_1$ hypotheses.
				\item Set up a decision rule.
				\item Test statistic (sample evidence).
				\item Conclusion.
			\end{enumerate}
			
		\subsection{Hypothesis on $p$, Population Proportion}
			\paragraph{Example} Government Claims that more than half of the Canadian support the idea of increasing [...]
			
			\[
				H_0: p \leq 0.5,\quad 
				H_1: p > 0.5
			\]
			\\
			\textbf{Decision rule} we will select a large sample, $n=100$. Let $\hat{p} = \%$ support in the sample. By choosing critical value $c$, we reject $H_0$ if $\hat{p} \geq c$ and do not reject $H_0$ if $\hat{p} < c$.
		
		\subsection{Determining the Critical Value $c$}
			\paragraph{Cont'd} Since $n=100$ is large, by central limit theorem,
				\[
					\hat{p} \sim N(p, \frac{pq}{n})
				\]
			\paragraph{Remark} To determine a critical value $c$, we select an acceptable $\alpha$ value.
			
			\paragraph{Example} Refer to previous example.
			\[
				H_0: p \leq 0.5,\quad 
				H_1: p > 0.5
			\]
			Want to choose $\alpha = 0.01$. We know that if $\hat{p} \geq c$ then reject $H_0$. then
			\begin{multline*}
				\\
				\alpha = 0.01 = P(\tx{Reject }H_0 | H_0 \tx{ True}) \\
				= P(\hat{p} \geq c | p \leq 0.5) \\
				 \tx{ (Normalizing data, since $p$ is unknown, use 0.5 for it.)} \\
				= P(\frac{\hat{p} - p}{\sqrt{pq/n}} \geq \frac{c - 0.5}{\sqrt{(0.5)(0.5)/100}})\\
				= P(z \geq \frac{c - 0.5}{\sqrt{(0.5)(0.5)/100}}) \\
				\implies \frac{c - 0.5}{\sqrt{(0.5)(0.5)/100}} = 2.33 \\
				\implies c = 0.5 + 2.33 \sqrt{\frac{0.25}{100}}\\
				\implies c = 0.6165 \\
				\blacksquare
			\end{multline*}
			\paragraph{} Therefore, for decision rule $\alpha = 0.01$, corresponds to \emph{Reject $H_0$ if $c \geq 0.6165$}.
			\\ also can be stated as a normalized proportion: \emph{Reject $H_0$ if $z = \frac{\hat{p} - p}{\sqrt{pq/n}} \geq 2.33$}
			
			\paragraph{Ways to Write Decision Rules}
			\begin{enumerate}
				\item \underbar{By significance value} $\alpha = 0.01$
				\item \underbar{By sample proportion} If $\hat{p} \geq 0.6165$ then reject $H_0$, else accept $H_0$.
				\item \underbar{By normalized sample proportion} If $z \geq 2.33$ reject $H_0$, else, accept $H_0$; where $z = \frac{\hat{p} - p}{\sqrt{pq/n}}$.
			\end{enumerate}
			
			\paragraph{Example} Manufacturer claims that \underbar{less than $10\%$} of the computer ship they manufactured are defective. Select a random sample with $n=100$.
			\\
			\emph{Solution.}
			\\
			Let $p=\%$ defective. Setting up the hypotheses:
				\[
					H_0 := p \geq 0.1 \quad
					H_1 := p < 0.1
				\]
			Setting up the decision rule: $\alpha = 0.05$. i.e. Reject $H_0$ if $\hat{p} \leq c$.
			\begin{multline*}
				\emph{Finding $c$:} \\
				\alpha = 0.05 = P(\hat{p} \leq c | p \geq 0.1) \\
				\implies 0.05 = P(z=\frac{\hat{p}-p}{\sqrt{pq/n}} \leq \frac{c-0.1}{\sqrt{0.09/100}}) \\
				\implies c = 0.05065 \\
				\blacksquare
			\end{multline*}
			Therefore decision rule associated with $\alpha = 0.05$ is \emph{if $\hat{p} \leq 0.05065$ then reject $H_0$.}
			\\
			Sample Statistic: in the sample of $n=100$, $\hat{p} = 0.06$. Therefore, since $\hat{p} > 0.005065$, accept $H_0$.
			
			\paragraph{Remark} Suppose we select the decision rule $\alpha$ less than $0.05$, the conclusion from hypothesis testing remains unchanged. Suppose we select a larger $\alpha$ the conclusion might change, depending on how large $\alpha$ is.
			
	\section{Lecture 17 Jul. 11 2018}
	
	\subsection{Continue, Type I Error Control}
		\paragraph{Two-Sided Test}
			\[
				H_0 := p = p_0 \quad
				H_1 := p \neq p_0
			\]
		\begin{example}
			A candidate believes that \underbar{at least} \footnote{See remark 17.1, moving the equal sign to the null hypothesis is insignificant in large population} $30\%$ of voters will vote for him in the upcoming election. Put the \underbar{want to prove} part into the alternative hypothesis.
			\[
				H_0 := p \leq 0.3 \quad
				H_1 := p > 0.3
			\]
		\end{example}
		
		\begin{remark}
			\color{red}{Always put the equal sign with the null hypothesis}
		\end{remark}
		\begin{proof}
			Set $\alpha = 0.05$ the decision rule also can also be written as:
			\[
			\begin{cases}
				\tx{if $\hat{p} \geq c$ reject $H_0$}\\
				\tx{if $\hat{p} < c$ do not reject $H_0$}.
			\end{cases}
			\]
			or using standardized $\hat{p}$,
			\[
			\begin{cases}
				\tx{if $z \geq 1.645$ reject $H_0$}\\
				\tx{if $z < 1.645$ do not reject $H_0$}.
			\end{cases}
			\]
		Sample result:
		\\
		In a sample of size $n=400$, $\hat{p} = 0.32$.
		\\
		\underbar{Step1} Standardize $z := \frac{\hat{p} - p}{\sqrt{pq/n}} = \frac{0.32-0.3}{\sqrt{0.21/400}} = 0.873$.
		\\
		\underbar{Step2} Check decision rule, $z < 1.645$.
		\\
		\underbar{Step3} Draw conclusion: do not reject $H_0$.
		\end{proof}
		
		
		\begin{example}
			Refer to example 1,
			\[
				H_0:= p \leq 0.3 \quad
				H_1:= p > 0.3
			\]
			with decision rule $\alpha=0.05$.
			\\
			Sample result is $\hat{p}=0.32$.
		\end{example}
		\begin{proof}
			Method2:
			\\
			Find the p-value:= area under $H_0$ normal graph to the right of $\hat{p}$.
			\[
				p-value = P(\hat{p}\geq0.32 | H_0) = P(z \geq \frac{0.32 - 0.3}{\sqrt{0.21/400}}) = P(z > 0.873) = 0.1922 > \alpha
			\]
			Therefore, accept $H_0$.
		\end{proof}
	
		\paragraph{Summary} Hypothesis testing using p-value.
		\begin{enumerate}
			\item if p-value $\leq \alpha$,\footnote{Notice that when $p-value = \alpha$, we reject $H_0$.} reject $H_0$.
			\item if p-value $ > \alpha$, do not reject $H_0$.
		\end{enumerate}
		
		
		\begin{example}
			Wish to test
			\[
				H_0 := p \geq 0.4 \quad
				H_1 := p < 0.4
			\]
		Setting $\alpha = 0.05$. Suppose p-value
			\[
				p-value = \frac{\hat{p} - 0.4}{\sqrt{0.24/n}} = 0.0193
			\]
		Since $p-value \leq \alpha$, reject $H_0$.
		\end{example}
		\paragraph{Intuitively} If the p-value is small compared to $\alpha$, then choose to reject $H_0$.
		
		\begin{example}
			Test 
			\[
				H_0 := p \leq 0.6 \quad
				H_1 := p > 0.6
			\]
			and the calculation shows the sample p-value is $0.025$. The conclusion would depend on the decision rule.
			\\
			(1) Choose $\alpha=0.5$ then we reject $H_0$.
			\\
			(2) If we choose $\alpha=0.01$, since $p-value > \alpha$, we do not reject $H_0$.
		\end{example}
		
		\subsection{Type II Error}
		
		\begin{example}
			Test 
			\[
				H_0 := p \leq 0.4 \quad
				H_1 := p > 0.4
			\]
			and select $\alpha=0.05$. Let $\hat{p}$ be the sample percentage from large sample with size $n$.
		\end{example}
		\paragraph{}
			By definition
			\[
				\beta = P(\tx{Do not reject }H_0 | H_1)
			\]
			and $\beta$ is the area to the \underbar{left} of $c$ under \underbar{$H_1$} curve. In the graph, \emph{as $\alpha$ decreases, $\beta$ increases at the same time.} Hence, in hypothesis testing, we select $\alpha$ first. Then we look at how large $\beta$ is.
		
		\begin{figure*}[h]
			\centering
			\caption{Graph representation of $\alpha$ and $\beta$.}
%			\includegraphics{}
		\end{figure*}
		
		And $\alpha$ is called the \textbf{significance level}. And $1-\beta$ is called the \textbf{power}.
		\\
		Ideally, in hypothesis testing, we want both $\alpha$ and $\beta$ small.
		
		\begin{example}
			Test 
			\[
				H_0 := p \leq 0.4 \quad
				H_1 := p > 0.4
			\]
			Select $\alpha = 0.05$ then to calculate $\beta$. For example, we can find $\beta$ at p=0.5.
		\end{example}



	\section{Lecture 18 Jul. 17 2018}
		\begin{example}
			\[
				H_0 := p \leq .4 \quad
				H_1 := p > .4
			\]
			Decision rule: $\alpha = 0.05$, reject region of $H_0$ has area $0.05 = \alpha$
			\\
			$\alpha = 0.05$ means we reject $H_0$ if $\hat{p} \geq c$ and don't reject $H_0$ of $\hat{p} < c$.
			\\
			\textbf{Use standardized normal curve} 
			\[
				\begin{cases}
					\tx{Reject $H_0$ if } z \geq 1.645 \\
					\tx{Do not reject $H_0$ if } z < 1.645
				\end{cases}
			\]
			From sample $n=400$, we find 184 of them will vote. The sample result shows $\hat{p} = 0.46$.
			To draw a conclusion for the first type of decision rule, need to determine $c$ by solving
			\[
				\frac{\hat{p}-c}{\sqrt{\hat{p}(1-\hat{p})/n}}
			\]
			for method 2, the same as method 1 but we use standard normal $z$ instead of the regular normal, where $p=0.4$
			\[
				z = \frac{\hat{p} - p}{\sqrt{pq/n}}
			\]
			by comparing p-value $p-v = P(\hat{p} \geq 0.46 | H_0)$ and compare to $\alpha$.
		\end{example}

		\paragraph{} If we don't reject $H_0$, then we do not make type I error. However, if $H_0$ is not true and we do not reject it. 
			There would be a \textbf{Type II Error} what's the probability of type II error $\beta$? By definition $\beta=P(Accept\ H_0 | H_1 \ True)$
		
	\section{Lecture 19 Jul. 18 2018}
	    \subsection{Confidence Interval and Hypothesis Testing on the Population Mean $\mu$}
	        \par \textcolor{red}{If $\sigma$ is known and $n$ is large}
	        \\
	        Let $\overline{X}$ denote the observed sample mean and as the point estimator of population mean $\mu$. And the $1-\alpha$ confidence interval for $\mu$ is 
	        \[
	            \overline{X} \pm z_{\alpha/2} \frac{\sigma}{\sqrt{n}}
	        \]
	        and z-statistic
	        \[
	            z = \frac{\overline{X} - \mu}{\sigma/\sqrt{n}}
	        \]
	        
	        \begin{remark}
	            When we use z-statistic, \ul{we assume $n$ is large or population is normal}.
	        \end{remark}
	        
	        \par \textcolor{red}{If $\sigma$ is unknown}
	        Use t-statistic and sample standard deviation $s$ to approximate normal distribution,
	        \[
	            t = \frac{\overline{X} - \mu}{s/\sqrt{n}} \quad df = n - 1
	        \]
	    
    	    \begin{remark}
    	        Mathematically, the t-distribution is derived from z-distribution. So when we use the t-distribution, \ul{we also assume the population is normal or close to normal}.
    	    \end{remark}
    	    
        \subsection{Comparing mean of two populations}
            \paragraph{Point estimation} on $\mu_1 - \mu_2$ is $\overline{X_1} - \overline{X_2}$.
            \paragraph{Confidence Interval} the $(1-\alpha)$ confidence interval for $\mu_1 - \mu_2$ is 
                \\
                if $\sigma_1, \sigma_2$ are known,
                \[
                    \overline{X_1} - \overline{X_2} \pm z_{\alpha/2} \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}
                \] if $\sigma_1, \sigma_2$ are unknown,
                \[
                    \overline{X_1} - \overline{X_2} \pm t_{\alpha/2} \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
                \]
	        
		
	\section{Lecture 20 Jul. 24 2018}
	    \subsection{Simple Regression}
            \subsubsection{Basic Model}
	            \paragraph{Model}
	            \[
	                y = \beta_0 + \beta_1 x + \epsilon
	            \]
	            estimate from sample data
	            \[
	                \hat{y} = b_0 + b_1 x
	            \]
	            \paragraph{Interpretation} $x$ increases by 1 unit, $y$ increases by $b_1$ unit(s).
	       \subsection{Regress $y$ on $\ln{x}$}
	            \paragraph{Model}
	            \[
	                y = \beta_0 + \beta_1 \ln{x} + \epsilon
	            \]
	            estimate from sample data
	            \[
	               \hat{y} = b_0 + b_1 \ln{x}
	            \]
	            \begin{gather*}
	                \frac{dy}{dx} = b_1 \frac{1}{x} \\
	                \implies dy = b_1 \frac{dx}{x}
	            \end{gather*}
	            \paragraph{Interpretation} $x$ increases by \underline{1 percent}, $y$ increase by $\frac{b_1}{100}$ unit(s).
	            
	       \subsection{Regress $\ln{y}$ on $x$}
	            \paragraph{Model}
	            \[
	                \ln{y} = \beta_0 + \beta_1 x + \epsilon
	            \]
	            estimate from sample data
	            \[
	                \hat{\ln{y}} = b_0 + b_1 x
	            \]
	            \begin{gather*}
	                \frac{d\ln{y}}{dy} \frac{dy}{dx} = b_1 \\
	                \implies \frac{dy}{y} = b_1 dx 
	            \end{gather*}
	            \paragraph{Interpretation} $x$ increases by 1 unit, $y$ increases by $b_1$ \underline{percent}.
	       
	       \subsection{Regress $\ln{y}$ on $\ln{x}$}
	            \paragraph{Model}
	            \[
	                \ln{y} = \beta_0 + \beta_1 \ln{x} + \epsilon
	            \]
	            estimate from sample data
	            \[
	                \hat{\ln{y}} = b_0 + b_1 \ln{x}
	            \]
	            \begin{gather*}
	                \frac{d\ln{y}}{dy} \frac{dy}{dx} = b_1 \frac{1}{x} \\
	                \implies \frac{dy}{y} = b_1 \frac{dx}{x} \\
	            \end{gather*}
	            \paragraph{Interpretation} $x$ increases by 1 \underline{percent} and $y$ increases by 1 \underline{percent}.
	            
    \section{Lecture 21 Jul. 31 2018}
        \subsection{Dummy Variable}
            \begin{definition}
                A \textbf{dummy variable} is a \ul{binary categorical variable} such that the numerical values are labels for the category.
            \end{definition}
            
        \subsection{Hypothesis Testing in Simple Regression}
            \paragraph{Model}
                \[
                    y = \beta_0 + \beta_1 x + \epsilon
                \]
            \paragraph{Significance of model relation}
            $\beta_1$ captures the relationship between $x$ and $y$, we wish to test if the relationship between $x$ and $y$ is significant.
            \\
            \textbf{Setup hypothesis}
            \[
                \begin{cases}
                    H_0 : \beta_1 = 0 \tx{ model relation is \textbf{not} significant.} \\
                    H_1 : \beta_1 \neq 0 \tx{ model relation is significant.} \\
                \end{cases}
            \]
            
            \paragraph{Method 1: Use t-statistic}
                \begin{gather*}
                    t = \frac{\tx{point estimator - value to be tested}}{SE(\tx{point estimator})} \\
                    = \frac{b_1 - 0}{SE(b_1)} \\
                    = \frac{b_1}{SE(b_1)}\quad df = n - 2\\
                \end{gather*}
            
            \paragraph{Method 2: Use F-statistic}
                From ANOVA table, and $F$ value can be find using
                \begin{gather*}
                    F = \frac{MS_{regression}}{MS_{residue}} \quad df = (1, n-2)
                \end{gather*}
                Notice $df_{numerator} = k = 1$ as the number of independent variables the model is regressing on and $df_{denominator} = n - k - 1$.
\end{document}






















